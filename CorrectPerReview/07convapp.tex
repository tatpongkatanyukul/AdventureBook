%\chapter{การประยุกต์ใช้ในการรู้จำทัศนรูปแบบ}
\chapter{การเรียนรู้เชิงลึกในโลกการรู้จำทัศนรูปแบบ}
\label{chapter: Convolution Applications}

\begin{Parallel}[c]{0.52\textwidth}{0.42\textwidth}
	\selectlanguage{english}
	\ParallelLText{
		``By three methods we may learn wisdom.
		First, it is by reflection, which is noblest.
		Second, it is by imitation, which is easiest.
		And, third, it is by experience, which is the bitterest.''
		\begin{flushright}
		---Confucius
		\end{flushright}
	}
	\selectlanguage{thai}
	\ParallelRText{
		``มีสามวิธีที่เราจะเรียนรู้.
		หนึ่ง ด้วยการคิดพิจารณา ซึ่งสูงส่งที่สุด.
		สอง ด้วยการเลียนแบบ ซึ่งง่ายที่สุด.
		สาม ด้วยประสบการณ์ ซึ่งขมขื่นที่สุด.''
		\begin{flushright}
		---ขงจื้อ
		\end{flushright}
	}
\end{Parallel}
\index{english}{words of wisdom!Confucius}
\index{english}{quote!learning}

%\vspace{1cm}

โครงข่ายคอนโวลูชั่น เหมาะกับข้อมูลที่มีลักษณะเชิงท้องถิ่นสูง.
ในทางปฎิบัติ ข้อมูลหลาย ๆ ชนิด มีลักษณะเชิงท้องถิ่นสูง รวมถึงข้อมูลเชิงทัศนะ เช่น ภาพ และวิดีโอ.
โครงข่ายคอนโวลูชั่นได้รับการประยุกต์ใช้อย่างกว้างขวางกับข้อมูลเชิงทัศนะ 
ไม่ว่าจะเป็น การรู้จำประเภทของวัตถุหลักในภาพ (image classification\cite{Alexnet2012, VGG2015, Inception2015, He_2016_CVPR, Densenet2017}),
การตรวจจับวัตถุในภาพ (object detection\cite{YOLO1, YOLO2, FasterRCNN2015}),
การตรวจจับท่าทาง (pose detection\cite{CaoEtAl2017}),
การรู้จำใบหน้า (face recognition\cite{SchroffEtAl2015}),
การแบ่งส่วนภาพตามความหมาย (semantic segmentation\cite{LongEtAl2015}),
การบรรยายภาพ (scene description\cite{KarpathyFeiFei2015, JohnsonEtAl2016, VinyalsEtAl2015},
การเพิ่มความละเอียดให้กับภาพ (enhance image resolution\cite{DongEtAl2014, ShiEtAl2016a, ShiEtAl2016},
การซ่อม เสริม และกำเนิดภาพ (image reparation/generation\cite{pixelRNN2016, VAE2019, GoodfellowEtAl2014a, PalssonEtAl2018}),
การจำแนกวิดีโอ (video classification\cite{KarpathyEtAl2014}),
การติดตามวัตถุ (object tracking\cite{WangEtAl2013b})
เป็นต้น.
การประยุกต์ใช้เหล่านี้ อาศัยความคิดสร้างสรรค์และความเข้าใจในภาระกิจ ทฤษฎี กลไกการทำงานของการเรียนรู้ของเครื่อง 
และในหลาย ๆ ครั้งได้พัฒนาทฤษฎีเฉพาะขึ้นมา.
การประยุกต์ใช้ที่น่าสนใจ มีมากมายและยังมีการพัฒนาอย่างต่อเนื่อง
บทนี้ เลือกอภิปรายบางส่วนของการประยุกต์ใช้ที่น่าสนใจ เพื่อให้เห็นตัวอย่างของความคิดสร้างสรรค์ในการประยุกต์ใช้โครงข่ายคอนโวลูชั่น.


\section{การตรวจจับวัตถุในภาพ}
\label{sec: object detection}

\textbf{การตรวจจับวัตถุในภาพ} (object detection)
\index{thai}{การตรวจจับวัตถุในภาพ}
\index{english}{object detection}
เป็นภาระกิจที่รับอินพุตเป็นภาพ และให้เอาต์พุตเป็นตำแหน่งของวัตถุที่พบในภาพ พร้อมชนิดของวัตถุ.
โดยทั่วไป ตำแหน่งของวัตถุ จะระบุด้วย\textit{กล่องขอบเขต} (bounding box) ซึ่งอาจอ้างอิงถึงด้วยพิกัดแนวนอนและแนวตั้งของจุดศูนย์กลางของ\textit{กล่องขอบเขต}
และความกว้างกับความสูงของ\textit{กล่องขอบเขต}.

รูป~\ref{fig: conv app classification vs detection} แสดงผลลัพธ์ของการตรวจจับวัตถุในภาพ (ภาพซ้าย)
เปรียบเทียบกับ\textbf{การรู้จำประเภทของวัตถุหลักในภาพ} (image classification ในภาพขวา).
\index{english}{image classification}
\index{thai}{การรู้จำประเภทของวัตถุหลักในภาพ}
\textit{การรู้จำประเภทของวัตถุหลักในภาพ} เป็นภาระกิจที่รับอินพุตเป็นภาพ และให้เอาต์พุตเป็นชนิดของวัตถุหลักในภาพ 
%(หรือความน่าจะเป็นของชนิดของวัตถุหลัก
ส่วน\textit{การตรวจจับวัตถุในภาพ} จะเพิ่มการระบุตำแหน่งของวัตถุออกมาให้ด้วย.

\textit{การรู้จำประเภทของวัตถุหลักในภาพ} ไม่มีการระบุตำแหน่งของวัตถุภายในภาพ
และมักถูกตีกรอบปัญหาเป็นปัญหา\textit{การจำแนกประเภท} (multi-class classification).
แบบจำลองของ\textit{การรู้จำประเภทของวัตถุหลักในภาพ} นิยมใช้โครงข่ายคอนโวลูชั่น ที่โครงสร้างเอาต์พุตใช้\textit{ชั้นเชื่อมต่อเต็มที่}ตามด้วยฟังก์ชันซอฟต์แมกซ์ 
ดังเช่น แบบจำลอง\textit{อเล็กซ์เน็ต} ที่ได้อภิปรายในหัวข้อ~\ref{sec: AlexNet}.

%
\begin{figure}
	\begin{center}
		\begin{tabular}{cc}
		การรู้จำประเภทของวัตถุหลักในภาพ (image classification)
		& การตรวจจับวัตถุในภาพ (object detection)
		\\
		\includegraphics[width=0.4\columnwidth]{07ConvApp/BabyKangaroo.png}
		&
		\includegraphics[width=0.4\columnwidth]{07ConvApp/BabyKangarooDetected.png}
		\\
		output: ``Baby Kangaroo'' & output: $(x, y, w, h, \mbox{``Baby Kangaroo''})$
		\end{tabular} 
		\caption[การรู้จำประเภทของวัตถุหลักในภาพ และการตรวจจับวัตถุในภาพ]{เปรียบเทียบการรู้จำประเภทของวัตถุหลักในภาพ และการตรวจจับวัตถุในภาพ. ภาพซ้ายมือแสดงผลลัพธ์จากการรู้จำประเภทของวัตถุหลักในภาพ ซึ่งจะระบุแค่ชนิดของวัตถุหลักในภาพ.
		ภาพขวามือแสดงผลลัพธ์จากการตรวจจับวัตถุในภาพ ซึ่งนอกจากระบุชนิดของวัตถุแล้วยังต้องระบุตำแหน่งด้วย. กรอบสีเขียวในภาพขวา คือ \textit{กล่องขอบเขต} ซึ่งมักถูกระบุด้วยพิกัด (แนวนอนและแนวตั้ง $x,y$) และขนาด (ความกว้างและความสูง $w,h$).}
		\label{fig: conv app classification vs detection}
	\end{center}
\end{figure}
%

\textit{การตรวจจับวัตถุในภาพ} อาจทำได้หลายวิธี. 
วิธีแบบดั่งเดิม ใช้\textit{การจำแนกประเภท} ร่วมกับ\textit{เทคนิคหน้าต่างเลื่อน} 
ดังอภิปรายในหัวข้อ~\ref{sec: classic object detection}
(หรือเทคนิคอื่นในลักษณะเดียวกัน\cite{FasterRCNN2015, DeformablePartModel2010}).
หนึ่งในศาสตร์และศิลป์ของ\textit{การตรวจจับวัตถุในภาพ} คือ \textbf{โยโล่} (YOLO\cite{YOLO1}) ซึ่งเป็น\textit{ระบบตรวจจับวัตถุในภาพแบบเวลาจริง} (real-time object detection)
และโยโล่ยังมีการทำงานภายใน ที่ใช้โครงสร้างกลไกหลักอย่างเดียว ทำให้การปรับแต่งประสิทธิภาพสามารถทำได้ง่าย.

\paragraph{โยโล่.}
\label{sec: YOLO}
\index{thai}{การตรวจจับภาพวัตถุ}\index{thai}{โยโล่}
\index{english}{Object Detection}\index{english}{YOLO}
\index{thai}{การตรวจจับภาพวัตถุ!โยโล่}
\index{english}{Object Detection!YOLO}
%
\textit{โยโล่}\cite{YOLO1, YOLO2}%
%\footnote{
%การประยุกต์ใช้โยโล่เป็นไปอย่างกว้างขวาง และมีพัฒนาการต่อเนื่อง
%เพื่อความกระชับ
%การอภิปรายในหัวข้อนี้ จะยึดแนวทางของ\textit{โยโล่} ที่นำเสนอโดยคณะของเรดมอน\cite{YOLO1} ในปี 2016 เป็นหลัก
%โดยอาจมีการดัดแปลงบ้างในรายละเอียด เพื่อความเหมาะสม.
%}
รับอินพุตเป็นภาพสี และให้เอาต์พุตออกมาเป็น\textit{กล่องขอบเขต}ระบุตำแหน่งของวัตถุที่ตรวจจับได้ในภาพ พร้อมชนิดของวัตถุที่พบ.
โยโล่ ใช้\textit{โครงข่ายคอนโวลูชั่น} ในการแปลงจากอินพุตไปเป็นเอาต์พุต.
%
ต่างจากระบบ\textit{การตรวจจับวัตถุในภาพ}แบบดั่งเดิม
โยโล่ ตั้งปัญหา\textit{การตรวจจับวัตถุในภาพ} เป็น\textit{การหาค่าถดถอย} เพื่อทำนายตำแหน่งของวัตถุ
และการ\textit{จำแนกประเภท} เพื่อทำนายชนิดของวัตถุที่พบ.
% โดยเพิ่มใช้วิธี{\color{red} non-max suppression or thresholding?} (non-max suppression, ดูหัวข้อ)
%รูป~\ref{fig: conv classic vs Yolo} แสดงแผนภาพเปรียบเทียบแนวทางการตรวจจับวัตถุแบบคลาสสิก (หัวข้อ~\ref{sec: classic object detection}) กับโยโล่.
%
%%
%\begin{figure}
%	\begin{center}
%		\includegraphics[width=6.8in]{07ConvApp/classicVYolo02.png}
%		\caption[การตรวจจับภาพวัตถุแบบคลาสสิกกับแบบโยโล่]{แผนภาพเปรียบเทียบการตรวจจับภาพวัตถุด้วยแนวทางคลาสสิก
%			กับแนวทางของโยโล่.
%			ภาพในแถวบนแสดงตัวอย่างภาพอินพุต
%			ตัวอย่างภาพที่ได้จากการตรวจจับก่อน\textit{การลดผลการตรวจหาที่ซ้ำซอน}
%			และตัวอย่างภาพเอาต์พุต.
%			ภาพในแถวกลางแสดงขั้นตอนคร่าวๆของแนวทางคลาสสิก ที่อาศัยการสุ่มส่วนภาพและการจำแนกส่วนของภาพ.
%			ภาพในแถวล่างสุดแสดงโครงสร้างของโยโล่ที่อาศัยเพียงโครงข่ายคอนโวลูชั่น และให้ผลลัพธ์ออกมาในรูปการทำนายค่าของพิกัดและขนาดของกรอบวัตถุ ความมั่นใจว่ามีวัตถุในกรอบ และความน่าจะเป็นของชนิดวัตถุต่างๆ.
%			สังเกตุว่า ขั้นตอนสุดท้ายโยโล่ก็ใช้\textit{วิธีเลือกด้วยขีดแบ่ง} (thresholding) หรืออาจใช้\textit{วิธียับยั้งค่าไม่มากที่สุด} (non-maximum suppression) ซึ่งจัดเป็นวิธี\textit{การลดผลการตรวจหาที่ซ้ำซอน} (redundancy removal)}
%		\label{fig: conv classic vs Yolo}
%	\end{center}
%\end{figure}
%%

แนวทางคือ
เพื่อสามารถตรวจจับตำแหน่งวัตถุได้สูงสุด $M$ วัตถุต่อภาพ 
เราต้องการเอาต์พุตเป็นเทนเซอร์ขนาดอย่างน้อย $5 M$
นั่นคือ สำหรับแต่ละการตรวจจับตำแหน่งวัตถุ โยโล่จะใช้ $5$ ค่า เพื่อระบุด้วยพิกัดของจุดศูนย์กลางและขนาดของ\textit{กล่องขอบเขต} ($x, y, w, h$ สำหรับพิกัดแนวนอนและแนวตั้ง ความกว้างและความสูง) พร้อมด้วยค่าความมั่นใจว่าภายในกล่องมีวัตถุอยู่.
ค่าความมั่นใจนี้ (confidence ใช้สัญกรณ์ $C$) มีเพื่อที่ช่วยให้ผลการทำนายสามารถยืดหยุ่นจำนวนวัตถุในภาพได้ ตั้งแต่ $0$ วัตถุ (ทุกตำแหน่งตรวจจับ มีค่าความมั่นใจต่ำหมด)
ไปจนถึง $M$ วัตถุ (ทุกตำแหน่งตรวจจับ มีค่าความมั่นใจสูงหมด).
อาจมองได้ว่า ค่าความมั่นใจ ทำหน้าที่เป็นเหมือนสวิตช์ปิดเปิดกล่องขอบเขต ว่าจะเลือกผลลัพธ์กล่องไหนบ้างให้ออกไป.

เพื่อให้การฝึกโครงข่ายทำได้อย่างมีประสิทธิิภาพ 
โยโล่ กำหนดพื้นที่รับผิดชอบของแต่ละตำแหน่งตรวจจับ.
การกำหนดพื้นที่รับผิดชอบของตำแหน่งตรวจจับ จำนวน $M$ ตำแหน่งตรวจจับ เทียบเท่ากับการแบ่งพื้นที่รับผิดชอบของภาพอินพุตออกเป็น $M$ ส่วน.
โยโล่แบ่งพื้นที่ภาพตามแนวนอนและแนวตั้งอย่างละเท่า ๆ กัน 
และเรียกการแบ่งนี้เป็นเสมือนช่องตาราง หรือ กริด (grid) และเรียกพื้นที่รับผิดชอบแต่ละส่วนว่า กริดเซลล์ (grid cell).
รูป~\ref{fig: Yolo Grid} แสดงแนวคิดนี้ ในรูปแสดงการแบ่งรูปออกเป็น $7 \times 7$ ส่วน ($M = 49$).
การกำหนดกริดเซลล์ให้รับผิดชอบพื้นที่อินพุตส่วนไหน ช่วยให้การฝึกทำได้มีประสิทธิภาพมากขึ้น 
โดยลดความสับสนว่า วัตถุควรจะถูกทายด้วยกริดเซลล์ไหน.
มันจะช่วยให้ การกำหนดฟังก์ชันสูญเสีย และการทำเฉลย ทำได้ง่ายขึ้น
เพราะถ้าไม่กำหนดความรับผิดชอบให้แน่นอน กริดเซลล์ใด ๆ หนึ่งใน $M$ กริดเซลล์ อาจทายวัตถุก็ได้
และการคำนวณค่าฟังก์ชันสูญเสียจะยุ่งยากมาก.
(ในระหว่างการฝึก ซึ่งการทายอาจจะยังผิดเพี้ยนอยู่มาก มันจะยากที่จะรู้ว่ากริดเซลล์ไหนที่กำลังทายเฉลยวัตถุไหน
และยังอาจมีกรณีที่ กริดเซลล์มากกว่าหนึ่งตัว พยายามทายวัตถุเดียวกันอีก.)

%
\begin{figure}
	\begin{center}
		\includegraphics[width=3in]{07ConvApp/BabyKangarooGrid.png}
		\caption[โยโล่ใช้เอาต์พุตที่มีโครงสร้างเทียบเท่าการแบ่งส่วนภาพอินพุต]{
			โยโล่ใช้เอาต์พุตที่มีโครงสร้างเป็น $G \times G$ ส่วน ซึ่งตัวอย่างนี้คือ $7 \times 7$ 
			และกำหนดให้แต่ละส่วนแบ่งขอบเขตรับผิดชอบอินพุต
			ซึ่งเทียบเท่าการแบ่งส่วนภาพอินพุตเป็น $7 \times 7$ ส่วน (โยโล่เรียก แต่ละส่วนว่า กริดเซลล์). แต่ส่วนถูกรับผิดชอบด้วยแต่ละกริดเซลล์ โดยหนึ่งกริดเซลล์ (หนึ่ง``พิกเซล''ในเอาต์พุต) จะมีค่าต่าง ๆ สำหรับระบุตำแหน่งการตรวจจับและชนิดวัตถุ. 
%			ในกรณีคือ หนึ่งกริดเซลล์ $30$ ค่า สำหรับกล่องขอบเขตสองกล่อง (แต่ละกล่อง ใช้ $5$ ค่าสำหรับพิกัดแกนนอนแกนตั้ง ความกว้าง ความสูง และค่าความมั่นใจ) และสำหรับชนิดวัตถุ $20$ ชนิด (รวม $5 \cdot 2 + 20 = 30$ ค่า).
%			เวกเตอร์ $30$ ค่า ทำนายตำแหน่งและขนาดของกล่องขอบเขตและชนิดวัตถุภายในพื้นที่รับผิดชอบ. 
%			หมายเหตุ โยโล่ จะปรับขนาดภาพอินพุตก่อน ในกรณีภาพอินพุตถูกปรับขนาดเป็น $448 \times 448$.			
		}
		\label{fig: Yolo Grid}
	\end{center}
\end{figure}
%

% Anchor Box
การกำหนดให้แต่ละกริดเซลล์ทายได้เพียงหนึ่งวัตถุ จะจำกัดความสามารถของการตรวจจับภาพวัตถุ
โดยเฉพาะกรณีที่วัตถุซ้อนท้บกันและมีจุดศูนย์กลางอยู่ใกล้กัน (ทำให้วัตถุตกอยู่ในความรับผิดชอบของกริดเซลล์เดียวกัน).
หลาย ๆ ครั้ง วัตถุที่ซ้อนทับกันนั้น อาจมีขนาดหรือรูปทรงที่แตกต่างกัน ทำให้ แม้จะทับซ้อนกัน ก็สามารถเห็นวัตถุต่าง ๆ ที่ทับซ้อนกันได้อย่างชัดเจน.
รูป~\ref{fig: example shows need for anchor box} แสดงตัวอย่างกรณีดังกล่าว.

%
\begin{figure}
	\begin{center}
		\includegraphics[width=3in]{07ConvApp/DiverShark.png}
		\caption[ตัวอย่างแสดงกรณีสำหรับเทคนิคกล่องสมอ]{ตัวอย่างแสดงกรณีสำหรับเทคนิคกล่องสมอ.
ในภาพ นักดำน้ำที่อยู่ด้านหน้า และฉลามที่อยู่ด้านหลัง มีจุดศูนย์กลางของกล่องขอบเขตอยู่ตำแหน่งเดียวกัน.
หากกำหนดให้การทายวัตถุสามารถทำได้เพียงหนึ่งวัตถุต่อกริดเซลล์ ความสามารถของระบบจะถูกจำกัดอย่างมากในกรณีนี้เช่นนี้.
สังเกตว่า แม้วัตถุจะทับซ้อนกันและมีจุดศูนย์กลางเดียวกันแต่ไม่ได้บังกันสนิท 
เนื่องจากวัตถุต่าง ๆ ที่ทับซ้อนกัน อาจมีขนาดหรือรูปทรงที่แตกต่างกัน.
กล่องขอบเขตในภาพ แสดงการทับซ้อนและการมีจุดศูนย์กลางใกล้เคียงกัน(อาจจะสังเกตได้ยาก) แต่มีขนาดและรูปทรงแตกต่างกันของวัตถุที่ทับซ้อนกัน 
(กล่องสีเขียว ตรวจจับนักดำน้ำ ส่วนกล่องสีเหลืองตรวจจับฉลาม).
}
		\label{fig: example shows need for anchor box}
	\end{center}
\end{figure}
%

วิธีแก้ไขเบื้องต้นคือ 
แทนที่จะให้แต่ละกริดเซลล์ทำนายตำแหน่งวัตถุได้แค่หนึ่งอัน ก็แค่อนุญาตให้หนึ่งกริดเซลล์ทำนายตำแหน่งวัตถุได้หลาย ๆ ตำแหน่ง โดยแต่ละการทายก็มีค่าความมั่นใจของตัวเอง.
เพียงแต่ ในการฝึก การคำนวณค่าฟังก์ชันสูญเสียจะจัดการให้มีประสิทธิภาพได้อย่างไร.
วิธีการที่ออกแบบมาเพื่อบรรเทาประเด็นนี้ คือ เทคนิค\textbf{กล่องสมอ} (anchor box\cite{FasterRCNN2015}).
\index{english}{anchor box}
\index{thai}{เทคนิคกล่องสมอ}

\paragraph{เทคนิคกล่องสมอ.} 
การทายตำแหน่งแต่ละกล่อง ในกริดเซลล์ จะเรียกว่า \textit{กล่องสมอ} 
โดยหนึ่งกริดเซลล์ สามารถทำนาย\textit{กล่องสมอ}ได้ $B$ กล่อง
และ \textit{กล่องสมอ}แต่ละกล่อง จะถูกกำหนดค่าเริ่มต้นให้มีขนาดหรือสัดส่วนต่างกัน.
การฝึก จะใช้ค่า\textit{ไอโอยู}ระหว่าง\textit{กล่องสมอ}กับเฉลย เป็นดัชนีกำหนดว่า \textit{กล่องสมอ}ใดจะรับผิดชอบเฉลยวัตถุใด (และอาจมีกฎในการกำหนดความรับผิดชอบในกรณีที่ค่า\textit{ไอโอยู}บังเอิญเท่ากัน).
\index{thai}{ไอโอยู}
\index{english}{IoU}
%เนื่องจากขนาดหรือสัดส่วนของ\textit{กล่องสมอ}แตกต่างกัน 
%เวลาฝึก ก็สามารถกำหนดให้ \textit{กล่องสมอ}ที่มีค่า\textit{ไอโอยู}สูงสุดสำหรับผิดชอบเฉลย
รูป~\ref{fig: Yolo anchor boxes} แสดงการใช้งานเทคนิคกล่องสมอในโยโล่.

%ซึ่งการจับคู่ระหว่าง\textit{กล่องสมอ}กับเฉลย
%อาจทำโดยเลือกจับคู่ คู่ที่มีค่า\textit{ไอโอยู}สูงสุดก่อน.
%แล้วไล่ลงมาสำหรับเฉพาะกับ\textit{กล่องสมอ}และเฉลยที่ยังไม่ถูกจับคู่กับใคร.

%
\begin{figure}
	\begin{center}
		\includegraphics[width=6in]{07ConvApp/BabyKangarooAnchorBox1.png}
		\caption[โยโล่เลือกกล่องสมอเพื่อรับผิดชอบวัตถุ]{
			โยโล่เลือกกล่องสมอเพื่อรับผิดชอบวัตถุ.
			ภาพซ้ายสุด แถวล่าง แสดงภาพอินพุต และส่วนรับผิดชอบต่าง ๆ พร้อมทั้งเฉลย (แสดงด้วยพื้นที่โปร่งใสสีแดง).
			ในภาพ สังเกต จุดศูนย์กลางของเฉลย จะตกอยู่ภายในกริดเซลล์ที่หกจากซ้ายและสี่จากบน และโยโล่จะใช้กริดเซลล์นี้รับผิดชอบเฉลย.
			ภาพซ้าย แถวบน แสดงเอาต์พุตขณะก่อนฝึก ที่แต่ละกริดเซลล์จะเป็นเวกเตอร์ทำนายกล่องสมอสองกล่อง (\texttt{B1} และ \texttt{B2} ในกริดเซลล์ที่รับผิดชอบเฉลย).
			%หากจุดศูนย์กลางของเฉลยตกอยู่ภายในบริเวณรับผิดชอบของกริด กริดนั้นจะทำนายค่าวัตถุนั้น
			กล่องสมอแต่ละตัวประกอบด้วยค่าตำแหน่งและขนาดกล่องขอบเขต ค่าความมั่นใจ และชนิดวัตถุ (ชนิดวัตถุ ระบุด้วยค่าความน่าจะเป็นของชนิดต่าง ๆ เตรียมไว้).
			ภาพล่างกลาง แสดงตัวอย่างของกล่องสมอก่อนเริ่มฝึก เมื่อเทียบกับเฉลย.
			กล่องสมอ ภายในกริดเซลล์เดียวกัน จะถูกกำหนดค่าเริ่มต้นให้มีขนาดหรือรูปทรงแตกต่างกัน.
			ขนาดหรือรูปทรงที่แตกต่างกัน ทำให้ค่า\textit{ไอโอยู}ระหว่างกล่องสมอต่าง ๆ กับเฉลย ต่างกัน และสามารถใช้เป็นดัชนี เพื่อกำหนดความรับผิดชอบได้.
			ในภาพ \textit{ไอโอยู} (ซึ่งคือ สัดส่วนทับซ้อน) ระหว่างกล่องสมอ \texttt{B2} กับเฉลย มีค่ามากกว่า ค่าของกล่องสมอ \texttt{B1} กับเฉลย.
			ดังนั้น ในกระบวนการฝึก โยโล่จะกำหนดให้ กล่องสมอ \texttt{B2} รับผิดชอบเฉลย. 
			%และหากกล่องสมอ \texttt{B1} ไม่มีเฉลยที่ต้องรับผิดชอบ มันจะถูกปล่อยทิ้ง.
			ภาพบนขวา แสดงตัวอย่างเอาต์พุตหลังฝึกเสร็จ (กริดเซลล์ที่ดูแลเฉลย เปลี่ยนค่าเป็น \texttt{B1*} และ \texttt{B2*})
			โดยเมื่อการฝึกสมบูรณ์ ค่าความมั่นใจของกล่องสมอที่ไม่ได้รับผิดชอบเฉลยใด (\texttt{C1}) จะใกล้กับศูนย์ 
			และค่าความมั่นใจของกล่องสมอที่ทำงาน (\texttt{C2}) จะใกล้กับหนึ่ง.
			%ทำนองเดียวกัน ค่าความน่าจะเป็นของชนิดที่ถูกต้องจะใกล้กับหนึ่ง และชนิดอื่น ๆ จะใกล้กับศูนย์.
			ภาพขวาล่าง แสดงผลลัพธ์ เมื่อนำไปวาดทับกับอินพุต.
			สังเกตว่า กล่องสมอที่รับผิดชอบเฉลย จะปรับขนาดและรูปทรงตามเฉลย.
			ตัวอย่างนี้ กริดเซลล์มีเพียงเฉลยเดียว จึงมีเพียงกล่องสมอเดียวที่ถูกใช้.
			หากกริดเซลล์รับผิดชอบวัตถุสองวัตถุทับซ้อนกัน กล่องสมอทั้งสองก็จะถูกใช้งาน และเลือกจับคู่โดยอาศัยค่า\textit{ไอโอยู}เป็นดัชนี.
			%ในภาพ วาดทั้งสองบล็อก เพื่อให้เห็นว่าบล็อกที่ถูกทิ้งจะไม่ได้ถูกปรับค่า และคงตำแหน่งและรูปทรงเดิม.
			%ในขณะที่บล็อกที่ถูกเลือก จะปรับตำแหน่งและรูปทรงให้เข้ากับเฉลย.
			%ในทางปฏิบัติ ผลลัพธ์จะเลือกเฉพาะบล็อกที่ใช้งาน และจะไม่แสดงบล็อกที่ถูกทิ้งออกมา.
		}
		\label{fig: Yolo anchor boxes}
	\end{center}
\end{figure}
%

สำหรับการตรวจจับวัตถุในภาพได้ครอบคลุม $K$ ชนิดวัตถุ 
แต่ละกล่องสมอจะมี $5 + K$ ค่า สำหรับตำแหน่งและขนาดของกล่องขอบเขต ($x, y, w, h$), ค่าความมั่นใจว่ามีวัตถุอยู่ภายในกล่อง $C$,
และค่าความน่าจะเป็นของวัตถุแต่ละชนิด $p(1), \ldots, p(K)$.
ดังนั้น สำหรับ $M$ กริดเซลล์ และ $B$ กล่องสมอต่อกริดเซลล์ แล้ว เอาต์พุตของโยโล่ $\bm{Y} \in \mathbb{R}^{M \cdot B \cdot (5 + K)}$ หรือ $\bm{Y} = [\tilde{x}_{mb}, \tilde{y}_{mb}, \tilde{w}_{mb}, \tilde{h}_{mb}$ $, \hat{C}_{mb},$ $\hat{p}_{mb}(1), \ldots, \hat{p}_{mb}(K)]$ สำหรับ $m = 1, \ldots, M; b = 1, \ldots, B$. 

เพื่อให้การฝึกแบบจำลองทำได้มีประสิทธิภาพมากขึ้น
แทนที่จะให้แบบจำลองทำนายค่าพิกัดและขนาดของกล่องขอบเขตโดยตรง
ค่าที่แบบจำลองทำนาย $\tilde{x}_{mb}, \tilde{y}_{mb}, \tilde{w}_{mb}, \tilde{h}_{mb}$
จะถูกคำนวณไปเป็นค่าพิกัดและขนาดของกล่องขอบเขต ดังนี้ (ละตัวห้อยออก เพื่อความกระชับ)
\begin{eqnarray}
\hat{x} &=&  c_w \cdot \sigma(\tilde{x}) + c_x
\label{eq: YOLO x} \\
\hat{y} &=&  c_h \cdot \sigma(\tilde{y}) + c_y
\label{eq: YOLO y} \\
\hat{w} &=&  p_w \cdot \exp(\tilde{w})
\label{eq: YOLO w} \\
\hat{h} &=&  p_h \cdot \exp(\tilde{h})
\label{eq: YOLO h}
\end{eqnarray}
เมื่อ $\hat{x}$ กับ $\hat{y}$ เป็นพิกัดแนวนอนกับแนวตั้งของศูนย์กลางกล่องขอบเขตที่ทำนาย
และ $\hat{w}$ กับ $\hat{h}$ เป็นความกว้างกับความสูงของกล่องขอบเขตที่ทำนาย
โดย $\sigma(\cdot)$ คือฟังก์ชันซิกมอยด์ (มีค่าระหว่างศูนย์ถึงหนึ่ง),
$c_x$ กับ $c_y$ เป็นพิกัดมุมซ้ายบนของกริดเซลล์,
$c_w$ กับ $c_h$ เป็นความกว้างกับความสูงของกริดเซลล์,
และ $p_w$ กับ $p_h$ เป็นค่าฐานของความกว้างกับความสูงของกล่องสมอ.

สังเกตว่า ถ้า $\tilde{x}$ มีค่าบวกขนาดใหญ่มาก จะทำให้ $\hat{x}$ อยู่ขอบขวาของกริดเซลล์.
ถ้า $\tilde{x}$ มีค่าลบขนาดใหญ่มาก จะทำให้ $\hat{x}$ อยู่ขอบซ้ายของกริดเซลล์.
ถ้า $\tilde{x}$ มีค่าเป็นศูนย์ จะทำให้ $\hat{x}$ อยู่ตรงกลางของกริดเซลล์.
ความสัมพันธ์ระหว่างค่า $\tilde{y}$ กับ $\hat{y}$ ก็เป็นในทำนองเดียวกัน.
ส่วนถ้า $\tilde{w}$ มีค่าบวก จะทำให้ $\hat{w}$ กว้างกว่าค่าฐาน $p_w$.
ถ้า $\tilde{w}$ มีค่าลบ จะทำให้ $\hat{w}$ แคบกว่าค่าฐาน $p_w$.
ถ้า $\tilde{w}$ มีค่าศูนย์ จะทำให้ $\hat{w}$ กว้างเท่ากับค่าฐาน $p_w$.
ความสัมพันธ์ระหว่างค่า $\tilde{h}$ กับ $\hat{h}$ ก็เป็นในทำนองเดียวกัน.

ค่าฐานของแต่ละกล่องสมอ $p_w$ และ $p_h$ อาจเลือกกำหนดเองตามเห็นว่าเหมาะสม.
คณะของเรดมอน\cite{YOLO2} ใช้\textit{การจัดกลุ่มข้อมูล}ด้วยวิธี\textit{เค-มีนส์} (K-means)
\index{thai}{การจัดกลุ่มข้อมูล}\index{english}{clustering}\index{thai}{เค-มีนส์}\index{english}{K-means}
\index{thai}{การจัดกลุ่มข้อมูล!เค-มีนส์}\index{english}{clustering!K-means}
สำรวจกล่องขอบเขตเฉลยของข้อมูลฝึกหัด
แล้วใช้ค่า\atom{\textit{เซนทรอยด์}}
ต่าง ๆ (centroids) ที่ได้มา เป็นค่าฐานของกล่องสมอต่าง ๆ.

โยโล่ นิยาม ค่าความมั่นใจ $\hat{C} = \mathrm{Pr}(\mbox{Object}) \cdot \mathrm{IOU}$
เมื่อ $\mathrm{Pr}(\mbox{Object})$ แทนค่าความน่าจะเป็นที่กล่องขอบเขตจะมีวัตถุ
และ $\mathrm{IOU}$ แทนค่า\textit{ไอโอยู}ระหว่างกล่องขอบเขตที่ทายกับกล่องขอบเขตเฉลย.
ดังนั้นค่าความมั่นใจเฉลย $C = 0$ ถ้าไม่มีวัตถุอยู่ภายในกริดเซลล์
และ $C = \mathrm{IOU}$ ถ้ามีวัตถุอยู่ภายในกริดเซลล์.

ในการฝึกการตรวจจับวัตถุในภาพ โยโล่กำหนดฟังก์ชันสูญเสียดังนี้
%\begin{eqnarray}
%\mathrm{loss} &=& \sum_{m=1}^M \sum_{b=1}^B \lambda_{\mathrm{coord}} \bm{1}_{mb}^{\mathrm{obj}} \cdot \left( (\hat{x}_{mb} - x_{mb})^2 + (\hat{y}_{mb} - y_{mb})^2 (\sqrt{\hat{w}_{mb}} - \sqrt{w_{mb}})^2 + (\sqrt{\hat{h}_{mb}} - \sqrt{h_{mb}})^2 \right)
%\nonumber \\
%&\;&
%+ \bm{1}_{mb}^{\mathrm{obj}} 
%\cdot \left( \hat{C}_{mb} - C_{mb} \right)^2
%\nonumber \\
%&\;&
%+ \bm{1}_{mb}^{\mathrm{obj}} \cdot \sum_{k \in \mathrm{classes}} 
%\cdot \left( \hat{p}_{mb}(k) - p_{mb}(k) \right)^2
%\nonumber \\
%&\;&
%+ \lambda_{\mathrm{noobj}} \bm{1}_{mb}^{\mathrm{noobj}} 
%\cdot \left( \hat{C}_{mb} - C_{mb} \right)^2
%\label{eq: YOLO loss function}
%\end{eqnarray}
%
%
\begin{eqnarray}
\mathrm{loss} &=& \lambda_{\mathrm{coord}} \sum_{m=1}^M \sum_{b=1}^B \bm{1}_{mb}^{\mathrm{obj}} \cdot \left( (\hat{x}_{mb} - x_{mb})^2 + (\hat{y}_{mb} - y_{mb})^2 \right)
\nonumber \\
&\;&
+ \lambda_{\mathrm{coord}} \sum_{m=1}^M \sum_{b=1}^B \bm{1}_{mb}^{\mathrm{obj}} \cdot \left( (\sqrt{\hat{w}_{mb}} - \sqrt{w_{mb}})^2 + (\sqrt{\hat{h}_{mb}} - \sqrt{h_{mb}})^2 \right)
\nonumber \\
&\;&
+ \sum_{m=1}^M \sum_{b=1}^B \bm{1}_{mb}^{\mathrm{obj}} 
\cdot \left( \hat{C}_{mb} - C_{mb} \right)^2
%&\;&
+ \lambda_{\mathrm{noobj}} \sum_{m=1}^M \sum_{b=1}^B \bm{1}_{mb}^{\mathrm{noobj}} 
\cdot \left( \hat{C}_{mb} - C_{mb} \right)^2
\nonumber \\
&\;&
+ \sum_{m=1}^M \sum_{b=1}^B  \bm{1}_{mb}^{\mathrm{obj}} \cdot \sum_{k \in \mathrm{classes}} 
\cdot \left( \hat{p}_{mb}(k) - p_{mb}(k) \right)^2
\label{eq: YOLO loss function}
\end{eqnarray}
เมื่อ 
%$\tilde{x}$, $\tilde{y}$, $\tilde{w}$, $\tilde{h}$ คือตัวอย่างเฉลย (annotated ground truth) เป็นพิกัดและขนาดของกล่องขอบเขต
%และ
$p_{mb}(k)$ คือเฉลยชนิดวัตถุที่กริดเซลล์ $m$ กล่องสมอ $b$
โดย $p_{mb}(k) = 1$ ถ้าที่กล่องสมอ มีภาพวัตถุชนิด $k$
และ $p_{mb}(k) = 0$ ถ้าที่กล่องสมอ มีภาพวัตถุชนิดอื่น.
%สัญญลักษณ์ $\bm{1}_{ij}^{\mathrm{obj}}$ ระบุว่าวัตถุปรากฏอยู่ในกริด $ij$.
สัญกรณ์ $\bm{1}_{mb}^{\mathrm{obj}}$ ใช้ระบุว่ากล่องสมอ $b$ ในกริดเซลล์ $m$ รับผิดชอบการทาย
นั่นคือ $\bm{1}_{mb}^{\mathrm{obj}} = 1$ เมื่อ กล่องสมอ $b$ ในกริดเซลล์ $m$ มีเฉลยที่รับผิดชอบอยู่
ถ้าไม่อย่างนั้นให้ $\bm{1}_{mb}^{\mathrm{obj}} = 0$.
โยโล่กำหนดการรับผิดชอบของกล่องสมอ
โดยให้กล่องสมอที่มีค่า\textit{ไอโอยู}ร่วมกับกรอบตัวอย่างเฉลยมากที่สุด ทำหน้าที่รับผิดชอบการทายเฉลยนั้น. 
%(ยกเว้น กล่องสมอนั้นจะถูกจับคู่กับเฉลยอื่นไปก่อนแล้ว).
สัญกรณ์ $\bm{1}_{mb}^{\mathrm{noobj}}$ ใช้ระบุว่ากล่องสมอ $b$ ในกริดเซลล์ $m$ ไม่มีวัตถุอยู่
ซึ่ง $\bm{1}_{mb}^{\mathrm{noobj}} = 1 - \bm{1}_{mb}^{\mathrm{obj}}$.

เนื่องจาก คณะของเรดมอน\cite{YOLO1} พบว่า ภาพต่าง ๆ ที่ใช้ฝึก ส่วนใหญ่มีวัตถุอยู่ไม่มาก.
กล่องสมอส่วนใหญ่ไม่มีวัตถุ และสัดส่วนการไม่มีวัตถุต่อการมีวัตถุสูงมาก (ข้อมูลไม่สมดุลย์ unbalanced data.\index{thai}{สัดส่วนข้อมูลไม่สมดุล}\index{english}{unbalanced data} แบบฝึกหัด~\ref{ex: binding affinity}).
ดังนั้น คณะของเรดมอน เลือกใช้แนวทางหนึ่งที่นิยมใช้บรรเทาปัญหาเช่นนี้ คือใช้ค่าน้ำหนักที่ต่างกันเพื่อชดเชย.
ค่า $\lambda_{\mathrm{coord}}$ และ $\lambda_{\mathrm{noobj}}$ เป็นเพียงเทคนิคเชิงเลข
เพื่อชดเชยความไม่สมดุลย์ของข้อมูล
(ซึ่งคณะของเรดมอน เลือกใช้ $\lambda_{\mathrm{coord}} = 5$ และ $\lambda_{\mathrm{noobj}} = 0.5$).

สังเกตว่า การคำนวณค่าผิดพลาดของความกว้างและความสูง ทำผ่านค่ารากที่สอง.
เนื่องจาก ค่าผิดพลาดสัมบูรณ์ ของการทำนายขนาดสำหรับกล่องขอบเขตขนาดเล็ก
แม้ตัวเลขจะเท่ากับค่าผิดพลาดสัมบูรณ์ ของการทำนายขนาดสำหรับกล่องขอบเขตขนาดใหญ่
แต่ถือเป็นความผิดพลาดที่รุนแรงกว่า.
ตัวอย่างเช่น การทายความกว้างผิดไป $10$ สำหรับความกว้าง $500$ นั้นถือว่าเล็กน้อยมาก จนผู้ใช้อาจไม่ได้เห็นความแตกต่าง
แต่ การทายความกว้างผิดไป $10$ สำหรับความกว้าง $5$ นั้นถือว่าผิดพลาดรุนแรงมาก และผลลัพธ์ก็เห็นได้อย่างชัดแจ้ง.
คณะของเรดมอน\cite{YOLO1} ใช้เทคนิคเชิงเลข โดยคำนวณความแตกต่างของค่ารากที่สองแทน เพื่อช่วยบรรเทาปัญหานี้.

ในกระบวนการฝึก คณะของเรดมอน\cite{YOLO1} ใช้\textit{การฝึกก่อน}
\index{thai}{การฝึกก่อน}\index{english}{pre-training}
โดยฝึกแบบจำลองกับงาน\textit{จำแนกชนิดวัตถุหลักในภาพ}ก่อนจนแบบจำลองทำงานได้ดีแล้ว.
จากนั้นจึงเพิ่มชั้นคำนวณท้าย ๆ (ด้านเอาต์พุต) เข้าไปแล้วจึงฝึกแบบจำลองสำหรับภาระกิจ\textit{การตรวจจับวัตถุในภาพ}.

หลังจากฝึกเสร็จ ในการงานอนุมาน
ค่าเอาต์พุตจะถูกนำมาประมวลผล 
โดยค่าของกล่องสมอที่ $\hat{C} > \tau$ จะถูกนำมาคำนวณตำแหน่งและขนาดของกล่องขอบเขต (สมการ~\ref{eq: YOLO x}, \ref{eq: YOLO y}, \ref{eq: YOLO w}, \ref{eq: YOLO h})
และวัตถุจะถูกอนุมานเป็นชนิด $k^\ast = \arg\max_k \hat{p}(k)$
เมื่อ $\tau$ เป็นระดับค่าขีดแบ่งที่กำหนด.
\index{english}{thresholding}

%เช่นเดียวกับภารกิจการตรวจจับภาพวัตถุทั่วไป 
%ขั้นตอนสุดท้าย
%ก่อนรายงานค่ากล่องขอบเขต $x'$, $y'$, $w'$, $h'$ และชนิด $k^\ast$ ของกรอบที่ผ่าน\textit{ขีดแบ่ง}
%ก็คือการทำ\textit{การลดการซ้ำซ้อน} (redundancy removal).
%โยโล่ทำ\textit{การลดการซ้ำซ้อน}ด้วย\textit{วิธีระงับค่าไม่มากที่สุด} (non-maximum suppression).
%\textit{วิธีระงับค่าไม่มากที่สุด}จะเปรียบเทียบ\textit{กล่องขอบเขต}ทีละคู่ 
%โดย\textit{กล่องขอบเขต}ที่อนุมานวัตถุชนิดเดียวกัน และมีบริเวณตรวจจับซ้อนทับกันมาก จะถือว่าเป็นการตรวจจับที่ซ้ำซ้อน (ตรวจพบวัตถุเดียวกัน).
%เมื่อพบการตรวจจับซ้ำซ้อน
%\textit{กล่องขอบเขต}ที่ความน่าจะเป็น $p'(k)$ มากที่สุดจะถูกรายงาน
%ส่วน\textit{กล่องขอบเขต}อื่น ที่ค่าความน่าจะเป็นไม่มากที่สุด จะถือว่าเป็นการตรวจพบซ้ำซ้อน
%และไม่ถูกรายงาน.
%
%การวัดปริมาณบริเวณทับซ้อนจะวัดด้วย\textit{ไอโอยู} (IOU, ย่อจาก Intersection Over Union) ซึ่งสำหรับบริเวณ $A$ และบริเวณ $B$
%ค่า $\mathrm{IOU} = \frac{A \cap B}{A \cup B}$.
%
%ในส่วนของการหาค่าพารามิเตอร์ 
%ค่าที่เหมาะสมของพารามิเตอร์ $\bm{\theta}$ 
%จะสามารถหาได้จากค่าที่ทำให้\textit{ฟังก์ชันสูญเสีย}มีค่าน้อยที่สุด.
%นั่นคือ $\bm{\theta} = \arg\min_{\bm{\theta}} \mathrm{loss}$.
%
%
%ภารกิจคือการทายค่า\textit{กล่องขอบเขต}จากภาพ.
%ประสบการณ์ได้จากตัวอย่างข้อมูลภาพและ\textit{กล่องขอบเขต}ที่สอดคล้องกัน.
%สมถนะวัดได้จากค่าฟังก์ชันสูญเสีย.

%นั่นคือ สำหรับ\textit{กล่องขอบเขต} 
%$\bm{f}_a = [x_a, y_a, w_a, h_a, p(c_1^{(a)}), \ldots, p(c_K^{(a)})]^T$
%กับ
%$\bm{f}_b = [x_b, y_b, w_b, h_b, p(c_1^{(b)}), \ldots, p(c_K^{(b)})]^T$
%ที่ทั้ง $C_a > \tau$ และ $C_b > \tau$
%แล้ว
%ถ้าค่า\textit{ไอโอยู}(IOU, ย่อจาก Intersect Over Union) ของกรอบ $\bm{f}_a$ และกรอบ $\bm{f}_b$ มีค่ามากกว่าค่าที่กำหนด
%จะถือว่ากรอบ $\bm{f}_a$ และกรอบ $\bm{f}_b$ ซ้ำซ้อน.
%เมื่อพบว่ากรอบ $\bm{f}_a$ และกรอบ $\bm{f}_b$ ซ้ำซ้อน
%\textit{วิธีระงับค่าไม่มากที่สุด}จะปรับค่า $p(c_k^{(a)}) = 0$ ถ้าหาก $p(c_k^{(a)}) < p(c_k^{(b)})$
%ไม่อย่างนั้นก็จะปรับค่า $p(c_k^{(b)}) = 0$ สำหรับแต่ละค่า $k$.
%หลังจากผ่านกระบวนการ\textit{วิธีระงับค่าไม่มากที่สุด}
%โยโล่จะรายงานเฉพาะ\textit{กล่องขอบเขต}ที่
%
%\begin{eqnarray}
%p(c_1) \cdot C
%\end{eqnarray}


%See explanation why train on 224x224 and use on 448x448 on cs231n (Winter 2016, Lecture 8, at about 18:39, explaining Overfeat, but I think it's the same idea.)
%
%(Fast R-CNN at about 44, this may inspire YOLO grid idea)
%
%(Faster R-CNN at about minute 50 has anchors, which may be similar to YOLO bounding boxes. Each anchor corresponds to different shape.)
%
%(YOLO is at 1:01:20.)

%\subsubsection{Training YOLO}
%
%We can simplify the YOLO loss function as,
%\begin{eqnarray}
%\mathrm{Cost} &=& \lambda_{\mathrm{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^B \mathbf{1}_{ij}^{\mathrm{obj}} \cdot \left( (x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2 \right)^2
%\nonumber \\
%&\;&
%+ \lambda_{\mathrm{coord}} \sum_{i=0}^{S^2} \sum_{j=0}^B \mathbf{1}_{ij}^{\mathrm{obj}} \cdot \left( (\sqrt{w_i} - \sqrt{\hat{w}_i})^2 + (\sqrt{h_i} - \sqrt{\hat{h}_i})^2 \right)^2
%\nonumber \\
%&\;&
%+ \sum_{i=0}^{S^2} \sum_{j=0}^B \mathbf{1}_{ij}^{\mathrm{obj}} 
%\cdot \left( 1 - \hat{C}_{ij} \right)^2
%\nonumber \\
%&\;&
%+ \sum_{i=0}^{S^2} \mathbf{1}_{i}^{\mathrm{obj}} \cdot \sum_{c \in \mathrm{classes}} 
%\cdot \left( p_i(c) - \hat{p}_i(c) \right)^2
%\nonumber \\
%&\;&
%+ \lambda_{\mathrm{noobj}} \sum_{i=0}^{S^2} \sum_{j=0}^B \mathbf{1}_{ij}^{\mathrm{noobj}} 
%\cdot \left( 0 - \hat{C}_{ij} \right)^2
%\label{eq: loss function 2}
%\end{eqnarray}
%where 
%variables $x_i, y_i, w_i, h_i$ represent coordinates of the center, width, and height of the ground truth object responsible by the $i$th cell.
%Variable 
%\begin{eqnarray}
%p_i(c)= \left\{
%\begin{array}{l l}
%0 & \quad \mbox{when ground truth object of class } c \mbox{ appears in cell } i,\\
%1 & \quad \mbox{when ground truth object of class } c \mbox{ does not appear in cell } i. 
%\end{array} \right.
%\nonumber
%\end{eqnarray}
%Variables $x_i, y_i \in [0,1]$ are in grid coordinate format.
%Variables $w_i, h_i \in [0,1]$ are relative to the image size.
%Term $\mathbf{1}_i^{\mathrm{obj}} \in \{0,1\}$ denotes if the ground truth object appears in cell $i$.
%Term $\mathbf{1}_{ij}^{\mathrm{obj}}  \in \{0,1\}$ denotes if the $j$th bounding box predictor in cell $i$ is responsible for the ground truth object.
%Term $\mathbf{1}_{ij}^{\mathrm{noobj}}  \in \{0,1\}$ denotes if the $j$th bounding box predictor in cell $i$ is not responsible for the ground truth object, $\mathbf{1}_{ij}^{\mathrm{noobj}} = 1 - \mathbf{1}_{ij}^{\mathrm{obj}}$.
%Variables $\hat{x}_i, \hat{y}_i, \hat{w}_i, \hat{h}_i, \hat{C}_{ij}$ are bounding box predictions for x-coordinate, y-coordinate, width, height, and confidence of the object appear in the grid cell. 
%Variable $\hat{p}_i(c)$ is a grid cell prediction for probability of an object of class $c$ appear in the cell. 

%\subsubsection{Coordination Conversion}
%
%Given an image of width $M$ and height $N$,
%\begin{eqnarray}
%X &=& M \cdot (x + g_x)/G_x
%%x = (predict.x + col)/7 * w
%\label{eq: global x}
%\\
%W &=& w^2 \cdot M
%%output.h = sqrt(gt.h/imwidth)
%\label{eq: global w}
%\end{eqnarray}
%where $X \in \{0, \ldots, M\}$ is an actual $x$-coordinate of the bounding box center,
%$x \in [0,1]$ is a prediction output,
%$g_x \in \{0, \ldots, G_x - 1\}$ is a grid index along $x$-direction,
%$G_x$ is a number of grid cell along $x$-direction,
%$W \in \{0, \ldots, M\}$ is an actual bounding box width,
%and $w \in [0,1]$ is a prediction bounding width.
%An actual $y$-coordinate, $Y$, and an actual height, $H$, can be calculated likewise.
%
%For example, given an image of $448\times224$, grid $(3, 12)$ of the $7\times14$ grid system has a prediction of a bounding box $(x=0.5,y=0.3,w=0.2,h=0.45)$.
%That bounding box can be mapped to an actual coordinate,
%\begin{eqnarray}
%X &=& 448 \cdot (0.5 + 3)/7 = 224
%\nonumber \\
%Y &=& 224 \cdot (0.3 + 12)/14 = 196.8 \approx 197
%\nonumber \\
%W &=& 0.2^2 \cdot 448 = 17.92 \approx 18
%\nonumber \\
%H &=& 0.45^2 \cdot 224 = 45.36 \approx 45
%\nonumber .
%\end{eqnarray}


%\section{การตรวจจับความสัมพันธ์ส่วนประกอบวัตถุในภาพ}
%\label{sec: part affinity}
%\index{Part Affinity Fields}
%
%\textit{วิธีส่วนสัมพรรคภาพ} (Part Affinity\cite{CSWS2017})
%
%Part Affinity Fields\cite{CaoEtAl2017}

% LATER
%\section{การเรียนรู้คุณลักษณะตัวแทน}
%\label{sec: representation learning}
%
%... facenet
%... จะไหวมั้ย

%FaceNet\cite{SchroffEtAl2015}


% LATER
%\section{การรู้จำส่วนภาพตามความหมาย}
%\label{sec: semantic segmentation}

%... จะไหวมั้ย
%
%
%\section{คุณสมบัติที่น่าแปลก}
%\label{sec: intriguing properties}
%\index{adversarial examples}



%{\small
%\begin{shaded}
%\paragraph{\small เกร็ดความรู้  ....}
%\index{side discourse}
%
%
%\begin{center}
%\begin{tabular}{ >{\arraybackslash}m{3.2in}  >{\arraybackslash}m{2.4in} }
%``dummy.''
%&
%``dummy''
%\\
%-- ...
%&
%-- ...
%\end{tabular} 
%\end{center}
%\index{words of wisdom}
%
%\end{shaded}
%}%small
%

% LATER
%\subsection{การติดตามวัตถุ}
%Object Tracking
%\label{sec: object tracking}
%
%following an object of interest within a sequence of images over time.
%Applications: surveillance camera and traffic monitoring

% LATER
%\subsection{Face Recognition}
%facenet

%\subsection{Pose estimation}
%action recognition
%
%gesture recognition

%\subsection{การแบ่งส่วนภาพตามความหมาย}
%semantic segmentation
%
%\cite{LongEtAl2015}

%\subsection{scene description}
%
%\cite{KarpathyFeiFei2015, JohnsonEtAl2016}
%\cite{VinyalsEtAl2015}

\section{การซ่อม เสริม และก่อกำเนิดภาพ}
\label{sec: convapp fix enhance gen images}

การซ่อมภาพ คือการเติมส่วนของภาพที่ต้องการ (ส่วนของภาพที่เสียหาย)
โดยคำนึงถึงบริเวณรอบข้าง และลักษณะของภาพโดยรวม.
การเสริมภาพ มีความหมายครอบคลุมการเพิ่มความละเอียดให้กับภาพ (หัวข้อ~\ref{sec: convapp increase resolution}).
การก่อกำเนิดภาพ คือการสร้างภาพขึ้นมาใหม่ทั้งภาพ โดยภาพที่สร้างขึ้นเป็นภาพในลักษณะที่ต้องการ 
เช่น ดูคล้ายภาพจริง (หัวข้อ~\ref{sec: convapp GAN}).

การซ่อม เสริม และก่อกำเนิดภาพ เป็นศาสตร์ที่กำลังได้รับความสนใจและมีการพัฒนาอย่างรวดเร็ว
มีหลายแนวทาง เช่น \textit{พิกเซลอาร์เอนเอน} (PixelRNN\cite{pixelRNN2016}),
\index{thai}{พิกเซลอาร์เอนเอน}\index{english}{PixelRNN}
\textit{ตัวเข้ารหัสอัตแบบเปลี่ยนแปลง} (Variational Autoencoder\cite{VAE2019}),
\index{thai}{ตัวเข้ารหัสอัตแบบเปลี่ยนแปลง}\index{english}{Variational Autoencoder}
หรือ\textit{โครงข่ายปรปักษ์เชิงสร้าง} (Generative Adversarial Network\cite{GoodfellowEtAl2014a, PalssonEtAl2018}).

ความท้าทายที่สำคัญสำหรับภาระกิจเช่นนี้ โดยเฉพาะการก่อกำเนิดภาพ 
คือ ตัวภาระกิจเป็นเสมือนการเรียนรู้ความน่าจะเป็นของภาพ 
(ไม่ว่าจะเรียนรู้ชัดแจ้งโดยตรง ซึ่งได้ค่า\textit{ฟังก์ชันความหนาแน่นความน่าจะเป็น}ออกมา หรือโดยนัย ซึ่งคือทำภาระกิจได้ แต่ไม่ได้ค่า\textit{ฟังก์ชันความหนาแน่นความน่าจะเป็น}).
จากมุมของปริภูมิมิติ ภาพเป็นจุดข้อมูลที่อยู่ในปริภูมิหลายมิติ ที่มีจำนวนมิติมหาศาล%
\footnote{%
ลักษณะภาระกิจที่การดำเนินการทำได้ไม่ยาก เมื่อมิติของปริภูมิมีจำนวนน้อย แต่ทำได้ยากมาก หรือไม่อาจทำได้เลยในทางปฏิบัติ 
หากมิติของปริภูมิมีจำนวนมาก มักถูกอ้างอิงถึงว่าเสมือนเป็น \textbf{คำสาปของมิติ} (curses of dimensionality).
\index{english}{curses of dimensionality}\index{thai}{คำสาปของมิติ}
}.
%
นั่นคือ ภาพสีขนาด $W \times H$ (สัญกรณ์ $\bm{X} \in \mathbb{R}^{3 \times W \times H}$)
แต่ละภาพเปรียบเสมือนจุดหนึ่งจุดในปริภูมิ $3 \cdot W  \cdot H$ มิติ.
การประมาณ\textit{ฟังก์ชันความหนาแน่นความน่าจะเป็น} $p(\bm{X})$ ทำได้ยากมาก และต้องการข้อมูลจำนวนมหาศาล.

\textit{โครงข่ายปรปักษ์เชิงสร้าง} จัดเป็นศาสตร์และศิลป์ที่สำคัญของการเรียนรู้ของเครื่อง 
ดังอภิปรายเกริ่นในบทที่~\ref{chapter: Deep Learning}
และ
ได้แสดงให้เห็นว่า \textit{โครงข่ายปรปักษ์เชิงสร้าง}เป็นแนวทางที่ช่วยแก้ปัญหาของภารกิจการก่อกำเนิดภาพได้.
หัวข้อ~\ref{sec: convapp GAN} อภิปราย\textit{โครงข่ายปรปักษ์เชิงสร้าง} รวมถึงอุปสรรคความท้าทายในการประยุกต์ใช้\textit{โครงข่ายปรปักษ์เชิงสร้าง} และแนวทางในการบรรเทาอุปสรรค.

\subsection{การเพิ่มความละเอียดให้กับภาพ}
\label{sec: convapp increase resolution}
การเพิ่มความละเอียดให้กับภาพ คือ กระบวนการที่รับภาพความละเอียดต่ำ (low-resolution image)
และประมาณภาพความละเอียดสูง (high-resolution) ออกมา.

การเพิ่มความละเอียดให้กับภาพ อาจทำได้หลายวิธี.
คณะของตง\cite{DongEtAl2014}
ทำการ\textit{อัพแซมปลิ้ง} (upsampling) ซึ่งคือการเพิ่มพิกเซลเข้าไปในภาพ โดยค่าพิกเซลที่เพิ่มขึ้นจะได้จากการทำ\textit{การประมาณค่าในช่วงแบบไบคิวบิก} (bicubic interpolation).
จากนั้นใช้โครงข่ายคอนโวลูชั่นในการประมาณภาพความละเอียดสูงออกมา (เพื่อปรับปรุงคุณภาพจากการประมาณค่าในช่วงแบบไบคิวบิก).

กล่าวคือ จากภาพความละเอียดต่ำ $\bm{\tilde{X}}$ 
คณะของตงสร้างภาพความละเอียดสูง $\bm{X}'$ ขึ้นด้วยวิธี\textit{การประมาณค่าในช่วงแบบไบคิวบิก}
แล้วใช้ $\bm{X}'$ เป็นอินพุตของโครงข่ายคอนโวลูชั่น เพื่อทำนาย $\bm{\hat{X}}$
(ซึ่ง แม้จะความละเอียดเท่ากัน แต่ $\bm{\hat{X}}$ มีคุณภาพดีกว่า $\bm{X}'$).
%
หาก $f$ คือฟังก์ชันที่แทนการคำนวณของโครงข่าย และ $\bm{\Theta}$ เป็นค่าพารามิเตอร์ต่าง ๆ ของโครงข่าย
โครงข่ายคอนโวลูชั่นถูกฝึกให้ทำนาย $\bm{\hat{X}} = f(\bm{X}'; \bm{\Theta})$ ให้ใกล้เคียงกับเฉลย (ที่เป็นภาพความละเอียดสูง) $\bm{X}$ ให้มากที่สุด.
นั่นคือ ฟังก์ชันสูญเสีย $\mathrm{loss}(\bm{\Theta}) = \frac{1}{N} \sum_{n=1}^N \| f(\bm{X}'_n; \bm{\Theta}) - \bm{X}_n \|^2$
เมื่อ $N$ คือจำนวนข้อมูลฝึกทั้งหมด.

คุณภาพของการเพิ่มความละเอียดให้กับภาพ อาจประเมินจาก 
\textit{ค่าผิดพลาดกำลังสองเฉลี่ย} เช่นเดียวกับภาระกิจการหาค่าถดถอยทั่วไป
เช่น $\mathrm{mse} = \frac{1}{W \cdot H} \sum_i \sum_j (\hat{x}_{i,j} - x_{i,j})^2$ 
เมื่อ $W$ กับ $H$ เป็นความกว้างกับสูงของภาพ
และ
$\hat{x}_{i,j}$ เป็นค่าพิกเซลของภาพที่เพิ่มความละเอียดขึ้นจากภาพความละเอียดต่ำ $\tilde{\bm{X}}$. 
โดย ภาพความละเอียดต่ำ $\tilde{\bm{X}}$ เป็นภาพที่ถูกลดความละเอียดลงจากภาพความละเอียดสูง $\bm{X}$.
ภาพความละเอียดสูง $\bm{X}$ มีค่าพิกเซลต่าง ๆ เป็น $x_{i,j}$ และ $i$ กับ $j$ คือ ดัชนีแนวนอนกับแนวตั้งของภาพ.
อย่างไรก็ดี แม้\textit{ค่าผิดพลาดกำลังสองเฉลี่ย}พอใช้งานได้ แต่นักวิจัยต่างพบว่า ค่าผิดพลาดกำลังสองเฉลี่ยไม่สัมพันธ์กับคุณภาพของภาพที่คนรับรู้\cite{WangEtAl2003a}.
คุณภาพของภาพจึงมักวัดด้วยดัชนีอื่น ๆ ได้แก่
อัตราส่วนสัญญาณสูงสุดต่อสัญญาณรบกวน (peak signal-to-noise ration คำย่อ PSNR\cite{WangEtAl2004a}),
ความคล้ายคลึงเชิงโครงสร้าง (structural similarity คำย่อ SSIM\cite{WangEtAl2004a}),
เงื่อนไขความเที่ยงตรง (fidelity criterion คำย่อ IFC\cite{SheikhEtAl2005}),
มาตราวัดคุณภาพสัญญาณรบกวน (noise quality measure คำย่อ NQM\cite{Damera-VenkataEtAl2000}),
อัตราส่วนสัญญาณสูงสุดปรับค่าน้ำหนักต่อสัญญาณรบกวน (weighted peak signal-to-noise ratio คำย่อ WPSNR\cite{WangEtAl2003a}),
หรือ ดัชนีความคล้ายคลึงเชิงโครงสร้างหลายสเกล (multi-scale  structure  similarity  index คำย่อ MSSSIM\cite{WangEtAl2003a}) เป็นต้น.
%, which obtain high correlation with the human perceptual scores as reported in \cite{YangEtAl2014a}

ต่างจากงานของตงและคณะ\cite{DongEtAl2014} 
%ที่อาศัย\textit{การประมาณค่าในช่วงแบบไบคิวบิก}
%ที่ช่วยปรับขนาดอินพุต (ซึ่งคือความละเอียดของอินพุต) ให้เป็นไปตามต้องการ 
%ก่อนจะปรับปรุงคุณภาพด้วยโครงข่ายคอนโวลูชั่น
คณะของชือ\cite{ShiEtAl2016a, ShiEtAl2016}
ใช้โครงข่ายคอนโวลูชั่น เพื่อเพิ่มความละเอียดให้กับภาพ โดยรับอินพุตเป็นภาพความละเอียดต่ำโดยตรง
และให้เอาต์พุตสุดท้ายออกมาเป็นภาพความละเอียดสูงได้เลย.
% โดยไม่ต้องอาศัย\textit{การประมาณค่าในช่วง}.
การใช้โครงข่ายคอนโวลูชั่นกับภาพความละเอียดต่ำโดยตรง ช่วยลดภาระการคำนวณลงไปได้มาก
และคณะของชือ ยังแสดงให้เห็นคุณภาพของผลลัพธ์ที่ดีขึ้นด้วย.

กลไกสำคัญที่ชือและคณะใช้ อยู่ที่ชั้นคำนวณท้ายสุด.
สำหรับภาพขนาด $W \times H$ (ช่องสีเดียว%
\footnote{%
ที่นี้ ยกตัวอย่างภาพช่องสีเดียว เพื่อความกระชับของเนื้อหา.
เทคนิคที่อธิบายนี้ สามารถประยุกต์ใช้กับภาพหลายช่องสี ได้อย่างตรงไปตรงมา.
}%
)
และต้องการขยายความละเอียดขึ้น $r$ เท่า (นั่นคือ ภาพจะถูกขยายเป็น ภาพผลลัพธ์ขนาด $r W \times r H$)
คณะของชือ ออกแบบโครงข่ายคอนโวลูชั่นที่ให้เอาต์พุตออกมา 
เป็น\textit{แผนที่ลักษณะสำคัญ}ขนาดเท่ากับขนาดภาพอินพุต 
แต่มีจำนวนแผนที่เท่ากับ $r^2$. 
แล้วภาพผลลัพธ์ จะสร้างขึ้นจากการจัดเรียง\textit{แผนที่ลักษณะสำคัญ}ขนาด $W \times H$ จำนวน $r^2$ แผ่นที่
ให้เป็นแผนที่เดียว ขนาด $r W \times r H$ ซึ่งคือภาพความละเอียดสูงที่ต้องการ.
กลไกของการจัดเรียงผลลัพธ์แผนที่สำคัญเช่นนี้ เรียกว่า กลไกพิกเซลย่อย
ซึ่งเป็นรูปหนึ่งของ\textit{ชั้นดีคอนโวลูชั่น} (deconvolution layer\cite{ZeilerEtAl2010}).
\index{thai}{ชั้นดีคอนโวลูชั่น}
\index{english}{deconvolution layer}
\textit{ชั้นดีคอนโวลูชั่น} อาจทำได้หลายรูปแบบ
ชือและคณะ\cite{ShiEtAl2016} แจกแจงและอภิปรายข้อแตกต่างของ\textit{ชั้นดีคอนโวลูชั่น}แบบต่าง ๆ.
รูป~\ref{fig: conv app deconvolution} แสดงจุดเด่น (รับอินพุตเป็นภาพความละเอียดต่ำ และให้เอาต์พุตเป็นภาพความละเอียดสูงได้โดยตรง)
และกลไกสำคัญ (ชั้นดีคอนโวลูชั่น ที่จัดเรียงแผนที่ลักษณะสำคัญ $r^2$ แผนที่ เป็นผลลัพธ์ ภาพเดียวที่เป็นมีความละเอียดเพิ่มเป็น $r$ เท่า).


%
\begin{figure}
	\begin{center}
		\includegraphics[width=6.8in]{07ConvApp/Deconvolution3.png}
		\caption[การขยายความละเอียดภาพด้วยชั้นดีคอนโวลูชั่น]{การขยายความละเอียดภาพด้วยชั้นดีคอนโวลูชั่น (ดัดแปลงจากชือและคณะ\cite{ShiEtAl2016a})}
		\label{fig: conv app deconvolution}
	\end{center}
\end{figure}
%
	
	
\subsection{โครงข่ายปรปักษ์เชิงสร้าง}
\label{sec: convapp GAN}
\index{english}{Generative Adversarial Network}\index{english}{GAN}	

\textbf{โครงข่ายปรปักษ์เชิงสร้าง}%
\footnote{%
เนื้อหาในหัวข้อนี้ ได้รับอิทธิพลหลัก ๆ จากเครสเวลและคณะ\cite{OverviewGAN2018}.
}
%
(Generative Adversarial Networks คำย่อ GANs)
หมายถึง \textit{โครงข่ายประสาทเทียม}ที่สามารถเรียนรู้ความน่าจะเป็นของข้อมูลที่มีจำนวนมิิติสูง ๆ และมีหลาย ๆ โหมดได้ (high-dimensional and multi-modal distribution)
โดยโครงข่ายถูกเตรียมด้วย\textit{วิธีการฝึกแบบปรปักษ์}.
ด้วยกลไก\textit{วิธีการฝึกแบบปรปักษ์} ที่ใช้\textit{การเรียนรู้แบบกึ่งมีผู้ช่วยสอน}และ\textit{การเรียนรู้แบบไม่มีผู้สอน}
\index{thai}{การเรียนรู้แบบกึ่งมีผู้ช่วยสอน}\index{english}{semi-supervised Learning}
\index{thai}{การเรียนรู้แบบไม่มีผู้สอน}\index{english}{unsupervised learning}
\textit{โครงข่ายปรปักษ์เชิงสร้าง}สามารถใช้ประโยชน์จากข้อมูลจำนวนมากที่ไม่มีฉลากเฉลยได้
ซึ่งข้อมูลจำนวนมากนั้น จำเป็นต่อการเรียนรู้ความน่าจะเป็นของข้อมูลที่มีจำนวนมิิติสูง ๆ (เช่น ข้อมูลรูปภาพ).

อย่างไรก็ตาม การเรียนรู้ความน่าจะเป็นของข้อมูลด้วย\textit{โครงข่ายปรปักษ์เชิงสร้าง}
อาจเป็นเพียงการเรียนรู้เชิงนัย นั่นคือ อาจไม่ได้ค่าความน่าจะเป็นหรือไม่ได้ฟังก์ชันความหนาแน่นความน่าจะเป็น.
นั่นคือ 
โครงข่ายอาจสามารถสังเคราะห์ หรือสร้างตัวอย่างข้อมูลขึ้นมาใหม่ได้ 
โดยตัวอย่างข้อมูลที่สร้างขึ้นมาใหม่ มีลักษณะในแบบเดียวกับตัวอย่างข้อมูลจริง (กล่าวคือ มีความเป็นไปได้สูงว่ามาจากการแจกแจงเดียวกัน).
หากข้อมูลที่กล่าวถึง คือภาพ
\textit{โครงข่ายปรปักษ์เชิงสร้าง} อาจสามารถสร้างตัวอย่างภาพขึ้นมาใหม่ ซึ่งภาพที่สร้างขึ้นนี้อาจดูเหมือนภาพถ่ายจริง
ซึ่งเบื้องหลังหมายถึงว่า โครงข่ายได้เรียนรู้การแจกแจงข้อมูลของภาพถ่ายจริง และสามารถสังเคราะห์ตัวอย่างข้อมูลจากการแจกแจงนั้นได้
แต่ฟังก์ชันการแจกแจงนั้น อาจไม่สามารถเข้าถึงได้โดยตรง.

\textbf{วิธีการฝึกแบบปรปักษ์}  (adversarial training)
\index{thai}{วิธีการฝึกแบบปรปักษ์}\index{english}{adversarial training}
มีลักษณะเด่น คือ การใช้โครงข่ายสองโครงข่ายในการฝึก และโครงข่ายทั้งสองถูกฝึกโดยมีเป้าหมายที่ขัดแย้งกัน.
%
คณะของกูดเฟโล\cite{GoodfellowEtAl2014a} เสนอ\textit{โครงข่ายปรปักษ์เชิงสร้าง} เพื่อสร้างตัวอย่างภาพต่าง ๆ ที่เหมือนภาพถ่ายจริงออกมา.
\textit{วิธีการฝึกแบบปรปักษ์} ใช้โครงข่ายสองโครงข่าย หนึ่งเรียกว่า \textbf{โครงข่ายแบ่งแยก} (discriminator ใช้สัญกรณ์ $\mathcal{D}$)
และอีกหนึ่ง เรียกว่า \textbf{โครงข่ายก่อกำเนิด} (generator ใช้สัญกรณ์ $\mathcal{G}$).
\index{thai}{โครงข่ายแบ่งแยก}\index{english}{discriminator}
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!โครงข่ายแบ่งแยก}\index{english}{GAN!discriminator}
\index{english}{generator}\index{thai}{โครงข่ายก่อกำเนิด}
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!โครงข่ายก่อกำเนิด}\index{english}{GAN!generator}
\textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ รับอินพุตเป็นภาพ และทำหน้าที่ทำนายว่า ภาพที่รับเข้ามาเป็นภาพถ่ายจริง หรือว่าเป็นภาพปลอม (ภาพที่สร้างขึ้น).
\textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ รับอินพุตเป็นค่าสุ่ม%
\footnote{%
ที่ต้องรับอินพุตเป็นค่าสุ่ม เพื่อให้\textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ เรียนรู้ที่จะสร้างเอาต์พุตที่หลากหลาย.
นั่นคือ อินพุตเป็นค่าหนึ่ง \textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ สร้างภาพหนึ่ง.
อินพุตเป็นอีกค่าหนึ่ง \textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ สร้างภาพอีกภาพหนึ่ง.
}
%
และทำหน้าที่สร้างภาพขึ้นมา.
ในกระบวนการฝึก
\textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ ถูกฝึก โดยมีเป้าหมายคือ การแแยกแยะให้ถูกต้องมากที่สุด
ในขณะที่\textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ ถูกฝึก โดยมีเป้าหมายคือ การสร้างภาพปลอมให้เหมือน
จน\textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ ทายถูกน้อยที่สุด.

%
\begin{figure}
\begin{center}
\includegraphics[width=6in]{07ConvApp/GAN/GAN.png}
\caption[วิธีการฝึกแบบปรปักษ์]{วิธีการฝึกแบบปรปักษ์. 
โครงข่ายก่อกำเนิด 
$\mathcal{G}$ (แสดงด้วยโครงข่ายเชื่อมต่อเต็มที่ มุมบนซ้าย) รับอินพุตเป็นเวกเตอร์ค่าสุ่ม $\bm{z}$
และให้เอาต์พุต $\bm{X}'$ ออกมา (ในภาพ แสดงเอาต์พุตถูกจัดเรียงใหม่เพื่อให้มีโครงสร้างเหมือนภาพจริง $\bm{X}$).
ภาพจริง $\bm{X}$ ถูกสุ่มออกมาจากชุดข้อมูล. 
โครงข่ายแบ่งแยก $\mathcal{D}$ (แสดงด้วยโครงข่ายคอนโวลูชั่น มุมล่างขวา)
รับอินพุตที่เป็นภาพ โดยโครงข่ายแบ่งแยกไม่รู้ว่าภาพอินพุตที่ได้ ถูกเลือกมาจากภาพจริง หรือภาพที่สร้างขึ้น
(การเลือกทำด้วยการสุ่ม) 
และ\textit{โครงข่ายแบ่งแยก}จะต้องทายว่าอินพุตที่เห็น เป็นภาพจริง หรือเป็นภาพที่สร้างขึ้น.
}
\label{fig: conv app GAN}
\end{center}
\end{figure}
%


รูป~\ref{fig: conv app GAN} แสดงแนวคิดของวิธีการฝึกแบบปรปักษ์ ซึ่งเป็นกลไกหลักของ\textit{โครงสร้างปรปักษ์เชิงสร้าง}.
%
ในการฝึก \textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ จะรับอินพุต เป็นภาพ ที่ถูกสุ่มขึ้นมา โดยภาพที่ได้อาจสุ่มจากภาพจริง หรืออาจสุ่มมาจากภาพปลอมที่สร้างโดย \textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$
แล้วให้ \textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ ทำนาย.
ผลของการทำนายผิดหรือถูก จะถูกนำไปปรับค่าน้ำหนักเพื่อให้ \textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ ทำงานได้ดีขึ้น แบ่งแยกได้ดีขึ้น (ทายถูกมากขึ้น)
และก็จะถูกนำไปปรับค่าน้ำหนัก \textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ เพื่อให้ $\mathcal{G}$ สร้างภาพได้ดีขึ้น (หลอก $\mathcal{D}$ ได้ดีขึ้น ทำให้ $\mathcal{D}$ ทายถูกน้อยลง).
หาก\textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ สามารถหลอก\textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ ได้โดยสมบูรณ์แล้ว
\textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ จะทายถูกได้ประมาณครึ่ง ๆ. 
นั่นคือ ถ้าภาพที่สร้างขึ้นเหมือนภาพจริง โอกาสคืิอเท่ากับเดาสุ่ม ซึ่งถ้าเดาดี ๆ โอกาสถูกคือแค่ประมาณ $0.5$ (หรือ $50\%$).
หมายเหตุ รูป~\ref{fig: conv app GAN} อาจแสดง\textit{โครงข่ายก่อกำเนิด}ด้วยโครงข่ายเชื่อมต่อเต็มที่
แต่การเปลี่ยนโครงสร้างไปเป็นโครงข่ายคอนโวลูชั่นก็สามารถทำได้ (ดู \cite{DCGAN, LAP-GAN} เพิ่มเติม).


การฝึก\textit{โครงข่ายปรปักษ์เชิงสร้าง} กล่าวโดยเจาะจงแล้วก็คือการแก้ปัญหาค่าดีที่สุด ในนิพจน์~\ref{eq: convapp GAN opt prob} ได้แก่
\begin{eqnarray}
\min_{\mathcal{G}} \max_{\mathcal{D}} V(\mathcal{G}, \mathcal{D})
\label{eq: convapp GAN opt prob}
\end{eqnarray}
เมื่อ
\begin{eqnarray}
V(\mathcal{G}, \mathcal{D}) &=& E_{\bm{X} \sim p_{data}}[\log \mathcal{D}(\bm{X})] 
+ E_{\bm{X} \sim p_{\mathcal{G}}}[\log(1 - \mathcal{D}(\bm{X}))]
\label{eq: convapp GAN obj function} 
\end{eqnarray}
โดย $\mathcal{D}(\bm{X}) \in (0,1)$
และ $\mathcal{D}(\bm{X}) \approx 1$ หมายถึง \textit{โครงข่ายแบ่งแยก}ทายว่า $\bm{X}$ เป็นภาพจริง
และ $\mathcal{D}(\bm{X}) \approx 0$ หมายถึง \textit{โครงข่ายแบ่งแยก}ทายว่า $\bm{X}$ เป็นภาพปลอมที่สร้างขึ้น.

พจน์ $E_{\bm{X} \sim p_{data}}[\log \mathcal{D}(\bm{X})]$
หมายถึง \textit{ค่าคาดหมาย}ของลอการิทึ่มของผลลัพธ์จาก\textit{โครงข่ายแบ่งแยก} เมื่ออินพุตของ\textit{โครงข่ายแบ่งแยก}มีการแจกแจงตามข้อมูลจริง (ดังระบุด้วยสัญกรณ์ $\bm{X} \sim p_{data}$)
หรือกล่าวง่าย ๆ คือ เมื่ออินพุตเป็นภาพจริง.
หาก\textit{โครงข่ายแบ่งแยก}ทำงานถูกต้องโดยสมบูรณ์ แล้ว $\mathcal{D}(\bm{X}) \approx 1$ สำหรับทุก ๆ ภาพจริง 
และ พจน์ $E_{\bm{X} \sim p_{data}}[\log \mathcal{D}(\bm{X})] \approx 0$.

ส่วนพจน์%
\footnote{%
คณะของกูดเฟโล\cite{GoodfellowEtAl2014a} ใช้พจน์ 
$E_{\bm{z} \sim p_z}[\log(1 - \mathcal{D}(\mathcal{G}(\bm{z})))]$
เมื่อ $\mathcal{G}(\bm{z})$ แทนภาพที่สร้างจากโครงข่ายก่อกำเนิดตามค่าสุ่ม $\bm{z}$ 
และ $E_{\bm{z} \sim p_z}$ หมายถึงค่าคาดหมายคำนวณตามการแจกแจงของตัวแปรสุ่ม.
แต่ ณ ที่นี้เขียนพจน์นี้ ตามเครสเวลและคณะ\cite{OverviewGAN2018}	
เพื่อความกระชับในการอธิบาย.
} 
%
$E_{\bm{X} \sim p_{\mathcal{G}}}[\log(1 - \mathcal{D}(\bm{X}))]$
แสดง\textit{ค่าคาดหมาย}ของลอการิทึ่มของ $1 - \mathcal{D}(\bm{X})$
เมื่ออินพุตของมีการแจกแจงตามการแจกแจงจาก\textit{โครงข่ายก่อกำเนิด}
(ดังระบุด้วยสัญกรณ์ $\bm{X} \sim p_{\mathcal{G}}$)
หรือกล่าวง่าย ๆ คือ เมื่ออินพุตถูกสร้างขึ้นจาก\textit{โครงข่ายก่อกำเนิด}.
หาก\textit{โครงข่ายแบ่งแยก}ทำงานถูกต้องโดยสมบูรณ์ แล้ว $\mathcal{D}(\bm{X}) \approx 0$ สำหรับทุก ๆ ภาพที่สร้างขึ้น 
และ พจน์ $E_{\bm{X} \sim p_{\mathcal{G}}}[\log(1 - \mathcal{D}(\bm{X}))] \approx 0$.
แต่หาก\textit{โครงข่ายแบ่งแยก} ทายผิด จะทำให้ได้ $\log(0) \rightarrow -\infty$ หรือทำให้ได้ค่าที่ต่ำมาก ๆ.

หมายเหตุ สัญกรณ์ที่ในนิพจน์~\ref{eq: convapp GAN opt prob} ใช้เพื่อความกระชับ.
เช่นเดียวกับการฝึกโครงข่ายประสาทเทียมอื่น ๆ 
การฝึก\textit{โครงข่ายก่อกำเนิด}และ\textit{โครงข่ายแบ่งแยก} ก็ดำเนินการผ่านการปรับค่าพารามิเตอร์ต่าง ๆ ของโครงข่าย.
นั่นคือ หากจะเขียนนิพจน์~\ref{eq: convapp GAN opt prob} ให้ละเอียดถูกต้องมากยิ่งขึ้น อาจเขียนเป็น
$\min_{\bm{\theta}} \max_{\bm{w}} V(\mathcal{G}_{\bm{\theta}}, \mathcal{D}_{\bm{w}})$
เมื่อ\textit{โครงข่ายก่อกำเนิด} $\mathcal{G}_{\bm{\theta}}$ 
และ\textit{โครงข่ายแบ่งแยก} $\mathcal{D}_{\bm{w}}$
ถูกควบคุมพฤติกรรมด้วยพารามิเตอร์ $\bm{\theta}$ และ $\bm{w}$ ตามลำดับ.
%$\min_{\bm{\theta}_\mathcal{G}} \max_{\bm{\theta}_\mathcal{D}} V(\mathcal{G}_{\bm{\theta}_\mathcal{G}}, \mathcal{D}_{\bm{\theta}_\mathcal{D}})$
%เมื่อ\textit{โครงข่ายก่อกำเนิด} $\mathcal{G}_{\bm{\theta}_\mathcal{G}}$ 
%และ\textit{โครงข่ายแบ่งแยก} $\mathcal{D}_{\bm{\theta}_\mathcal{D}}$
%ถูกควบคุมพฤติกรรมด้วยพารามิเตอร์ $\bm{\theta}_\mathcal{G}$ และ $\bm{\theta}_\mathcal{D}$ ตามลำดับ.


\textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ จะถูกฝึกเพื่อให้ค่าฟังก์ชันจุดประสงค์นี้สูงที่สุด
ผ่านกลไกการทำนาย $\mathcal{D}(\bm{X})$.
ในขณะที่
\textit{โครงข่ายก่อกำเนิด} จะพยายามทำให้ค่าฟังก์ชันจุดประสงค์นี้ต่ำที่สุด
โดยผ่านกลไก $\bm{X} \sim p_{\mathcal{G}}$ 
ซึ่งคือ การสร้างภาพให้เหมือนภาพจริงที่สุด หรือพยายามเรียนรู้ให้การแจกแจง $p_{\mathcal{G}}$ ใกล้เคียงกับ $p_{data}$ มากที่สุด.
\textit{โครงข่ายก่อกำเนิด}ในอุดมคติ จะมี $p_{\mathcal{G}} \approx p_{data}$.
%ถ้า $p_{\mathcal{G}}$ เหมือนกับ $p_{data}$ โดยสมบูรณ์
%\textit{โครงข่ายแบ่งแยก} ไม่มีทางรู้ได้เลย สิ่งที่ทำได้ก็แค่เดา

ปัจจัยสำคัญประการหนึ่งคือ \textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ ไม่ได้รับข้อมูลเกี่ยวกับภาพจริงโดยตรงเลย
\textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ ถูกบังคับให้เรียนรู้การแจกแจงของภาพจริงผ่านปฏิสัมพันธ์กับ\textit{โครงข่ายแบ่งแยก} $\mathcal{D}$.
\textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ เห็นทั้งภาพจริง และภาพที่สร้างขึ้น และได้รับเฉลยผ่านเกรเดียนต์หลังจากทายไป.
อีกทอดหนึ่ง \textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ ก็ได้รับเกรเดียนต์ของมันผ่านเกรเดียนต์ของ\textit{โครงข่ายแบ่งแยก} $\mathcal{D}$ อีกต่อหนึ่ง.

\textit{โครงข่ายก่อกำเนิด} อาจถูกมองว่าเป็นการเรียนรู้ เพื่อที่จะแปลงข้อมูลจากปริภูมิของตัวแทนสุ่ม ที่อาจถูกเรียกว่า \textit{ปริภูมิตัวแทน} (representation space) หรือ\textit{ปริภูมิซ่อนเร้น} (latent space) ไปสู่ปริภูมิของข้อมูล.
\index{english}{latent space}
\index{english}{representation space}
นั่นคือ $\mathcal{G}: \bm{z} \rightarrow \bm{X}$ เมื่อ $\bm{z}$ คือตัวแปรใน\textit{ปริภูมิซ่อนเร้น}
และ $\bm{X}$ คือตัวแปรในปริภูมิข้อมูล.
ส่วน\textit{โครงข่ายแบ่งแยก}ก็เป็นเสมือนการแปลงจากข้อมูลไปสู่ค่าระหว่างศูนย์กับหนึ่ง.
%ทวิภาค.
นั่นคือ $\mathcal{D}: \bm{X} \rightarrow (0,1)$.
% เมื่อ $\tilde{\bm{X}}$ คือตัวแปรในปริภูมิข้อมูล.
ภายหลังการฝึกเสร็จสิ้น 
\textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$ สามารถนำไปใช้สร้างตัวอย่างข้อมูลได้ตามต้องการ.

\paragraph{โครงข่ายปรปักษ์เชิงสร้างแบบมีเงื่อนไข.}
เมียร์ซะและคณะ\cite{MirzaEtAl2014} ขยายความสามารถของโครงข่ายปรปักษ์เชิงสร้าง
โดยใช้ความน่าจะเป็นแบบมีเงื่อนไข.
โครงข่ายปรปักษ์เชิงสร้างที่มีความสามารถที่เพิ่มขึ้นมาเช่นนี้ ถูกเรียกว่า \textbf{โครงข่ายปรปักษ์เชิงสร้างแบบมีเงื่อนไข} (Conditional Generative Adversarial Networks).
\index{thai}{โครงข่ายปรปักษ์เชิงสร้างแบบมีเงื่อนไข}\index{english}{Conditional Generative Adversarial Networks}
\index{english}{GAN!Conditional GAN}
% 
กระบวนการฝึกของโครงข่ายปรปักษ์เชิงสร้างแบบมีเงื่อนไข อาจตั้งจุดประสงค์เป็น
\begin{eqnarray}
\min_{\mathcal{G}} \max_{\mathcal{D}} V(\mathcal{G}, \mathcal{D})
&=& E_{\bm{X} \sim p_{data|\bm{C}}}[\log \mathcal{D}(\bm{X}|\bm{C})] 
+ E_{\bm{X} \sim p_{\mathcal{G}|\bm{C}}}[\log(1 - \mathcal{D}(\bm{X}|\bm{C}))]
\label{eq: convapp conditional GAN opt prob}
\end{eqnarray}
เมื่อ $\mathcal{D}(\bm{X}|\bm{C})$ แทนผลการทำนายจาก\textit{โครงข่ายแบ่งแยก} ที่รับอินพุตหลักเป็น $\bm{X}$ 
และรับอินพุตรองเป็น $\bm{C}$ ซึ่งใช้ระบุเงื่อนไข.
สัญกรณ์ $\bm{X} \sim p_{data|\bm{C}}$ หมายถึง ตัวแปร $\bm{X}$ มีการแจกแจงตามข้อมูลจริงที่เป็นไปตามเงื่อนไข $\bm{C}$.
สัญกรณ์ $\bm{X} \sim p_{\mathcal{G}|\bm{C}}$ หมายถึง ตัวแปร $\bm{X}$ มีการแจกแจงตามการแจกแจงจากโครงข่ายก่อกำเนิด ที่เงื่อนไข $\bm{C}$.
รูป~\ref{fig: conv app conditional GAN} แสดงกลไกเพิ่มเติม เพื่อเพิ่มคุณสมบัติการใช้เงื่อนไข ให้กับ\textit{โครงข่ายปรปักษ์เชิงสร้าง}.
โครงสร้างและรายละเอียดในการทำโครงข่ายปรปักษ์เชิงสร้างแบบมีเงื่อนไข อาจแตกต่างไปได้ เช่น \textit{อินโฟแกน} (InfoGAN\cite{InfoGAN}).

%
\begin{figure}
	\begin{center}
		\includegraphics[width=6in]{07ConvApp/GAN/CGAN.png}
		\caption[การฝึกโครงสร้างปรปักษ์เชิงสร้างแบบมีเงื่อนไข]{การฝึกโครงสร้างปรปักษ์เชิงสร้างแบบมีเงื่อนไข. 
			คล้ายการฝึกโครงสร้างปรปักษ์เชิงสร้างแบบดั้งเดิม (ไม่มีเงื่อนไข)
			การฝึกโครงสร้างปรปักษ์เชิงสร้างแบบมีเงื่อนไข เพิ่มข้อมูลของเงื่อนไข และให้ข้อมูลเงื่อนไขนี้กับโครงข่ายก่อกำเนิด 
			และโครงข่ายแบ่งแยก
			รวมถึงข้อมูลที่จริงที่จะเลือกมา ก็ต้องถูกควบคุมให้เป็นข้อมูลที่ตรงกับเงื่อนไขด้วย.
			การกำหนดเงื่อนไขเช่นนี้ ช่วยให้เราสามารถควบคุมเอาต์พุตของโครงข่ายก่อกำเนิด เพื่อให้สร้างเอาต์พุตตามเงื่อนไขที่เราต้องการได้.
		}
		\label{fig: conv app conditional GAN}
	\end{center}
\end{figure}
%

\paragraph{การประยุกต์ใช้โครงข่ายปรปักษ์เชิงสร้าง.}
โครงข่ายปรปักษ์เชิงสร้าง เป็นพัฒนาการที่สำคัญสำหรับการเรียนรู้เชิงลึก 
และได้ทำให้เกิดการประยุกต์ใช้อย่างกว้างขวาง ขยายเข้าไปแม้แต่ในวงการศิลปะ.
การศึกษาวิจัยและขอบเขตการใช้งานของโครงข่ายปรปักษ์เชิงสร้าง เป็นไปอย่างรวดเร็วและต่อเนื่อง
จนโครงข่ายปรปักษ์เชิงสร้างเป็นเสมือนศาสตร์ย่อย ๆ ในตัวเอง.
ตัวอย่างการประยุกต์ใช้ทั่ว ๆ ไปส่วนหนึ่งของโครงข่ายปรปักษ์เชิงสร้าง ได้แก่
การจำแนกกลุ่ม (เช่น การนำโครงข่ายแบ่งแยกไปใช้),
การสกัดลักษณะสำคัญ (ซึ่งอาจจะได้จากทั้งค่าเอาต์พุตชั้นซ่อนภายในโครงสร้างของโครงข่ายแบ่งแยก หรืออาจจะได้จากการทำ\textit{พีชคณิตเวกเตอร์}
ที่จะอธิบายเพิิ่มเติมต่อไป),
การสังเคราะห์ข้อมูล (ซึ่งคือ การสร้างข้อมูล โดยใช้โครงข่ายก่อกำเนิด และนี่คือ จุดประสงค์หลักของโครงข่ายปรปักษ์เชิงสร้าง),
การแปลงรูปหนึ่งไปสู่อีกรูปหนึ่ง,
% เช่น \textit{การแปลงกระบวนแบบศิลปะ},
การเพิ่มความละเอียดให้กับภาพ เป็นต้น.

คณะของรีด\cite{ReedEtAl2016} ใช้โครงข่ายปรปักษ์เชิงสร้าง ในการสร้างภาพขึ้นมาตามคำบรรยาย.
\textit{โครงข่ายปรปักษ์เชิงสร้างอะไรที่ไหน} (Genverative Adversarial What-Where Network\cite{ReedEtAl2016a}) สามารถสร้างภาพขึ้นจากส่วนภาพเล็ก ๆ ที่แต่ละส่วนภาพสร้างขึ้นมาตามตำแหน่งที่กำหนด และตามลักษณะพืื้นผิวที่บรรยาย.
นอกจากนั้น มีการใช้โครงข่ายปรปักษ์เชิงสร้างไปใช้ในกระบวนแก้ไขและตกแต่งรูป\cite{BrockEtAl2017a, ZhuEtAl2016}.
การแปลงรูปหนึ่งไปสู่อีกรูปหนึ่ง\cite{IsolaEtAl2016} ก็มีการประยุกต์ใช้ที่หลากหลาย 
เช่น การแปลงกระบวนแบบศิลปะ (artistic style transfer\cite{LiWand2016}),
\textit{การแปลงกระบวนแบบ} (style transfer\cite{KarrasEtAl2019}),
การสร้างภาพเหมือนจริงตามส่วนภาพ ที่ศิลปินสามารถวาดภาพคร่าวแล้วให้โครงข่ายปรปักษ์เชิงสร้างช่วยเติมรายละเอียด (semantic image synthesis\cite{PartEtAl2019, GauGAN2019}),
การสร้างภาพล้อเลียนบุคคลอัตโนมัติ (automatic caricature generation\cite{ShiEtAl2019a}),
การเพิ่มอายุให้หน้า (age progression\cite{DebEtAl2020}).

%Child Face Age-Progression via Deep Feature Aging
%Debayan Deb, Divyansh Aggarwal, Anil K. Jain

\textit{พีชคณิตเวกเตอร์} (Vector arithmetic)
คือ การนำเวกเตอร์ค่าสุ่ม $\bm{z}$ ที่เป็นอินพุตของโครงข่ายก่อกำเนิด สำหรับภาพต่าง ๆ มาทำบวกหรือลบกัน
แล้วนำเวกเตอร์ผลลัพธ์เข้าไปเป็นอินพุตของโครงข่ายก่อกำเนิด 
ผลลัพธ์ที่ได้พบว่ามีลักษณะสำคัญจากภาพของเวกเตอร์ที่เป็นตัวถูกดำเนินการ ผสมกันในลักษณะเชิงเส้น.
ตัวอย่างเช่น แรดฟอร์ดและคณะ\cite{DCGAN} เลือกภาพผู้หญิงยิ้มสามภาพออกมา 
แล้วหาเวกเตอร์เฉลี่ย $\bar{\bm{z}}_{\mathrm{smile, woman}}$ จากเวกเตอร์ค่าสุ่มของภาพทั้งสาม
นำไปลบออกด้วยเวกเตอร์เฉลี่ย $\bar{\bm{z}}_{\mathrm{neutral, woman}}$ ที่เฉลี่ยจากเวกเตอร์ค่าสุ่มของภาพผู้หญิงหน้าเฉย (ไม่ได้ยิ้ม)
แล้วนำไปบวกด้วยเวกเตอร์เฉลี่ย $\bar{\bm{z}}_{\mathrm{neutral, man}}$ ที่เฉลี่ยจากเวกเตอร์ค่าสุ่มของภาพผู้ชายหน้าเฉย (ไม่ได้ยิ้ม)
สุดท้ายนำเวกเตอร์ผลลัพธ์เข้าโครงข่ายก่อกำเนิด และรูปภาพที่สร้างขึ้นมา พบว่าเป็นภาพผู้ชายยิ้ม.
นั่นคือ 
โครงข่ายก่อกำเนิด ได้เรียนรู้ที่จะเข้ารหัสลักษณะสำคัญของภาพไว้ในเวกเตอร์ค่าสุ่ม $\bm{z}$
และการเข้ารหัสยังเป็นไปในลักษณะเชิงเส้น (จึงสามารถลบและบวก แล้วได้ผลลัพธ์ในลักษณะเชิงเส้นออกมา).
ด้วยคุณสมบัติเช่นนี้ อาจมองว่า\textit{โครงข่ายก่อกำเนิด}ได้เรียนรู้ที่จะกำหนดความหมายของลักษณะสำคัญไว้ที่ค่าของเวกเตอร์ $\bm{z}$.
เนื่องจากความหมายของลักษณะสำคัญนี้ ไม่ได้ถูกกำหนดออกมาอย่างชัดเจน ต้องอาศัยการสืบการสังเกตจึงจะพอเห็นความเชื่อมโยง
เวกเตอร์ $\bm{z}$ บางครั้งจึงถูกเรียกเป็น\textit{ลักษณะซ่อนเร้น} (latent representation)
และปริภูมิของ $\bm{z}$ จึงมักถูกอ้างถึงเป็น\textit{ปริภูมิซ่อนเร้น} หรือ\textit{ปริภูมิตัวแทน} ตามที่อภิปรายไปก่อนหน้า.
รูป~\ref{fig: conv app vector arith} แสดงภาพประกอบที่วาดขึ้น (ดูภาพจริงจาก \cite{DCGAN}).
\index{english}{GAN!latent representation}
\index{english}{GAN!latent space}\index{english}{GAN!representation space}
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!ลักษณะซ่อนเร้น}
\index{english}{latent variable}
\index{english}{latent variable!GAN}

%
\begin{figure}
	\begin{center}
		\includegraphics[width=6in]{07ConvApp/GAN/vector_arith1.png}
		\caption[การทำพีชคณิตเวกเตอร์กับเวกเตอร์ค่าสุ่มของโครงสร้างปรปักษ์เชิงสร้าง]{การทำพีชคณิตเวกเตอร์กับเวกเตอร์ค่าสุ่มของโครงข่ายก่อกำเนิด.
		ภาพผู้หญิงยิ้มถูกคัดเลือกมาสามภาพ โดยเก็บเวกเตอร์ค่าสุ่ม $\bm{z}_i$ ของแต่ละภาพมาด้วย
		นำเวกเตอร์ค่าสุ่มมาหาค่าเฉลี่ย $\bar{\bm{z}}_{s,w}$.
		ทำแบบเดียวกันกับภาพผู้หญิงหน้าเฉย และภาพผู้ชายหน้าเฉย
		ได้ค่าเฉลี่ย $\bar{\bm{z}}_{n,w}$ สำหรับภาพผู้หญิงหน้าเฉย และ $\bar{\bm{z}}_{n,m}$ สำหรับภาพผู้ชายหน้าเฉย.
		คำนวณ $\bm{z}_{\mathrm{result}} = \bar{\bm{z}}_{s,w} - \bar{\bm{z}}_{n,w} + \bar{\bm{z}}_{n,m}$
		แล้วนำ $\bm{z}_{\mathrm{result}}$ เข้าโครงข่ายก่อกำเนิด ภาพผลลัพธ์ $\bm{X}' = \mathcal{G}(\bm{z}_{\mathrm{result}})$ ที่ได้พบว่า ภาพ $\bm{X}'$ คล้ายภาพของผู้ชายยิ้ม.
		หมายเหตุ การทำพีชคณิตทำใน\textit{ปริภูมิซ่อนเร้น} (ทำกับเวกเตอร์ค่าสุ่ม) ถึงจะได้ผลลัพธ์คล้ายการเลือกลักษณะสำคัญ.
		หากทำพีชคณิตในปริภูมิของภาพโดยตรง (เช่น $\bm{X}_{\mathrm{result}} = \bar{\bm{X}}_{s,w} - \bar{\bm{X}}_{n,w} + \bar{\bm{X}}_{n,m}$) ภาพที่ได้จะเลอเทอะ และยากจะมองออก.
		ดูภาพตัวอย่างใน \cite{DCGAN}.
		}
		\label{fig: conv app vector arith}
	\end{center}
\end{figure}
%


แม้ว่าโครงข่ายก่อกำเนิดที่ถูกฝึกมาดีแล้วจะสามารถแปลงค่าจาก\textit{ปริภูมิซ่อนเร้น} ไปสู่\textit{ปริภูมิข้อมูล}ได้
แต่เช่นเดียวกับโครงข่ายประสาทเทียมทั่วไป คือ หากต้องการจะคำนวณย้อนกลับ ซึ่งคือการแปลงจากภาพ $\bm{X}$ กลับมาเป็นเวกเตอร์ซ่อนเร้น $\bm{z}$ นั้น ไม่สามารถทำได้โดยตรง.
อย่างไรก็ตาม มีความพยายามที่จะเพิ่มกลไกภายใน เพื่อให้โครงข่ายปรปักษ์เชิงสร้างสามารถคำนวณกลับไปกลับมาระหว่าง\textit{ปริภูมิซ่อนเร้น} และ\textit{ปริภูมิข้อมูล}ได้.
รูป~\ref{fig: conv app ALI/BiGAN} แสดงโครงสร้างของ\textit{ไบแกน} (BiGAN\cite{BiGAN}).
\textit{การอนุมานที่เรียนเชิงปรปักษ์} (Adversarially learned inference คำย่อ ALI\cite{ALI}) ซึ่งเป็นแนวคิดเดียวกันกับ\textit{ไบแกน} ก็ถูกเสนอในช่วงเวลาเดียวกัน.
กลไกที่สำคัญ สำหรับทั้ง\textit{ไบแกน}และ\textit{การอนุมานที่เรียนเชิงปรปักษ์} 
คือ การเพิ่ม\textit{ตัวเข้ารหัส} (encoder)
เพื่อเรียนรู้ความสัมพันธ์ระหว่าง\textit{ปริภูมิซ่อนเร้น}และ\textit{ปริภูมิข้อมูล}.
หากจำเพาะลงไปก็คือ
\textit{ตัวเข้ารหัส} ทำหน้าที่เรียนรู้\textit{การแจกแจงแบบมีเงื่อนไข} $p(\bm{z}|\bm{X})$ เมื่อ $\bm{X}$ แทนข้อมูลภาพ และ $\bm{z}$ คือ ค่า\textit{ลักษณะซ่อนเร้น} ที่โครงข่ายก่อกำเนิดใช้.
%
อย่างไรก็ตาม เครสเวลและคณะ\cite{OverviewGAN2018} ให้ความเห็นว่า ภาพที่สร้างจาก\textit{ไบแกน}หรือ\textit{การอนุมานที่เรียนเชิงปรปักษ์}ยังมีคุณภาพค่อนข้างต่ำ.
นั่นอาจหมายถึงว่า การศึกษาวิจัย
ถึงกลไกแปลงกลับจาก\textit{ปริภูมิข้อมูล}ไปสู่\textit{ปริภูมิซ่อนเร้น}
ในโครงข่ายปรปักษ์เชิงสร้าง ยังอยู่ในขั้นเริ่มต้นเท่านั้น.

%
\begin{figure}
	\begin{center}
		\includegraphics[width=6in]{07ConvApp/GAN/ALIBIGAN.png}
		\caption[โครงสร้างของไบแกนและการอนุมานที่เรียนเชิงปรปักษ์]{
		โครงสร้างของ\textit{ไบแกน}และ\textit{การอนุมานที่เรียนเชิงปรปักษ์}
		เพื่อเรียนรู้ความสัมพันธ์ระหว่าง\textit{ปริภูมิซ่อนเร้น}และ\textit{ปริภูมิข้อมูล}.
		กลไกสำคัญอยู่ที่\textit{ตัวเข้ารหัส}.
		\textit{โครงข่ายก่อกำเนิด} เรียนรู้\textit{การแจกแจงแบบมีเงื่อนไข} $p(\bm{X}|\bm{z})$.
		ส่วน\textit{ตัวเข้ารหัส} ที่เห็นข้อมูลจริง แต่พยายามเรียนรู้\textit{การแจกแจงแบบมีเงื่อนไข} $p(\bm{z}|\bm{X})$.
		ทั้ง\textit{โครงข่ายก่อกำเนิด}และ\textit{ตัวเข้ารหัส} พยายามเรียนรู้ เพื่อจะสร้างคู่ข้อมูล $(\bm{\tilde{X}}, \bm{\tilde{z}})$ ที่\textit{โครงข่ายแบ่งแยก} จำแนกได้ยากว่าเป็นภาพปลอม (คู่ $(\bm{X'}, \bm{z})$ จาก\textit{โครงข่ายก่อกำเนิด}) หรือเป็นภาพจริง (คู่ $(\bm{X}, \bm{z'})$ จากภาพจริงและ\textit{ตัวเข้ารหัส}).
		}
		\label{fig: conv app ALI/BiGAN}
	\end{center}
\end{figure}
%



%* mapping images back to latent space BiGAN and ALI



\paragraph{ปัญหาในการฝึก.}
%ในการฝึก\textit{โครงข่ายปรปักษ์เชิงสร้าง}
%
การฝึก\textit{โครงข่ายปรปักษ์เชิงสร้าง} ถูกรายงาน\cite{DCGAN, OverviewGAN2018} ว่าทำได้ยาก และมีโอกาสล้มเหลวสูงมาก
จากหลาย ๆ สาเหตุ รวมถึง
\begin{itemize}
\item การลู่เข้ายาก\cite{DCGAN} ที่นักวิจัยมักพบว่า มันยากที่ทำให้การฝึก\textit{โครงข่ายก่อกำเนิด} 
%และการฝึก\textit{โครงข่ายแบ่งแยก} 
ลู่เข้า.
ปัญหานี้ ส่วนหนึ่งอาจมาจากธรรมชาติของข้อมูลภาพ. 
ข้อมูลภาพมีปริภูมิที่ขนาดใหญ่มาก ๆ (รูปสีขนาด $W \times H$ พิกเซล เทียบเท่าจุดข้อมูลในปริภูมิขนาด $3 \cdot W \cdot H$ มิติ)
แต่ตัวอย่างข้อมูลต่าง ๆ ที่มี (เช่น ภาพจริงต่าง ๆ) เป็นข้อมูลสำหรับ\textit{การสนับสนุน}ของฟังก์ชันความหนาแน่นความน่าจะเป็น%
\footnote{%
ในทางคณิตศาสตร์และสถิติศาสตร์ 
\textit{การสนับสนุน}ของฟังก์ชันค่าจริง (the support of a real-valued function) 
หมายถึง เซตย่อยของโดเมน ที่เซตย่อยนั้นมีจุดข้อมูลที่ค่าของฟังก์ชันที่สนใจไม่เป็นศูนย์อยู่.
ในบริบทของการเรียนรู้การแจกแจง \textit{การสนับสนุน}ของฟังก์ชันความหนาแน่นความน่าจะเป็น หมายถึง
เซตย่อยในปริภูมิที่มีจุดข้อมูลจริงอยู.
% (เช่น $p_{data}$ ในสมการ~\ref{eq: convapp GAN obj function}).
}%
ครอบคลุมเพียงบริเวณเล็ก ๆ ในปริภูมิ และเมื่อเทียบกับขนาดของปริภูมิทั้งหมดแล้ว บริเวณที่ครอบคลุมมีขนาดเล็กมาก ๆ.
กล่าวคือ แม้จะใช้ตัวอย่างข้อมูลจำนวนมากแล้ว แต่จำนวนตัวอย่างที่ใช้ ก็ยังน้อยมากเมื่อเทียบกับขนาด\textit{ประชากร} (โอกาสทั้งหมดที่เป็นไปได้ของข้อมูล) และตัวอย่างข้อมูลเหล่านี้ ก็ยากที่จะเป็น\textit{ตัวแทน}ที่พอเพียงได้. 
%
%การค้นหาส่วนของปริภูมิที่มี\textit{การสนับสนุน}อยู่นั้น อาจทำได้ยากมาก และนั่นทำให้การเรียนรู้\textit{ฟังก์ชันความหนาแน่นความน่าจะเป็น}ทำได้ยาก
%% (เช่น เรียนรู้ $p_{\mathcal{G}}}$ $p_{data}$ ในสมการ~\ref{eq: convapp GAN obj function}) 

นอกจากนั้น ยังมีการศึกษา\cite{OverviewGAN2018, ArjovskyEtAl2016} ที่พบว่า ก่อนการฝึก
การแจกแจงก่อกำเนิด $p_{\mathcal{G}}$ อาจจะไม่มีการซ้อนทับกับการแจกแจงเป้าหมาย $p_{data}$ เลย.
หากเป็นเช่นนั้นจริง ผลคือ \textit{โครงข่ายแบ่งแยก}จะสามารถถูกฝึกได้อย่างง่ายดายและรวดเร็ว 
เพื่อที่จะสามารถจำแนกตัวอย่างจริง $\bm{X} \sim p_{data}$ ออกจากตัวอย่างปลอม $\bm{X} \sim p_{\mathcal{G}}$
ได้อย่างแม่นยำสมบูรณ์ (ความแม่นยำ $100\%$)
นั่นคือ การฝึก\textit{โครงข่ายแบ่งแยก}จะลู่เข้าจน ฟังก์ชันจุดประสงค์มีค่าเป็นศูนย์ ได้อย่างรวดเร็ว
และส่งผลให้เกรเดียนต์ต่าง ๆ เป็นศูนย์ ซึ่งจะทำให้การฝึก\textit{โครงข่ายกำเนิด}ไม่สามารถทำต่อไปได้.

อีกประเด็นหนึ่ง 
เครสเวลและคณะ\cite{OverviewGAN2018} อภิปรายประเด็นจากการศึกษาทฤษฎีโครงข่ายปรปักษ์เชิงสร้าง\cite{GoodfellowEtAl2014a}
กับฟังก์ชันจุดประสงค์ที่ใช้
ว่า หาก\textit{โครงข่ายแบ่งแยก}ไม่ได้อยู่ในสภาพที่ดีที่สุดแล้ว การฝึก\textit{โครงข่ายกำเนิด}ก็อาจจะไม่แม่นยำ หรืออาจได้ผลลัพธ์ผิดความหมายได้.
นี่อาจหมายถึง ความจำเป็นในการออกแบบฟังก์ชันจุดประสงค์ใหม่ สำหรับโครงข่ายปรปักษ์เชิงสร้าง.
อย่างไรก็ตาม ด้วยฟังก์ชันจุดประสงค์ดังเช่นนิพจน์~\ref{eq: convapp GAN obj function}
ประเด็นนี้ ที่เมื่อประกอบกับข้ออภิปรายข้างต้นแล้ว จะช่วยให้เห็นความยากของการฝึกโครงข่ายปรปักษ์เชิงสร้าง
ที่หาก\textit{โครงข่ายแบ่งแยก}ทำงานได้ดีเกินไป การฝึก\textit{โครงข่ายกำเนิด}ก็จะทำได้ยาก หรืออาจล้มเหลว
และหาก\textit{โครงข่ายแบ่งแยก}ทำงานไม่ดีเลย การฝึก\textit{โครงข่ายกำเนิด}ก็จะไปผิดทาง.


%the support of a real-valued function f is the subset of the domain containing those elements which are not mapped to zero. If the domain of f is a topological space, the support of f is instead defined as the smallest closed set containing all points not mapped to zero.

\item \textbf{การพังทลายของภาวะ} (mode collapse\cite{SalimansEtAl2016})
\index{english}{GAN!mode collapse}
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!การพังทลายของภาวะ}
ที่หมายถึง \textit{โครงข่ายกำเนิด}สร้างแต่เอาต์พุตที่เหมือน ๆ กัน แม้ว่าจะรับอินพุตต่างกัน.
จุดประสงค์ คือ ต้องการได้\textit{โครงข่ายกำเนิด}ที่สามารถสร้างแต่เอาต์พุตออกมาได้ โดยเอาต์พุตที่ได้ มีการแจกแจงคล้ายข้อมูลจริงมากที่สุด.
ตัวอย่างเช่น แทนที่\textit{โครงข่ายกำเนิด}จะสามารถสร้างภาพเหมือนจริงใหม่ ๆ ออกมาได้เรื่อย ๆ
แต่\textit{โครงข่ายกำเนิด}กลับสร้างภาพเหมือนจริงภาพเดิม ๆ ออกมา แม้ว่าจะรับอินพุต (ซึ่งคือค่าสุ่ม) ค่าใหม่แล้วก็ตาม.

\item การฝึก\textit{โครงข่ายแบ่งแยก}ได้เร็วและดีเกินไป\cite{OverviewGAN2018}.
หาก\textit{โครงข่ายแบ่งแยก}ทำงานได้ดีมาก ๆ อาจทำให้ $V(\mathcal{G}, \mathcal{D}) \approx 0$
ซึ่งมีผลให้เกรเดียนต์มีค่าใกล้ศูนย์ และทำให้การฝึก\textit{โครงข่ายก่อกำเนิด}ทำได้ยากมาก หรืออาจล้มเหลวได้.
รูป~\ref{fig: conv app GAN prob} แสดงสมมติฐานกลไกการเรียนรู้การแจกแจงของโครงข่ายปรปักษ์เชิงสร้าง ในสถานการณ์ต่าง ๆ.

แม้มองผิวเผินอาจจะดูดี
แต่การฝึก\textit{โครงข่ายแบ่งแยก}ให้ได้สมบูรณ์ก่อน (เมื่อเทียบกับความสามารถของ\textit{โครงข่ายก่อกำเนิด})
แล้วจึงค่อยฝึก\textit{โครงข่ายก่อกำเนิด}
ไม่ใช่แนวทางที่นิยมปฏิบัติ ด้วยเหตุผลข้างต้น. 
%การทำเช่นนี้อาจทำให้การฝึก
แนวทางปฏิบัติที่นิยมคือ การฝึก\textit{โครงข่ายแบ่งแยก}ไปก่อนระยะหนึ่ง 
แล้วจึงค่อยฝึก\textit{โครงข่ายก่อกำเนิด}ไปพร้อม ๆ กัน.
นอกจากนั้น ด้วยเหตุผลด้านเสถียรภาพเชิงตัวเลข ในการฝึก\textit{โครงข่ายก่อกำเนิด} มักนิยมใช้จุดประสงค์ $\max_{\mathcal{G}} E_{\bm{X} \sim p_{\mathcal{G}}} [\log \mathcal{D}(\bm{X})]$ มากกว่า $\min_{\mathcal{G}} E_{\bm{X} \sim p_{\mathcal{G}}} [\log(1 - \mathcal{D}(\bm{X}))]$.

\end{itemize}

%
\begin{figure}
	\begin{center}
		\begin{tabular}{ccc}
\includegraphics[width=2in]{07ConvApp/GAN/GAN_prob0.png}
			&
\includegraphics[width=2in]{07ConvApp/GAN/GAN_prob1.png}
			&
\includegraphics[width=2in]{07ConvApp/GAN/GAN_prob2.png}
\\			
(ก) & (ข) & (ค)
\\
		\end{tabular} 
		\caption[ภาพแสดงสมมติฐานการเรียนรู้การแจกแจงข้อมูลของโครงข่ายปรปักษ์เชิงสร้าง]{ภาพแสดงสมมติฐานการเรียนรู้การแจกแจงข้อมูลของโครงข่ายปรปักษ์เชิงสร้าง. 
		ทั้งสามภาพ แสดง
		ภาพอย่างง่ายของ ค่าความหนาแน่นความน่าจะเป็น (แกนตั้ง) ต่อค่าข้อมูล (แกนนอน) ของข้อมูลจริง (แสดงด้วยเส้นไข่ปลา) กับ ของที่สร้างขึ้นจากโครงข่ายก่อกำเนิด (แสดงด้วยเส้นประ) พร้อมทั้งแสดงค่าเอาต์พุตของโครงข่ายแบ่งแยก (แสดงด้วยเส้นทึบ).
		ภาพซ้ายสุด (ก) การแจกแจงของข้อมูลจริง ต่างจากการแจกแจงจากโครงข่ายก่อกำเนิดมาก ไม่มีส่วนที่ซ้อนทับกันเลย.
		โครงข่ายแบ่งแยก สามารถจำแนกข้อมูลจริงออกจากข้อมูลปลอมได้อย่างสมบูรณ์ ด้วยความแม่นยำสูงสุด. 
		กรณีเช่นนี้ จะทำให้การฝึกโครงข่ายก่อกำเนิดไม่สามารถดำเนินการต่อได้.
		ภาพกลาง (ข) การแจกแจงของข้อมูลจริง ต่างจากการแจกแจงจากโครงข่ายก่อกำเนิด แต่มีส่วนซ้อนทับกันอยู่มาก.
		โครงข่ายแบ่งแยก ไม่สามารถจำแนกข้อมูลจริงออกจากข้อมูลปลอมได้อย่างสมบูรณ์.
		การฝึกโครงข่ายก่อกำเนิด สามารถดำเนินการต่อไปได้.
		ภาพขวา (ค) โครงข่ายก่อกำเนิดสามารถเรียนรู้การแจกแจงของข้อมูลจริง และสามารถสร้างข้อมูลจากการแจกแจงที่เหมือนของข้อมูลจริง.
โครงข่ายแบ่งแยก ไม่สามารถจำแนกข้อมูลจริงออกจากข้อมูลปลอมได้เลย.}
		\label{fig: conv app GAN prob}
	\end{center}
\end{figure}
%

\paragraph{เทคนิคในการฝึกโครงข่ายปรปักษ์เชิงสร้าง.}
จากความท้าทายในการฝึกโครงข่ายปรปักษ์เชิงสร้างที่อภิปรายข้างต้น
แรดฟอร์ดและคณะ\cite{DCGAN} ได้เสนอ\textit{ดีซีแกน} (DCGAN จาก Deep Convolutional Generative Adversarial Networks)
\index{english}{DCGAN}
\index{english}{GAN!DCGAN}
เพื่อบรรเทาปัญหา.
\textit{ดีซีแกน}
มีปัจจัยที่สำคัญคือ 
(1) การใช้\textit{คอนโวลูชั่นก้าวยาว} (strided convolution)
แทนการใช้\textit{ชั้นดึงรวม} ในโครงสร้างของ\textit{โครงข่ายแบ่งแยก} $\mathcal{D}$.
\textit{คอนโวลูชั่นก้าวยาว} \index{english}{strided convolution}\index{thai}{คอนโวลูชั่นก้าวยาว}
หมายถึง \textit{ชั้นคอนโวลูชััน}ที่ใช้\textit{ก้าวย่าง}ขนาดใหญ่กว่าหนึ่ง เช่น การใช้\textit{ขนาดก้าวย่าง} $S = 2$. 
%(หัวข้อ~\ref{sec: convolution layer}) 
ผลลัพธ์ของการใช้\textit{คอนโวลูชั่นก้าวยาว} จะให้ผลเหมือนการลดขนาด\textit{แผนที่ลักษณะสำคัญ}ลง (หรือ spatially downsampling).
(2) การใช้\textit{ชั้นคอนโวลูชั่น} โดยเฉพาะใช้การทำ\textit{คอนโวลูชั่นก้าวเศษ} (fractionally-strided convolution หรือ transposed convolution\cite{DumoulinVisin2018}) 
ในโครงสร้างของ\textit{โครงข่ายก่อกำเนิด} $\mathcal{G}$.

หากจะอธิบายโดยง่ายแล้ว 
ภายใต้บริบทนี้
\textit{คอนโวลูชั่นก้าวเศษ}%
\index{english}{fractionally-strided convolution}
\index{thai}{คอนโวลูชั่นก้าวเศษ}
ก็คือ การขยายขนาด\textit{แผนที่ลักษณะสำคัญ}ที่เป็นอินพุต แล้วจึงทำการคำนวณคอนโวลูชั่น.
การขยายขนาด\textit{แผนที่ลักษณะสำคัญ} (ซึ่งขยายเฉพาะในมิติลำดับเชิงพื้นที่) 
ทำด้วยการเติมค่าศูนย์เข้าไประหว่างค่าพิกเซลเดิม (รวม\textit{การเติมเต็มด้วยศูนย์} ที่เติมค่าศูนย์ที่บริเวณขอบของแผนที่ด้วย).
%
ผลลัพธ์ของการใช้\textit{คอนโวลูชั่นก้าวเศษ} จะให้ผลเหมือนการเพิ่มขนาด\textit{แผนที่ลักษณะสำคัญ}ขึ้น (หรือ spatially upsampling).
รูป~\ref{fig: conv app fractionally strided convolution} 
แสดงกลไกที่\textit{คอนโวลูชั่นก้าวเศษ} ช่วยขยายขนาด\textit{แผนที่ลักษณะสำคัญ}ขึ้น.
หากสังเกตการทำคอนโวลูชั่นในรูป 
เมื่อมองจากปฏิสัมพันธ์ระหว่างฟิลเตอร์และอินพุต 
อาจดูเหมือนกับว่าฟิลเตอร์ขยับผ่านพิกเซลช้าลง คล้ายกับว่า ใช้ขนาด\textit{ก้าวย่าง}ที่เล็กกว่าหนึ่ง ซึ่งเป็นที่มาของชื่อ \textit{คอนโวลูชั่นก้าวเศษ}.

%
\begin{figure}
	\begin{center}
	\includegraphics[width=5in]{07ConvApp/GAN/TransposedConv.png}
\caption[คอนโวลูชั่นก้าวเศษช่วยขยายขนาดแผนที่ลักษณะสำคัญ]{\textit{คอนโวลูชั่นก้าวเศษ}ช่วยขยายขนาด\textit{แผนที่ลักษณะสำคัญ}.
อินพุตขนาด $2 \times 2$ พิกเซล ถูกขยายเป็นเอาต์พุตขนาด $5 \times 5$ พิกเซล เมื่อใช้ฟิลเตอร์ขนาด $3 \times 3$ โดยการเติมศูนย์หนึ่งตัวระหว่างพิกเซล 
และทำ\textit{การเติมเต็มด้วยศูนย์}ด้วยศูนย์สองตัวที่ขอบแต่ละข้าง.
ขนาดเอาต์พุต $o' = s (i' - 1) + k$ เมื่อ $i'$ คือขนาดอินพุต และ $k$ คือขนาดฟิลเตอร์ และเติมศูนย์ระหว่างพิกเซล $s - 1$ ตัว. 
กรณีนี้ $o' = 2 (2 - 1) + 3 = 5$.
(ดูรายละเอียดการคำนวณจาก \cite{DumoulinVisin2018}. ภาพดัดแปลงจาก \cite[รูป 4.5]{DumoulinVisin2018})}
		\label{fig: conv app fractionally strided convolution}
	\end{center}
\end{figure}
%


หมายเหตุ
\textit{คอนโวลูชั่นก้าวเศษ} บางครั้งอาจถูกเรียก \textit{คอนโวลูชั่นสลับเปลี่ยน} (Transposed convolution) ซึ่งมาจากการตีความทางคณิตศาสตร์.
นั่นคือ 
หากดำเนินคอนโวลูชั่นด้วยการแปลงอินพุตและค่าน้ำหนักของฟิลเตอร์เป็นเมทริกซ์ โดยจัดรูปเมทริกซ์ทั้งสองให้ถูกต้อง (มีการใช้ค่าซ้ำและมีการเติมศูนย์เข้าไป ดูแบบฝึกหัด~\ref{ex: CNN implementation} ประกอบ) ซึ่งทำให้ได้เมทริกซ์ของค่าน้ำหนักเป็น \textit{เมทริกซ์มากเลขศูนย์} (sparse matrix) แล้ว
การทำ\textit{คอนโวลูชั่น} ก็เหมือนกับการคูณเมทริกซ์อินพุตเข้ากับเมทริกซ์ค่าน้ำหนัก แล้วนำผลลัพธ์ที่ได้ไปจัดรูปให้เข้ากับโครงสร้างที่ถูกต้อง.
ในทำนองเดียวกัน \textit{คอนโวลูชั่นก้าวเศษ} ก็เสมือนการคูณเมทริกซ์อินพุตเข้ากับ\textit{การสลับเปลี่ยน}ของเมทริกซ์ค่าน้ำหนัก.
ดังนั้น กระบวนการนี้จึงเรียกว่า \textit{คอนโวลูชั่นสลับเปลี่ยน}.
(ศึกษาเพิ่มเติมได้จาก \cite{DumoulinVisin2018})

%นอกจากสองชื่อข้างต้น บางครั้ง 
\textit{คอนโวลูชั่นก้าวเศษ} บางครั้ง อาจถูกเรียกว่า \textit{การถอดคอนโวลูชั่น} (Deconvolution).
อย่างไรก็ตาม 
\textit{การถอดคอนโวลูชั่น} มีความหมายอื่น (ซึ่งเป็นคนละเรื่อง)
และถูกยอมรับมากกว่า.
ความหมายที่ถูกยอมรับมากกว่าของ\textit{การถอดคอนโวลูชั่น}
คือ การถอดพารามิเตอร์ของโครงข่ายคอนโวลูชั่นย้อนกลับ 
เพื่อศึกษากลไกการทำงานของโครงข่ายคอนโวลูชั่น ว่า
ฟิลเตอร์แต่ละตัวที่ใช้ในโครงข่ายคอนโวลูชั่น 
ได้เรียนรู้เพื่อจะตรวจจับลักษณะรูปแบบเช่นไร.
สำหรับ\textit{การถอดคอนโวลูชั่น} ในความหมายที่นิยมนี้
สามารถศึกษาเพิ่มเติมได้จากบทความ \cite{ZeilerFergus2014, ZeilerEtAl2010, SpringenbergEtAl2015} เป็นต้น.

นอกจากการใช้\textit{คอนโวลูชั่นก้าวยาว}และ\textit{คอนโวลูชั่นก้าวเศษ}ในโครงสร้างของโครงข่ายแบ่งแยกและโครงข่ายก่อกำเนิดแล้ว
แรดฟอร์ดและคณะ\cite{DCGAN} ยังแนะนำการใช้\textit{แบชนอร์ม} (หัวข้อ~\ref{sec: batch norm}),
\index{english}{batch norm}\index{thai}{แบชนอร์ม}
แนะนำใช้ชั้นคอนโวลูชั่นลึก ๆ (หลาย ๆ ชั้น) แทนการใช้\textit{ชั้นเชื่อมต่อเต็มที่}%
\footnote{%
อย่างไรก็ตาม 
ในโครงข่ายก่อกำเนิด
การใช้\textit{ชั้นเชื่อมต่อเต็มที่}เป็นชั้นคำนวณแรก (ชั้นที่รับอินพุตเป็นเวกเตอร์ค่าสุ่ม) 
อาจจะสะดวกที่จะใช้\textit{ชั้นเชื่อมต่อเต็มที่} มากกว่าการใช้ชั้นคอนโวลูชั่น
ถึงแม้จะมีหลายวิธีที่จะประยุกต์ใช้ชั้นคอนโวลูชั่นกับอินพุตเวกเตอร์ได้ก็ตาม อาทิ การจัดเรียงโครงสร้างของอินพุตใหม่ ให้เหมาะกับการทำคอนโวลูชั่น เป็นต้น.
},
แนะนำการใช้\textit{เรลู}
\index{english}{ReLu}\index{thai}{เรลู}
สำหรับฟังก์ชันกระตุ้นของทุก ๆ ชั้นคำนวณในโครงข่ายก่อกำเนิด ยกเว้นชั้นเอาต์พุตที่แนะนำให้ใช้\textit{ไฮเปอร์บอลิกแทนเจนต์},
แนะนำการใช้\textit{เรลูรั่ว}
\index{english}{leaky relu}\index{thai}{เรลูรั่ว}
สำหรับฟังก์ชันกระตุ้นของทุก ๆ ชั้นคำนวณในโครงข่ายแบ่งแยก.

เทคนิคอื่น ๆ ที่มีรายงานว่า เป็นปัจจัยสำคัญช่วยการฝึกโครงข่ายปรปักษ์เชิงสร้าง
ได้แก่ \textit{การจับคู่ลักษณะสำคัญ}\cite{SalimansEtAl2016},
\textit{การแยกแยะหมู่เล็ก}\cite{SalimansEtAl2016},
\textit{การเฉลี่ยตามประวัติ}\cite{SalimansEtAl2016},
\textit{การทำฉลากราบรื่นทางเดียว}\cite{SalimansEtAl2016},
\textit{การทำหมู่เล็กเสมือนจริง}\cite{SalimansEtAl2016},
\textit{การใส่สัญญาณรบกวน}\cite{SonderbyEtAl, ArjovskyEtAl2016}
ไปจนถึงการเปลี่ยนฟังก์ชันจุดประสงค์ (ดู \cite{NowozinEtAl2016, WGAN} เพิ่มเติม) เป็นต้น.
เครสเวลและคณะ\cite{OverviewGAN2018} ให้ความเห็นว่า 
โครงข่ายปรปักษ์เชิงสร้างที่ฝึกได้ง่ายที่สุด น่าจะเป็นแบบจำลองที่เสนอโดยคณะของอาร์โจฟสกี\cite{WGAN}
หรือของคณะของมาคฮ์ซานี\cite{AAE}.

\textit{การจับคู่ลักษณะสำคัญ} (feature matching)%
\index{english}{feature matching}\index{thai}{การจับคู่ลักษณะสำคัญ}
\index{english}{GAN!feature matching}\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!การจับคู่ลักษณะสำคัญ}
เปลี่ยนฟังก์ชันจุดประสงค์สำหรับ\textit{โครงข่ายก่อกำเนิด}
เป็น $\min_{\mathcal{G}} \| E_{\bm{X} \sim p_{data}}[\bm{f}(\bm{X})] - E_{\bm{X} \sim p_{\mathcal{G}}}[\bm{f}(\bm{X})] \|^2_2$
เมื่อ $\bm{f}(\bm{X})$ เป็นลักษณะสำคัญที่ได้จากโครงข่ายแบ่งแยก 
(ค่าเวกเตอร์ของชั้นคำนวณชั้นหนึ่งที่อยู่ภายในโครงสร้างของโครงข่ายแบ่งแยก)
ในขณะที่ยังใช้ฟังก์ชันจุดประสงค์แบบเดิมสำหรับ\textit{โครงข่ายแบ่งแยก} (เช่น $\max_{\mathcal{D}} V(\mathcal{G}, \mathcal{D})
= E_{\bm{X} \sim p_{data}}[\log \mathcal{D}(\bm{X})] 
+ E_{\bm{X} \sim p_{\mathcal{G}}}[\log(1 - \mathcal{D}(\bm{X}))]$).

\textit{การแยกแยะหมู่เล็ก} (minibatch discrimination)%
\index{thai}{การแยกแยะหมู่เล็ก}\index{english}{minibatch discrimination}
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!การแยกแยะหมู่เล็ก}\index{english}{GAN!minibatch discrimination}
เพิ่มสัญญาณสารสนเทศ ที่ช่วยบอก\textit{โครงข่ายแยกแยะ}ว่าอินพุตที่ได้ เหมือนหรือแตกต่างจากอินพุตอื่นใน\textit{หมู่เล็ก}มากน้อยขนาดไหน.
ดังนั้น \textit{โครงข่ายแยกแยะ}จะสามารถระบุอินพุตปลอมที่มีปัญหา\textit{โครงข่ายแยกแยะ}ได้อย่างง่ายดาย.

รูป~\ref{fig: conv app minibatch discrimination} แสดงกลไกของ\textit{การแยกแยะหมู่เล็ก}.
คณะของแซลลิมันส์\cite{SalimansEtAl2016} แปลงเวกเตอร์ลักษณะสำคัญ $\bm{z}_n \in \mathbb{R}^M$ 
(เลือกจากชั้นคำนวณใน\textit{โครงข่ายแยกแยะ} และ $M$ เป็นขนาดของเวกเตอร์)
ให้เป็นเมทริกซ์ลักษณะสำคัญ $\bm{A}_n \in \mathbb{R}^{P \times Q}$ (ด้วยการคูณกับเทนเซอร์ค่าน้ำหนัก $\bm{W}'$ ที่ปรับค่าได้ในกระบวนการฝึก)
เมื่อ $P$ และ $Q$ เป็นจำนวนแถวและสดมภ์ที่ต้องการ.
ความต่างระหว่างเมทริกซ์ลักษณะสำคัญ ถูกระบุด้วยเวกเตอร์ $\bm{d}(i,j) \in \mathbb{R}^P$ ที่มีส่วนประกอบ 
$d_r(i,j) = \exp( - \| \mathrm{row}_r(\bm{A}_i) - \mathrm{row}_r(\bm{A}_j)\|_1)$
สำหรับ $r = 1, \ldots, P$ เมื่อ ดัชนีของตัวอย่างในหมู่เล็ก $i, j \in \{1, \ldots, B\}$ และ $B$ คือจำนวนตัวอย่างในหมู่เล็ก.
ตัวดำเนินการ $\mathrm{row}_r(\bm{A})$ หมายถึง แถวที่ $r^{th}$ ของเมทริกซ์ $\bm{A}$
และ $\| [v_1, v_2, \ldots, v_N]^T \|_1 = \sum_{n=1}^N |v_n|$ หรือ $L^1$ นอร์ม (L1 norm). 
\index{english}{L1 norm}\index{english}{norm}\index{thai}{นอร์ม}
ความต่างระหว่างเมทริกซ์ ถูกสรุปเป็น\textit{เวกเตอร์แยกแยะ} $\bm{d}_i = [\sum_{j=1}^B \bm{d}_1(i,j), \ldots,  \sum_{j=1}^B \bm{d}_P(i,j)]^T$
และค่าเวกเตอร์ $\bm{d}_i$ ถูกป้อนร่วมกับเวกเตอร์ลักษณะสำคัญ $\bm{z}_i$ (สำหรับตัวอย่างที่ $i^{th}$ ในหมู่เล็ก) เข้าไปสู่ชั้นคำนวณต่อไปในโครงข่ายแบ่งแยก.

% train_cifar_minibatch_discrimination.py --> line 66: disc_layers.append(nn.MinibatchLayer( ...
% nn.py --> line 132: class MinibatchLayer( ...
%     def get_output_for(self, input, init=False, **kwargs):
%          ...
%          activation = T.tensordot(input, self.W, [[1], [0]])
%          abs_dif = (T.sum(abs(activation.dimshuffle(0,1,2,'x') - activation.dimshuffle('x',1,2,0)),axis=2)
%                    + 1e6 * T.eye(input.shape[0]).dimshuffle(0,'x',1))
%
%          f = T.sum(T.exp(-abs_dif),axis=2)
%          f += self.b.dimshuffle('x',0)
%          return T.concatenate([input, f], axis=1)
%
% # minibatch discrimination layer


%
\begin{figure}
	\begin{center}
		\includegraphics[width=5in]{07ConvApp/GAN/CGAN_Minibatch_discrimination.png}
		\caption[การแยกแยะหมู่เล็ก]{การแยกแยะหมู่เล็ก. แต่ละอินพุตในหมู่เล็ก $\tilde{\bm{x}}_n$ จะถูกแปลงเป็นเวกเตอร์ลักษณะสำคัญ $\bm{z}_n$ (เลือกมาจากเอาต์พุตของชั้นคำนวณชั้นหนึ่งของโครงข่ายแยกแยะ). 
		การแยกแยะหมู่เล็ก จะแปลงเวกเตอร์ลักษณะสำคัญ $\bm{z}_n$ เป็น\textit{เมทริกซ์ลักษณะสำคัญ} $\bm{A}_n$
		แล้ววัดความต่างระหว่าง\textit{เมทริกซ์ลักษณะสำคัญ}นั้นเปรียบเทียบกับ\textit{เมทริกซ์ลักษณะสำคัญ}อื่น ๆ ในหมู่เล็ก 
		และสรุปออกมาเป็น\textit{เวกเตอร์แยกแยะ} $d_n$.
		ค่าของ\textit{เวกเตอร์แยกแยะ}จะถูกนำไปประกอบเป็นอินพุตเสริมให้กับชั้นคำนวณต่อไปในโครงข่ายแยกแยะ.
		\textit{การพังทลายของภาวะ} ที่โครงข่ายก่อกำเนิดมักสร้างเอาต์พุตคล้าย ๆ กันออกมา จะทำให้\textit{เวกเตอร์แยกแยะ}มีขนาดเล็ก เมื่อเปรียบเทียบกับอินพุตจริงที่มีความหลากหลาย.
		ดังนั้นโครงข่ายแยกแยะ จะสามารถจำแนกอินพุตปลอมจาก\textit{การพังทลายของภาวะ}ได้ง่ายขึ้นจาก\textit{เวกเตอร์แยกแยะ} 
		และเกรเดียนต์จากโครงข่ายแยกแยะจะช่วยให้โครงข่ายก่อกำเนิดเรียนรู้เพื่อแก้\textit{การพังทลายของภาวะ}ได้ดีขึ้น.
	}
		\label{fig: conv app minibatch discrimination}
	\end{center}
\end{figure}
%

\textit{การเฉลี่ยตามประวัติ} (historical averaging)
\index{thai}{การเฉลี่ยตามประวัติ}
\index{english}{historical averaging}
เป็นการเพิ่มพจน์ที่ช่วยลดการเปลี่ยนค่าพารามิเตอร์อย่างรุนแรงในระหว่างการฝึก 
เพื่อช่วยให้ระบบเข้าสู่สมดุลย์ได้ง่ายขึ้น.
ตัวอย่างเช่น คณะของแซลลิมันส์\cite{SalimansEtAl2016} 
ซึ่งได้รับแรงบัลดาลใจจาก\textit{ทฤษฎีเกม} (game theory) 
เพิ่มพจน์ $\| \bm{\theta} - \frac{1}{T} \sum_{i=1}^T \bm{\theta}^{(i)} \|^2$ เข้าไปในฟังก์ชันสูญเสียเดิม 
โดย $\bm{\theta}$ แทนค่าปัจจุบันของพารามิเตอร์ต่าง ๆ
ส่วน $\bm{\theta}^{(i)}$ แทนค่าใน\textit{สมัยฝึก}ที่ $i^{th}$ ของพารามิเตอร์ต่าง ๆ
และ $T$ คือจำนวน\textit{สมัยฝึก}ที่ผ่านมา.
พจน์ที่คณะของแซลลิมันส์ เพิ่มเข้าไปเป็น\textit{ระยะทางยูคลีเดียน} ระหว่างค่าพารามิเตอร์ปัจจุบัน กับค่าเฉลี่ยที่ผ่านมา.
การเพิ่มพจน์นี้เข้าไปในฟังก์ชันสูญเสีย ส่งผลให้กระบวนการฝึกลดการปรับค่าพารามิเตอร์อย่างมากลงได้.
อย่างไรก็ตามการใช้\textit{การเฉลี่ยตามประวัติ} ควรทำอย่างระมัดระวัง และควรเลือกค่าน้ำหนักเพื่อรักษาดุลย์ระหว่างค่าฟังก์ชันสูญเสียเดิม กับค่าของพจน์\textit{การเฉลี่ยตามประวัติ}นี้อย่างเหมาะสม.


\textit{การทำฉลากราบรื่นทางเดียว} (one-sided label smoothing)
\index{thai}{การทำฉลากราบรื่นทางเดียว}
\index{english}{one-sided label smoothing}
คือ การเปลี่ยนค่าเป้าหมายของฉลากเฉลยของโครงข่ายแบ่งแยก จากเฉลยว่าเป็นภาพจริง $y = 1$ ลดลงเป็น $1 - \epsilon$
แต่คงค่าเฉลยภาพปลอม $y = 0$ ไว้เหมือนเดิม
เช่น เปลี่ยนจากเฉลยภาพจริง จากค่า $1$ เป็น $0.9$ ($\epsilon = 0.1$).
เทคนิคนี้ดัดแปลงมาจาก\textit{การทำฉลากราบรื่น} (label smoothing) เพื่อป้องกันไม่ได้โครงข่ายแบ่งแยกมีความมั่นใจมากเกินไป.

%for what

\textit{การทำฉลากราบรื่น}\cite{MullerEtAl2019, SzegedyEtAl2016}
\index{thai}{การทำฉลากราบรื่น}
\index{english}{label smoothing}
เป็นเทคนิคที่เปลี่ยนค่าเป้าหมายของฉลากเฉลย เพื่อป้องกันไม่ให้แบบจำลองมีความมั่นใจมากเกินไป (over-confidence).
\textit{การทำฉลากราบรื่น} ดั่งเดิมออกแบบมาสำหรับการจำแนกกลุ่ม (multi-class classification)
โดยการปรับค่าเป้าหมายของฉลากเฉลยสำหรับประเภท $k^{th}$ 
เป็น $q_k = (1 - \epsilon) y_k + \epsilon p(k)$
เมื่อ $y_k$ คือค่าฉลากเฉลยของประเภท $k^{th}$  (อยู่ในรูปรหัสหนึ่งร้อน นั่นคือ $y_k = 1$ เมื่อเฉลยคือชนิด $k^{th}$ และ $y_k = 0$ เมื่อเฉลยไม่ใช่ชนิด $k^{th}$)
และ $p(k)$ คือการแจกแจงของข้อมูลชนิด $k^{th}$
ส่วน $\epsilon$ คืออภิมานพารามิเตอร์ที่เลือกได้ตามความเหมาะสม.

เซเจดีและคณะ\cite{SzegedyEtAl2016} เลือกประมาณ $p(k)$ ด้วยการแจกแจงเอกรูป
นั่นคือ ค่าฉลากเฉลย $q_k = (1 - \epsilon) y_k + \frac{\epsilon}{K}$ เมื่อ $K$ คือจำนวนประเภททั้งหมด.
ตัวอย่างเช่น กรณีการจำแนก $5$ ประเภท แล้วเลือก $\epsilon = 0.1$ 
ค่าเป้าหมาย จะถูกปรับเป็น $0.92$ สำหรับประเภทที่ถูกต้อง และ $0.02$ สำหรับประเภทที่ไม่ถูกต้อง.
ดังนั้นแบบจำลองที่ถูกฝึกอย่างดีแล้วจะปรับค่าทำนายเข้ามาที่ $0.92$ ซึ่งอาจตีความว่ามั่นใจมาก แต่ไม่ร้อยเปอร์เซ็นต์ มีเผื่อใจไว้บ้าง
ซึ่งหากมองเชิงการคำนวณ การปรับค่าฉลากเฉลยจะช่วยป้องกันไม่ให้แบบจำลองถูกปรับค่าเข้าไปสู่\textit{ช่วงอิ่มตัว} (saturation region). แบบจำลองที่ถูกปรับค่าเข้าไปสู่\textit{ช่วงอิ่มตัว} จะทำให้การฝึกต่อทำได้ยาก และให้ผลคล้ายการเกิดโอเวอร์ฟิต.
(ดูแบบฝึกหัด~\ref{ex: label smoothing} เพิ่มเติมสำหรับ\textit{การทำฉลากราบรื่น})


เพื่อลดการขึ้นกับข้อมูลภายในหมู่เล็กมากเกินไป เมื่อใช้\textit{แบชนอร์ม}
คณะของแซลลิมันส์\cite{SalimansEtAl2016} 
ใช้\textit{การทำหมู่เล็กเสมือนจริง} (virtual minibatch)
\index{thai}{การทำหมู่เล็กเสมือนจริง}
\index{english}{virtual minibatch}
ทำ\textit{แบชนอร์ม}กับจุดข้อมูล 
โดยใช้ค่าสถิติที่คำนวณจากจุดข้อมูลนั้น ๆ และ\textit{หมู่อ้างอิง} (reference batch)
ซึ่ง\textit{หมู่อ้างอิง} ถูกเลือกขึ้นมาก่อนการฝึก และใช้หมู่นี้ตลอด (ไม่มีการเปลี่ยนแปลง).
เนื่องจาก\textit{การทำหมู่เล็กเสมือนจริง} ทำการคำนวณมากขึ้น 
เพราะว่า ต้องทำ\textit{การคำนวณไปข้างหน้า} (forward pass) สำหรับสองหมู่เล็ก 
ดังนั้นคณะของแซลลิมันส์ จึงใช้\textit{การทำหมู่เล็กเสมือนจริง}เฉพาะกับการฝึกโครงข่ายก่อกำเนิด

\textit{การใส่สัญญาณรบกวน} (noise addition)
\index{thai}{การใส่สัญญาณรบกวน}
\index{english}{noise addition}
คือการใส่สัญญาณรบกวน เช่น สัญญาณรบกวนที่มีการแจกแจงแบบเกาส์เซียน
เข้าไปในทั้งภาพจริง และภาพที่สร้างจากโครงข่ายก่อกำเนิด.
ซอนเดอบายและคณะ\cite{SonderbyEtAl} อ้างว่าการใส่สัญญาณรบกวน ให้ผลดีกว่า\textit{การทำฉลากราบรื่นทางเดียว}.
การใส่สัญญาณรบกวนเข้าไปกับทั้งภาพจริงและภาพปลอม เป็นคล้าย ๆ กับการปรับการแจกแจงจริง กับการแจกแจงจากโครงข่ายก่อกำเนิดให้เข้ามาใกล้กันและกันมากขึ้น.

%% Just in case / may just comment on
%Towards Universal Representation Learning for Deep Face Recognition
%Yichun Shi, Xiang Yu, Kihyuk Sohn, Manmohan Chandraker, Anil K. Jain
%
%%
%
%%
%On the Intrinsic Dimensionality of Image Representations
%Sixue Gong, Vishnu Naresh Boddeti, Anil K. Jain
%
%%
	
	

{\small
	\begin{shaded}
		\paragraph{\small เกร็ดความรู้ รูปแบบ``ประหลาด''ของจิต}
		\index{english}{mind}\index{thai}{จิต}
		\index{english}{life}\index{thai}{ชีวิต}
		\index{english}{NDE}\index{thai}{ประสบการณ์เฉียดตาย}
		\index{english}{side story}
		\index{english}{side story!Mind, Brain, and Life}
		\index{thai}{เกร็ดความรู้}
		\index{thai}{เกร็ด!จิต สมอง และชีวิต}
		
%		\begin{center}
%			\begin{tabular}{ >{\arraybackslash}m{3.3in}  >{\arraybackslash}m{2.3in} }
%				``The most difficult subjects can be explained to the most slow-witted man if he has not formed any idea of them already; but the simplest thing cannot be made clear to the most intelligent man if he is firmly persuaded that he knows already, without a shadow of doubt, what is laid before him.''
%				&
%				``เรื่องที่ยากที่สุดสามารถอธิบายให้คนที่หัวช้าที่สุดเข้าใจได้ ถ้าเขาไม่ฝังใจคิดไปเองก่อนแล้ว.
%				แต่เรื่องที่ง่ายที่สุดไม่อาจจะอธิบายให้คนที่ฉลาดที่สุดเข้าใจได้ ถ้าเขามัวยึดติดสิ่งที่เขาคิด 
%				โดยที่ไม่สนใจความจริงที่อยู่ตรงหน้าเลยสักนิด''
%				\\
%				---Leo Tolstoy
%				&
%				---ลิโอ โตล์สตอย
%			\end{tabular} 
%		\end{center}
%		\index{words of wisdom}
%		\index{words of wisdom!Leo Tolstoy}
%		\index{quote!pre-condition}
		
\begin{Parallel}[c]{0.54\textwidth}{0.42\textwidth}
	\selectlanguage{english}
	\ParallelLText{
		``The most difficult subjects can be explained to the most slow-witted man if he has not formed any idea of them already; but the simplest thing cannot be made clear to the most intelligent man if he is firmly persuaded that he knows already, without a shadow of doubt, what is laid before him.''
		\begin{flushright}
			---Leo Tolstoy
		\end{flushright}
	}
	\selectlanguage{thai}
	\ParallelRText{
		``เรื่องที่ยากที่สุดสามารถอธิบายให้คนที่หัวช้าที่สุดเข้าใจได้ ถ้าเขาไม่ฝังใจคิดไปเองก่อนแล้ว.
		แต่เรื่องที่ง่ายที่สุดไม่อาจจะอธิบายให้คนที่ฉลาดที่สุดเข้าใจได้ ถ้าเขามัวยึดติดสิ่งที่เขาคิด 
		โดยที่ไม่สนใจความจริงที่อยู่ตรงหน้าเลยสักนิด.''
		\begin{flushright}
			---ลิโอ โตล์สตอย
		\end{flushright}
	}
\end{Parallel}
\index{english}{words of wisdom!Leo Tolstoy}
\index{english}{quote!pre-condition}
\vspace{0.5cm}
		
		แม้ว่า ความเชื่อหลักในวงการแพทย์ เชื่อว่า (1) จิตเกิดจากสมอง และ (2) ชีวิตสิ้นสุดเมื่อคนตาย.
		แนวคิดนี้ เอ็ดเวิร์ด เคลลี่\cite{Kelly2016a} เรียกว่า \textit{กายภาพนิยม} (physicalism).
		\textit{กายภาพนิยม} เป็นกรอบความคิด และมุมมองโลกที่มองว่า ทุกอย่างเป็นกายภาพ.
		นั่นรวมถึง ความคิดที่ว่า จิตก็เกิดมาจากกิจกรรมของสมอง สติและความรู้ตัวก็เป็นผลพลอยได้จากกิจกรรมของเซลล์ประสาท
		และเนื่องจากแนวคิดนี้เชื่อว่า จิตมาจากสมอง ดังนั้นเมื่อตัวตาย สมองหยุดทำงาน จิตจะจบหายไป.
		และถึงแม้ว่าคนส่วนใหญ่ก็เชื่อเช่นนั้น แต่แนวคิดนี้ก็ไม่ได้ถูกพิสูจน์ 
		หรือทดสอบอย่างเป็นทางการเลย
		จนกระทั่งงานศึกษาที่สำคัญของพาร์เนียและคณะ\cite{ParniaEtAl2001a} กับทีมของแวนโลมเมล\cite{vanLommelEtAl2001a}.
		
		%หนึ่งในการศึกษาเหล่านั้น รวมถึงการศึกษาของแซม พาร์เนีย (Sam Parnia) และคณะ.
		แซม พาร์เนีย เป็นแพทย์โรคหัวใจ ซึ่งเชี่ยวชาญในการกู้ชีพผู้ป่วยหัวใจวาย 
		เนื่องจากต้องการลดความเสี่ยงภาวะเจ้าชายนิทราของผู้ป่วย 
		พาร์เนียจึงได้ศึกษาวิจัยเกี่ยวกับ\textit{สติรู้ตัว} (consciousness) และรวมไปถึง
		การศึกษา\textit{ประสบการณ์เฉียดตาย} (Near Death Experience คำย่อ NDE) ของผู้ป่วย.
		
		\textit{ประสบการณ์เฉียดตาย} เป็นประสบการณ์การรับรู้ของผู้ป่วยที่อยู่ในสถานการณ์ที่ใกล้จะตาย หรือหลายครั้งผู้ป่วยหยุดหายใจ หัวใจหยุดเต้น และไม่มีกิจกรรมทางสมองแล้ว แต่แพทย์ พยาบาล เจ้าหน้าที่ สามารถกู้ชีพกลับมาได้.
		แม้ชื่อจะบอกว่าเป็น ประสบการณ์เฉียดตาย 
		แต่จริง ๆ แล้ว ส่วนใหญ่ผู้ที่มีประสบการณ์นี้ ก็คือ ผู้ป่วยที่ได้ตายไปแล้วในช่วงเวลาสั้น ๆ แต่ได้รับการกู้ชีพกลับมาสำเร็จ.
		ถึงแม้ จะมีรายงาน\textit{ประสบการณ์เฉียดตาย} จากอาการป่วยหลากหลายประเภท แต่งานวิจัยของพาร์เนียและคณะจะเน้นที่กลุ่มผู้ป่วยภาวะหัวใจวาย.
		%จากงานวิจัยนี้\cite{ParniaEtAl2001a} พบว่า
		%ในจำนวนผู้ป่วยที่รอดชีวิตและให้สัมภาษณ์ มีแค่ราว $11.1\%$ ที่มีความจำระหว่างที่หมดสติไป และส่วนใหญ่เป็นประสบการณ์ที่จัดว่าเป็น\textit{ประสบการณ์เฉียดตาย} (ตามเงื่อนไขที่กำหนดในงานวิจัย) และผู้ป่วยรู้สึกดีกับประสบการณ์.
		
		จากงานวิจัย\cite{ParniaEtAl2014a} พาร์เนียและคณะพบว่า
		ในจำนวนผู้ป่วยที่รอดชีวิตและให้สัมภาษณ์ มีราว ๆ 46\% ที่มีความทรงจำ
		โดย 9\%  จัดเป็น\textit{ประสบการณ์เฉียดตาย} (ตามเงื่อนไขที่กำหนดในงานวิจัย).
		มี 2\% ที่รู้ตัว โดย``เห็น'' หรือ ``ได้ยิน'' เหตุการณ์เกี่ยวกับการกู้ชีพอย่างชัดเจน.
		มีกรณีหนึ่งที่ยืนยันได้ว่า ช่วงที่ผู้ป่วยรู้ตัวอยู่นั้น ไม่พบกิจกรรมหรือสัญญาณทางสมอง.
		
		การที่มีการรู้ตัวในช่วงที่ไม่พบกิจกรรมทางสมอง
		อาจบอกได้ว่า (1) จิตไม่ได้ถูกสร้างจากสมอง 
		หรือ (2) วิธีการวัดในปัจจุบันไม่สามารถวัดกิจกรรมที่เกี่ยวข้องนี้ได้.
		%
		การอ้างการรู้ตัวในช่วงระหว่างการกู้ชีพได้ถูกตรวจสอบอย่างละเอียด.
		หนึ่งในการทดสอบก็คือ การทดสอบ\textit{ประสบการณ์ออกจากร่าง} (out-of-body experience) 
		ที่มักบรรยายถึง ความรู้สึกลอยออกจากร่างกายของตัวเอง และมองเห็นภาพต่าง ๆ จากมุมสูง.
		คณะของพาร์เนียเตรียมการทดสอบ
		โดยการติดตั้งหิ้งไว้ในห้องที่มีโอกาสสูงที่จะเกิดเหตุการณ์หัวใจวาย.
		บนหิ้ง จะวางรูปเอาไว้ โดยรูปหันหน้าขึ้นเพดาน ซึ่งผู้ที่อยู่ในห้องไม่สามารถที่จะมองเห็นภาพในรูป.
		ภาพในรูปจะใช้เพื่อพิสูจน์ความถูกต้องของคำบรรยายที่ได้จาก\textit{ประสบการณ์ออกจากร่าง}.
		การทดสอบ พบว่า ผู้ที่อ้าง\textit{ประสบการณ์ออกจากร่าง}สามารถบรรยายภาพได้อย่างถูกต้อง.
		%
		การบรรยายภาพในรูปได้ถูกต้อง บอกได้ว่า
		(1) การรับรู้สามารถแยกออกจากร่างกายได้
		และ (2) ประสบการณ์ที่บรรยายเป็นประสบการณ์จริง ไม่ใช่ความฝัน จินตนาการ หรือผลของกิจกรรมที่สมองสร้างขึ้นมาเอง.
		
		นอกจาก งานของพาร์เนียและคณะแล้ว ยังมีการศึกษาอื่น ๆ อีก\cite{vanLommelEtAl2001a, TuckerEtAl2017a} ที่สนับสนุนสมมติฐานว่า (1) จิตไม่ได้เกิดจากสมอง 
		และ (2) การรับรู้ของจิตสามารถแยกออกจากสมองได้.
		แม้ว่าจะมีหลักฐานสนับสนุนหนักแน่น แต่วงการจิตวิทยาและประสาทวิทยาส่วนใหญ่ ก็ยังเชื่อในแนวคิดเดิมอยู่
		ส่วนหนึ่งก็เพราะว่า แม้หลักฐานจะบอกว่า จิตไม่ได้เกิดจากสมอง 
		แต่ธรรมชาติของจิต การแยกออกจากสมอง ความสัมพันธ์กับสมอง ความสัมพันธ์กับชีวิต ชีวิตหลังความตาย กลไกที่อยู่เบื้องหลัง เงื่อนไขของประสบการณ์เฉียดตาย เรื่องเหล่านี้ วงการวิทยาศาสตร์ยังไม่รู้อะไรเลย.
		ปัจจุบันวงการวิชาการรู้เรื่องจิตน้อยมาก และหลาย ๆ อย่างที่คิดว่ารู้ ก็อาจจะไม่ถูกต้อง.
		
\vspace{0.5cm}		
\begin{Parallel}[c]{0.48\textwidth}{0.35\textwidth}
	\selectlanguage{english}
	\ParallelLText{
		``We should not be ashamed to acknowledge truth from whatever source it comes to us, 
		even if it is brought to us by former generations and foreign peoples. For him who seeks the truth there is nothing of higher value than truth itself.''
		\begin{flushright}
			---Al-Kindi
		\end{flushright}
	}
	\selectlanguage{thai}
	\ParallelRText{
		``เราไม่ควรอายที่จะยอมรับความจริง ไม่ว่าเราได้รับมันมาจากไหน 
		ถึงแม้ว่ามันจะมาจากคนรุ่นก่อนหรือมาจากคนต่างชาติ. 
		สำหรับผู้แสวงหาความจริง ไม่มีอะไรมีค่ามากกว่าความจริง.''
		\begin{flushright}
			---อัลคินดี
		\end{flushright}
	}
\end{Parallel}
\index{english}{words of wisdom!Al-Kindi}
\index{english}{quote!truth}
		
		
		\paragraph{\small การกลับชาติมาเกิด}
		\index{english}{reincarnation}
		ในขณะที่ เรายังไม่เข้าใจความสัมพันธ์ของจิตและชีวิต
		สิ่งหนึ่งที่น่าสนใจ และอาจจะช่วยเติมภาพความสัมพันธ์นี้ให้ดีขึ้น 
		คือ การศึกษาเรื่อง\textit{การกลับชาติมาเกิด} (reincarnation).
		%
		ภาควิชาการศึกษาการรับรู้ มหาวิทยาลัยเวอร์จิเนีย (Division of Perceptual Studies, University of Virginia) ดำเนินการศึกษาเรื่อง\textit{การกลับชาติมาเกิด}มากว่า 50 ปี ซึ่งทัคเกอร์และคณะ\cite{TuckerEtAl2017a} ได้สรุปสาระสำคัญของผลจากการศึกษาว่า
		เด็กที่ระลึกชาติได้
		%\begin{itemize}
		%\item 
		มีมากกว่า 2,500 คนทั่วโลก
		%\item 
		เป็นเด็กอายุน้อยมาก ๆ (ไม่เกิน 6 ขวบ)
		%\item 
		พูดถึงชาติที่แล้ว ซึ่งเป็นชีวิตของคนธรรมดา ๆ
		%\item 
		ราวๆ 70\%  จะพูดถึงชาติที่แล้วที่ไม่ได้ตายตามธรรมชาติ เช่น ถูกฆ่าตาย
		%\item 
		หลาย ๆ คน มีอารมณ์หรือพฤติกรรม ที่สัมพันธ์กับคนในชาติที่แล้วที่อ้างถึง
		%\item 
		เด็กบางคนมีปานหรือตำหนิตั้งแต่เกิด ที่เข้ากับแผลของคนในชาติที่แล้วที่อ้าง
		เช่น มีเด็กอินเดียคนหนึ่งระลึกได้ว่า ชาติที่แล้ว เขาเกิดอุบัติเหตุ เครื่องจักรตัดนิ้วมือขวาเขาออกไป 
		ตัวเด็กเองเกิดมา โดยไม่มีนิ้วมือขวา แต่มือซ้ายปกติ
		%\end{itemize}
		
		เรื่องการกลับชาติมาเกิดไม่ได้เกี่ยวกับเชื้อชาติ หรือความเชื่อ
		เช่น กรณีของหนูน้อยเจมส์ ไลนินเกอร์ (James Leininger)
		ที่เป็นลูกชายของครอบครัวชาวคริสต์ที่หลุยส์เซียน่า สหรัฐอเมริกา
		เดิมครอบครัวไม่ได้เชื่อเรื่องการกลับชาติมาเกิดเลย.
		%
		แต่ช่วงราว ๆ เจมส์อายุได้สองขวบ
		เจมส์ก็เริ่มมีฝันร้ายบ่อย ๆ.
		เจมส์ร้อง ดิ้น เตะขาในอากาศ
		``ไฟไหม้เครื่องบิน หนูน้อยออกไปไม่ได้''
		(``Airplane catches on fire.
		Little man can't get out.'')
		%
		เวลากลางวัน เจมส์เอาเครื่องบินมาเล่น แล้วก็เล่นทำเครื่องบินตก ทำแบบนั้นซ้ำ ๆ
		พอพ่อคุยกับเจมส์ เจมส์เล่าว่า เครื่องเขาถูกยิงตกโดยพวกญี่ปุ่น
		เจมส์ว่าเขาขับเครื่อง\textit{คอร์แซร์} (Corsair).
		%
		ตอนอายุ 28 เดือน เจมส์บอกว่าเขาบินออกจากเรือ
		พอพ่อถามถึงเรือ เจมส์บอกว่าเรือชื่อ \textit{นาโทม่า}.
		ซึ่งช่วงสงครามโลกครั้งที่สอง ก็มีเรือรบ\textit{ยูเอสเอส นาโทม่า เบย์} (USS Natoma Bay) ที่ประจำการอยู่ในแปซิฟิก
		พอวาดรูป เจมส์ก็วาดแต่รูปเครื่องบินตก วาดเป็นสิบ ๆ รูป
		จนพ่อของเจมส์เริ่มคิดว่า หรือว่าเจมส์ระลึกชาติได้จริง ๆ
		
		ตอนเจมส์อายุ 4 ขวบครึ่ง พ่อของเจมส์ไปร่วมงานสังสรรค์ทหารเกษียณของ \textit{ยูเอสเอส นาโทม่า เบย์}
		ถึงได้รู้ว่า มีนักบินคนเดียวในปฏิบัติการที่ถูกฆ่าตาย 
		นักบินคนนั้นชื่อ เจมส์ ฮูสตัน (James Huston).
		เมื่อคณะนักวิจัยเปรียบเทียบ
		สิ่งที่หนูน้อยเจมส์พูดกับประวัติของฮูสตันก็พบว่า
		
		%		{\small
		\begin{tabular}{ >{\arraybackslash}p{2.8in} | >{\arraybackslash}p{2.8in} }
			หนูน้อยเจมส์ ไลนินเกอร์ & เจมส์ ฮูสตัน \\
			\hline
			$\bullet$ เซ็นต์ชื่อในรูปวาดว่า เจมส์ที่สาม (James 3) & $\bullet$ เป็น เจมส์ จูเนียร์ (James, Jr.) \\
			$\bullet$ บอกว่าบินออกจากนาโทม่า &  $\bullet$ เป็นนักบินของ ยูเอสเอส นาโทม่า เบย์ \\
			$\bullet$ บอกว่าบินเครื่องคอร์แซร์ & $\bullet$ เคยบินเครื่องคอร์แซร์ \\
			$\bullet$ บอกว่าถูกยิงตกโดยทหารญี่ปุ่น & $\bullet$ ถูกยิงตกโดยทหารญี่ปุ่น \\
			$\bullet$ บอกว่าตายที่ฮิโรชิม่า & $\bullet$ เป็นนักบินคนเดียวของ ยูเอสเอส นาโทม่า เบย์ ที่ถูกยิงตกตายในปฏิบัติการฮิโรชิม่า \\
			$\bullet$ บอก ``เครื่องบินผมถูกยิงที่เครื่อง ตกลงน้ำ นั่นหละที่ผมตาย'' 
			%			(``My airplane got shot in the engine and crashed in the water and that's how I died.'')
			& $\bullet$ พยานที่เห็นเหตุการณ์รายงานว่า ``ถูกยิงส่วนหน้าตรงกลางเครื่อง'' 
			%			(``hit head on right in the middle of the engine.'') 
			\\
			$\bullet$ ฝันร้ายถึงเครื่องบินตกและจมน้ำบ่อย ๆ & $\bullet$ เครื่องตกน้ำ และจมลงอย่างรวดเร็ว \\
			$\bullet$ บอกว่าเพื่อนผม แจ๊ค ลาร์เซน (Jack Larsen) อยู่ที่นั่นด้วย
			& $\bullet$ แจ๊ค ลาร์เซน เป็นนักบินเครื่องที่อยู่ใกล้กับเครื่องของฮูสตัน วันที่ฮูสตันเครื่องตกตาย \\
			\hline
		\end{tabular} 
		%	}%small
		%14:46 รายการเปรียบเทียบ
		\vspace{0.5cm}
		
		ในปี พ.ศ. 2560 หนูน้อยเจมส์ ไลนินเกอร์ อายุ 18 ปี เรียนจบมัธยมและได้เข้าทำงานกับกองทัพเรือ.
		
%		\begin{center}
%			\begin{tabular}{ >{\arraybackslash}m{3.3in}  >{\arraybackslash}m{2.3in} }
%				``Your assumptions are your windows on the world. Scrub them off every once in a while, or the light won't come in.''
%				&
%				``ทิฐิเป็นเสมือนหน้าต่างที่มองโลกของคุณ ขัดมันออกบ้าง ไม่อย่างนั้นแสงมันจะไม่ส่องเข้ามา''
%				\\
%				---Isaac Asimov 
%				&
%				---ไอแซค อาซิมอฟ
%			\end{tabular} 
%		\end{center}
%		\index{words of wisdom}

\vspace{0.5cm}		
\begin{Parallel}[c]{0.5\textwidth}{0.36\textwidth}
	\selectlanguage{english}
	\ParallelLText{
		``Your assumptions are your windows on the world.
		 Scrub them off every once in a while, or the light won't come in.''
		\begin{flushright}
			---Isaac Asimov 
		\end{flushright}
	}
	\selectlanguage{thai}
	\ParallelRText{
		``ทิฐิเป็นเสมือนหน้าต่างที่มองโลกของคุณ ขัดมันออกบ้าง
		 ไม่อย่างนั้นแสงมันจะไม่ส่องเข้ามา.''
		\begin{flushright}
			---ไอแซค อาซิมอฟ
		\end{flushright}
	}
\end{Parallel}
\index{english}{words of wisdom!Isaac Asimov}
\index{english}{quote!pre-condition}
		
		
		%แม้ว่า ทัคเกอร์และคณะ\cite{TuckerEtAl2017a}จะยังไม่รู้กลไกของการกลับชาติมาเกิด หรือเงื่อนไขของการระลึกชาติได้
		%แต่ หลักฐานที่มี ยืนยันได้ว่า\textit{การกลับชาติมาเกิด}มีจริง.
		%การกลับชาติมาเกิดอาจจะเป็นความต่อเนื่องของจิต ที่แยกออกจากร่างเดิม และเข้าไปติดกับร่างใหม่ก็ได้.
		%reincarnation end at 16:30
		
		\paragraph{\small ประสบการณ์เฉียดตาย}
		\index{english}{near death experience}
		นอกจากการกลับชาติมาเกิด ทัคเกอร์และคณะ\cite{TuckerEtAl2017a} ยังได้สรุปงานศึกษา\textit{ประสบการณ์เฉียดตาย} ที่ดำเนินการมาร่วม 40 ปี ของภาควิชาการศึกษาการรับรู้ ไว้ว่า
		\textit{ประสบการณ์เฉียดตาย} พบได้ประมาณ 20\% ในผู้ป่วยหัวใจวาย %at 18:19min
		บรูซ เกรสัน (Bruce Grayson) หนึ่งในคณะได้เสนอแบบจำลอง ที่ใช้วัดความเข้มข้นของ\textit{ประสบการณ์เฉียดตาย} จากสี่ส่วนประกอบ
		ได้แก่ (1) การเปลี่ยนกระบวนการความคิด,
		(2) การเปลี่ยนสถานะของอารมณ์ความรู้สึก,
		(3) ลักษณะเชิงปาฏิหารย์,
		และ (4) ลักษณะเชิงโลกอื่น.
		
		การเปลี่ยนกระบวนการความคิด เช่น ความรู้สึกถึงการปราศจากเวลา (sense of timelessness),
		ความคิดที่รวดเร็วและชัดเจนกว่าปกติ, 
		การทบทวนชีวิต (life review) ที่ผู้ป่วยรายงานว่า เห็นชีวิตที่ผ่านมาทั้งหมดฉายผ่านตา เหมือนกับเป็นสรุปของชีวิต,
		ความรู้สึกว่าเข้าใจ รู้สิ่งต่าง ๆ ชัดเจนแจ่มแจ้ง.
		%
		การเปลี่ยนแปลงกระบวนการความรู้สึก เช่น 
		ความรู้สึกถึงความสงบ ความพอใจ ความรู้สึกดี (sense of peace and well-being), 
		รู้สึกมีความสุข (sense of joy), 
		รู้สึกเป็นหนึ่งเดียว (sense of oneness or cosmic unity), รู้สึกถึงความรักและความอบอุ่น.
		%
		ลักษณะของปาฏิหารย์ เช่น การมีชีวิตชีวาของสัมผัสต่างๆ ที่ผู้ป่วยรายงานว่า เห็นสีสันต่าง ๆ ที่ไม่เคยเห็นในโลกมาก่อน ได้ยินเสียงที่ไม่เคยได้ยินมาก่อน,
		การรับรู้ถึงเหตุการณ์ต่าง ๆ ที่เกิดขึ้น ระหว่างที่ผู้ป่วยหัวใจวาย,
		การรู้เห็นถึงอนาคต, การรู้สึกว่าได้ออกจากร่าง.
		%
		ลักษณะของการสัมผัสโลกอื่น เช่น การได้เข้าไปในโลกอื่น, 
		การได้พบกับสิ่งมีชีวิตที่ลึกลับ,
		การได้พบกับวิญญาณของคนที่ตายไปแล้ว,
		การได้พบกับจิตวิญญาณเชิงศาสนา,
		หรือว่า การได้ไปถึง\textit{จุดที่กลับไม่ได้} (a point of no return) ที่หากข้ามไปแล้ว จะกลับไม่ได้.
		
		%(1) การเปลี่ยนแปลงความคิด (thought processes)
		%- sense of timelessness
		%- thinking has been faster and clearer than usual
		%- life review - panoramic memory
		%- sense of understanding / revelation
		%where everything becomes crystal clear 
		%(2) การเปลี่ยนแปลงกระบวนการความรู้สึก (emotional states)
		%- sense of peace and well-being
		%- feeling of joy and sense of oneness
		%- sense of being loving, warming of light
		%(3) ``ปาฏิหารย์'' paranormal features
		%- sensory vivid: seeing colors they have never seen on Earth
		%hearing sounds they've never heard before
		%- frank perception of things going on
		%- sense of future
		%- sense of leaving physical body
		%(4) ``ปาฏิหารย์อื่น ๆ'' otherworldly features
		%- being in otherworldly realm
		%unearthly/mystical realm
		%- encounter mystical beings
		%- seeing deceased spirits / religious spirits
		%- going to the point of no-return (if go beyond you can't come back)
		
		%NDE has all four with varying degrees.
		
		บรูซ เกรสัน บอกว่า \textit{ประสบการณ์เฉียดตาย}ส่วนใหญ่จะมีลักษณะดังกล่าวผสม ๆ กัน โดยสัดส่วนแตกต่างกันไปตามแต่ละคน โดยได้ยกตัวอย่าง\textit{ประสบการณ์เฉียดตาย}ของผู้หญิงคนหนึ่ง
		ที่เล่าว่า
		
		``ในช่วงสงคราม ฉันนอนป่วยอยู่ในโรงพยาบาล.
		เช้าวันหนึ่ง นางพยาบาลเข้ามา และพบว่าฉันไม่มีสัญญาณชีพใด ๆ เลย.
		นางพยาบาลตามหมอมา ซึ่งหมอก็พบว่าฉันตายแล้วเช่นกัน
		และฉันก็ตายอยู่อย่างนั้นราวๆ 20 นาที ตามที่หมอบอกฉันในภายหลัง.
		
		ฉันรับรู้แสงสว่างแพรวพราว ที่ฉันรู้สึกถูกเย้ายวนตามมันไป.
		ตอนนั้นเหมือนกับว่า เวลามันแตกต่างออกไป เหมือนมันไม่มีเวลาอยู่ที่นั่น ไม่ว่าที่นั่น มันจะคือที่ไหน.
		แสงนั้นสวยงามมาก และมันก็ให้ความรู้สึกของ\textit{ความรักที่ปราศจากเงื่อนไข} (unconditional love) และความสงบสุข.
		%
		เมื่อมองไปรอบๆ ฉันก็พบว่า ฉันอยู่ในที่ที่สวยงาม เขียว เป็นเนินขึ้นลง.
		แล้วฉันก็เห็นนายทหารหนุ่มกับทหารอีกหลายนายเดินเข้ามา.
		นายทหารหนุ่มเป็น อัลบิน ญาติคนโปรดของฉัน.
		ตอนนั้น ฉันไม่รู้ว่าอัลบินตายแล้ว และฉันก็ไม่เคยเห็นอัลบินในชุดเครื่องแบบมาก่อนด้วย.
		แต่ว่าสิ่งที่ฉันเห็น ก็ยืนยันได้จากภาพถ่ายที่ฉันได้เห็นหลายปีหลังจากนั้น.
		ฉันคุยกับอัลบินอย่างมีความสุขอยู่สักพัก แล้วอัลบินกับเพื่อนทหารก็เดินแถวออกไป.
		%
		แล้วคนข้าง ๆ ฉันก็อธิบายว่า ทหารเหล่านี้ได้รับอนุญาตให้ไปทักทายคนอื่น ๆ ที่เพิ่งตาย และช่วยแนะนำเขากับความตาย.
		%
		ความทรงจำที่มีชีวิตชีวาต่อมา ก็คือการมองจากความสูงประมาณเพดานลงไปที่เตียง
		บนเตียง มีร่างซูบผอมนอนอยู่.
		มีหมอและพยาบาลอยู่รอบ ๆ เตียง.
		ฉันตะโกนเรียก แต่ไม่มีใครได้ยินฉัน.
		%
		ฉันเห็นทุกอย่างอย่างชัดเจน และรู้สึกอบอุ่น ปลอดภัย และสุขสงบ.
		
		อึดใจต่อมา ฉันมองขึ้นไปเห็นหมอกับพยาบาลเหล่านั้น
		และก็รู้สึกผิดหวังอย่างแรง.
		ฉันพึ่งออกมาจากสิ่งที่น่าเบิกบานใจ น่าพอใจอย่างที่สุด.
		%
		สองวันหลังจากนั้น หมอเข้ามาคุยกับฉันว่า ฉันโชคดีที่ยังไม่ตาย.
		ฉันตอบหมอไปว่า ฉันตายไปแล้ว.
		หมอมองฉันแบบแปลกๆ แล้วก็นัดให้ฉันไปประเมินสภาพจิต.
		และฉันก็ได้เรียนรู้ที่จะหุบปากเรื่องนี้ ตั้งแต่นั้นเป็นต้นมา.''
		\\
		
		%Example of one woman (at 20:10)
		%During the war, I was very ill in the hospital.
		%One morning nurse came in and found me showing no sign of life whatever.
		
		%She called the doctors to whom I also appeared dead and I remained so --- they told me afterwards--- for at least 20 minutes.
		
		%I became aware of a brilliant light and felt drawn toward it.
		%It seemed that time was different or non existent there, wherever there was.
		
		%The light was beautiful to look at and projected feelings of unconditional love and peace.
		%Looking around, I found myself in a beautiful green undulating country.
		
		%I then saw a young officer with a few soldiers approaching. The officer was my favorite cousin, Albin. I did not know that he had died, nor had I ever seen him in uniform. But what I saw him was confirmed by a photograph I had seen many years later. We spoke for a few minutes happily, and then he and the few men with him marched off.
		
		%Then a presence beside me explaining that these soldiers were allowed to go and greet others who were dying and help them meet their death.
		
		%My next vivid recollection after this was of looking down from about ceiling height onto a bed on which laid a very emaciated body.
		
		%There were doctors and nurses around it. I yelled out to them, but they couldn't hear me. I could see everything clearly and felt warm, safe, and peaceful.
		
		%In a few moments, I was looking up at them and feeling sensation of intense disappointment. 
		%I had come back from something so lovely and so utterly satisfying.
		
		%บรูซ เกรสันได้ยืนยันถึงความน่าเชื่อถือของความทรงจำเกี่ยวกับ\textit{ประสบการณ์เฉียดตาย} ว่า เนื่องจากงานวิจัยนี้ทำมาหลายสิบปีแล้ว และในปี ค.ศ. 2002 ทีมผู้วิจัยได้ติดต่อกับผู้มีประสบการณ์เฉียดตายที่ได้เคยสัมภาษณ์ไปในช่วงปี ค.ศ. 1980-1989 และพบว่า ค่าคะแนนความเข้มข้นของประสบการณ์เฉียดตายที่ได้จากวัดในปี คศ 2002 ไม่ต่างจากค่าคะแนนเดิมที่วัดในช่วงปี ค.ศ. 1980-1989 เลย.
		
		% @22:31 How reliable NDE is?
		
		%Now one of the problem we have in researching near death experiences is that for the most part, they're retrospective.
		%We're getting account from people who had the experiences sometime in the past.
		
		%That leaves open the question of how reliable memories of NDEs really are.
		%Some authors have speculated that memories are embellished over the years.
		
		%In particularly, that the sense of well-being and peace and the pleasantness of the experience gets embellished over time.
		
		%Because we've been studying these experiences for four decades now, we're able to address this question.
		
		%Starting in 2002, I started trying to reconnect with people I had interviewed in the 1980s about their near death experiences and asked them to describe their NDEs for me again.
		
		%What we found is that the NDE scale scores measuring the depth of the NDE were the same now in the 2000s as they were in the 1980s.
		%And that held true for all four of the components, changes in thinking, changes in feeling, paranormal, and transcendental.
		%So memories of the NDE are, indeed, reliable over years.
		%And that suggests that retrospective research is also reliable.
		
		%(cognitive, affective, paranormal, transcendental)
		
		
		เกรสันอภิปรายว่า อิทธิพลของความเชื่อและวัฒนธรรมไม่ได้มีผลต่อ\textit{ประสบการณ์เฉียดตาย} 
		แต่ความเชื่อและวัฒนธรรมมีอิทธิพลต่อการตีความของ\textit{ประสบการณ์เฉียดตาย}
		เช่น ผู้ผ่านประสบการณ์เฉียดตายในโลกที่สามจะบรรยายถึง ถ้ำ หรือบ่อน้ำ แทนอุโมงค์ ที่ผู้ผ่านประสบการณ์เฉียดตายในอเมริกาบรรยาย.
		
		%@23.37
		
		%Another important question about retrospective reports of NDEs is whether they're influenced by cultural beliefs.
		
		%We know that people's cultural beliefs influence how they interpret their perceptions.
		%We see what we expect.
		
		%For example, near death experiences of third world countries do not talk about entering a tunnel the way Americans do. They would talk about entering a cave or a well.
		
		%One truck driver who I interviewed talked about entering a tailpipe.
		
		%So you have to use whatever cultural metaphors at your disposal to describe the phenomenon.
		
		%So our NDEs just reporting what they expect to happen when they come close to death.
		%The image of NDEs that most people have nowsadays is the one described by Raymond Moody in 1975. Now we've been collecting NDEs here at UVA since 1960s, years before Moody's book came out. So we compared 24 experiences we collected in the 1960s with 24 recent experiences that were matched with the original ones in terms of age, race, gender, religion, cause of death and proximity to death.
		
		%What we found is that the features that Moody reported, were reported just as often before the experience and after the experience.
		
		%(Out-of-body, feeling of peace, meeting others, being of light, music or noise, life review)
		
		%No matter what we looked at.
		%The out-of-body experience, the feeling of peace, meeting others, a being of light, noises, or life review all reported before Moody had described them as often as they are now.
		
		%And they also hold true for the after effects that Moody reported, attitude changes, loss of fear of death, difficulty telling others, belief in survival after life, and corrobaration of extrasensory perceptions.
		%All reported as often before Moody described them as after.
		
		%So report do not seem to be influenced by the widespread public knowledge of NDEs.
		
		%@25:33
		%Although the interpretation of the phenomenon may be influenced by culture, the actual experience appears not to be.
		
		คณะผู้วิจัยได้ทำการศึกษาและยืนยันถึงความน่าเชื่อถือของความทรงจำ
		ใน\textit{ประสบการณ์เฉียดตาย}ที่คงเส้นคงวา
		แม้ว่าจะเปรียบเทียบการให้สัมภาษณ์ถึง\textit{ประสบการณ์เฉียดตาย}
		ที่คณะผู้วิจัยกลับไปสัมภาษณ์หลังการสัมภาษณ์เดิมที่เวลาต่างกันร่วม 10 ถึง 20 ปี.
		และ
		เพื่อตอบคำถามว่าความทรงจำใน\textit{ประสบการณ์เฉียดตาย} เป็นความทรงจำของเหตุการณ์จริงๆ ไม่ใช่แค่ความทรงจำของจินตนาการ หรือจากภาพหลอน
		%
		คณะผู้วิจัยใช้\textit{แบบสอบถามลักษณะพิเศษของความทรงจำ} (memory characteristics questionnaire\cite{JohnsonEtAl1988a}) ที่ออกแบบมาเพื่อจำแนกแยก ความทรงจำของเหตุการณ์จริง ออกจากความทรงจำของเหตุการณ์ในจินตนาการ.
		
		%But even though these memories of NDEs are reliable and consistent over decades, that doesn't establish that their memories are real events rather than memories of fantasies or hallucinations.
		
		%@25:48
		
		%To test that possibility, we use the memory characteristics questionnaire, which was designed to differentiate memories of real events from memories of imagined events.
		
		\textit{แบบสอบถามลักษณะพิเศษของความทรงจำ} ทดสอบความทรงจำใน 5 แง่มุม 
		%ได้แก่
		%ความชัดเจนของความทรงจำ (clarity of memories),
		%ด้านการรับสัมผัส (sensory aspects),
		%บริบท (context),
		%ความคิดและความรู้สึก (thoughts and feelings),
		%และความเข้มข้นของความรู้สึก (intensity of feeling)
		ซึ่งสามารถแยกความทรงจำของเหตุการณ์จริง ออกจากเหตุการณ์สมมติ หรือเหตุการณ์ในจินตนาการได้อย่างน่าเชื่อถือ.
		แง่มุมต่างๆ ได้แก่
		แง่ความชัดเจนของความทรงจำ (clarity of memories) ซึ่งรวมถึง รายละเอียดของสิ่งที่เห็น,
		แง่การรับสัมผัส (sensory aspects) เช่น เสียง กลิ่น รส,
		แง่ของบริบท (contextual features) เช่น ความทรงจำเกี่ยวกับตำแหน่ง และ การจัดเรียงเชิงพื้นที่ (spatial arrangements),
		แง่ความคิดและความรู้สึก (thoughts and feelings) ระหว่างที่ระลึกถึงเหตุการณ์,
		และแง่ความเข้มข้นของความรู้สึก (intensity of feeling) ระหว่างเหตุการณ์และขณะรำลึกถึง.
		
		%This memory characteristics questionnaire .. into five aspects of memories (clarity of memories, sensory aspects, context, thoughts and feelings, and intensity of feelings) that reliably differentiate memories of real from imagined events.
		%It includes the clarity of the memories including the visual details, sensory aspects, like sound, smell, taste, in the memory, contextual features, like the memory for location and spatial arrangements, thoughts and feelings during the recalled event, and the intensity of feelings both during the event and now remembering it.
		
		คณะผู้วิจัยประเมินผู้ผ่านประสบการณ์เฉียดตาย สำหรับเหตุการณ์ประสบการณ์เฉียดตาย 
		เหตุการณ์จริงอื่นที่เกิดขึ้นในชีวิตในเวลาใกล้เคียงกัน
		และเหตุการณ์ในจินตนาการที่เกิดขึ้นในช่วงเวลานั้น.
		%
		%We asked people who had come close to death to rate their memories of that event, and also of real events
		%that happened around the same time in their lives.
		%And also about an imagined event from that time in their lives.
		%
		การทดสอบพบว่า ผู้ผ่านประสบการณ์เฉียดตายจำ\textit{ประสบการณ์เฉียดตาย} ได้ชัดเจน ละเอียด มีบริบท และด้วยความเข้มข้นของความรู้สึก
		ที่มากกว่า เหตุการณ์จริงอื่นที่เกิดในช่วงเวลาใกล้เคียงกัน.
		\textit{ประสบการณ์เฉียดตาย}ถูกระลึกถึงว่า จริงกว่าเหตุการณ์จริง
		ในระดับขั้นเดียวกับ ที่เหตุการณ์จริง จริงกว่าเหตุการณ์ในจินตนาการ.
		%
		ในขณะที่ผู้ที่ไม่ได้มี\textit{ประสบการณ์เฉียดตาย} แต่ผ่านเหตุการณ์กู้ชีพในลักษณะคล้ายกัน 
		จะรายงานความทรงจำช่วงเหตุการณ์ชีวิตนั้น ว่าจริงในระดับขั้นเดียวกันกับเหตุการณ์จริงอื่น ๆ เท่านั้น ไม่ได้พบว่าจริงมากกว่า.
		
		%What we found is that for those people who had NDEs, the near death experience was remembered with more clarity, more detail, more context, and more intense feelings than real events from the same time period.
		%NDEs were recalled as realer than real events to the same degree that real events remembered as realer than the imaginary events.
		
		%On the other hand, people who did not have NDEs reported their close brush with death to be as real as other real events, but not realer.
		
		%So NDEs are remembered with great consistency over decades, and they're recalled as realer than real.
		
		%(Memory characteristics questionnaire, Johnson, et al., 1988\cite{JohnsonEtAl1988a})
		
		เกรสันและคณะยังไม่พบปัจจัยใดที่จะสามารถทำนายถึงผู้ที่จะมี\textit{ประสบการณ์เฉียดตาย}ได้ ไม่ว่าจะเป็นปัจจัย อายุ เชื้อชาติ เพศ ศาสนา ความเคร่งศาสนา หรืออาการป่วยทางจิต
		และได้ให้ข้อสังเกตว่า แม้จะมีแนวคิดที่พยายามเชื่อมโยง สภาวะทางสรีรวิทยา ทางกายภาพ ทางชีวภาพ เข้ากับ\textit{ประสบการณ์เฉียดตาย}
		แต่ที่สุดแล้ว 
		มันก็ยากที่จะอธิบายถึง ความสามารถของสมองที่เพิ่มขึ้น การคิดและรับรู้ได้ชัดเจนขึ้น ในขณะที่สมองไม่สมบูรณ์ ไม่ว่าจากยาสลบ หรือจากภาวะหัวใจวาย.
		
		%@27:31
		
		%How do we explain them?
		%There are no variables that we found yet that can predict whether someone's going to have an NDE.
		
		%Neither age, race, gender, religion, religiosity (= strong religious feeling or belief), or mental illness. 
		%There's been lots of speculation about physiological variables that may be involved in NDEs, but the bottom line is that it's hard to reconcile enhanced mental function, thinking and perception being clearer and sharper than ever before with the impaired brain function as you have in deep anesthesia or cardiac arrest.
		
		แม้ว่า\textit{ประสบการณ์เฉียดตาย} อาจเป็นเงื่อนงำของการแยกกันระหว่างจิตกับสมอง  
		หรืออาจเป็นหลักฐานสำคัญของชีวิตหลัง\atom{ความตาย}
		แต่สิ่งที่น่าสนใจที่สุดเกี่ยวกับ\textit{ประสบการณ์เฉียดตาย}
		ก็คือ ผลจากการผ่าน\textit{ประสบการณ์เฉียดตาย}.
		ผู้ที่ผ่าน\textit{ประสบการณ์เฉียดตาย}จะมีการเปลี่ยนแปลงในเชิงความเชื่อ ทัศนคติ ค่านิยม
		ได้แก่ มีความเชื่อและศรัทธาในเรื่องของจิตวิญญาณมากขึ้น (increase in spirituality),
		มีความเป็นห่วงเป็นใยมีเมตตาต่อผู้อื่นมากขึ้น (increase in sense of concern/compassion for others),
		ตระหนักในค่าของชีวิตมากขึ้น (increase in appreciation of life),
		ใช้ชีวิตมีคุณค่า มีความหมายมากขึ้น (increase in sense of meaning or purpose),
		มีความมั่นใจ มีความยืดหยุ่นในทักษะการรับมือกับสถาณการณ์ต่าง ๆ ได้ดีขึ้น (increase in confidence and flexibility in coping skills),
		และเชื่อในชีวิตหลังความตาย (a belief in postmortem survival).
		%
		%@28:06
		%So why are near death experiences of interest to health professionals.
		%
		%One reason is that there's a consistent pattern of after effects from near death experiences.
		%
		%Changes in beliefs, attitudes, and values, and it's been corroborated with long term studies and interviews with significant others.
		%
		%@28:20
		%We see increases in spirituality, a sense of concern or compassion for others, appreciation of life, a sense of meaning or purpose, confidence and flexibility in your coping skills, and a belief in postmortem survival.
		%
		ในขณะเดียวกัน
		ผู้ผ่านประสบการณ์เฉียดตาย
		จะลดการกลัวตายลง (decrease in fear of death),
		มีความสนใจในวัตถุนิยมลดลง (decreased interest in material possession),
		ลดความสนใจในสถานะ อำนาจ เกียรติ และชื่อเสียงลง (decreased interest in status, power, prestige, and fame),
		ลดความสนใจในการแก่งแย่งชิงดีชิงเด่นลง (decreased interest in competition).
		
		ถึงตรงนี้ อาจทำให้เกิดคำถามว่า ถ้า\textit{ผู้ผ่านประสบการณ์เฉียดตาย}ไม่กลัวตาย และพบว่าความตายนั้นเป็นสุขและสวยงาม
		ทำไมเขาไม่ฆ่าตัวตายไปเลย
		แต่กลับรักและชื่นชมคุณค่าของชีวิต และใช้ชีวิตอย่างมีความหมาย.
		คำถามนี้ ทัคเกอร์ เกรสัน และคณะไม่ได้อภิปรายไว้.
		แต่หากลองใคร่ครวญพิจารณาด้วยตนเองแล้ว จะพบว่าชีวิตคนนั้นแปลก.
		คนที่เห็นความตาย กลับไม่กลัวตาย.
		คนที่กลัวตาย ไม่เคยเห็นความตาย.
		คนไม่กลัวความตาย กลับเข้าใจชีวิต ใช้ชีวิตได้ดี ใช้ชีวิตอย่างมีคุณค่า.
		แต่คนทั่วไปที่ส่วนใหญ่กลัวความตาย หลายคนเลือกใช้ชีวิตทิ้งเปล่าไป.
		%ติดโทรศัพท์ ติดเหล้า ติดการพนัน
		หลายคนเลือกเล่นโทรศัพท์มือถือ แทนการมีปฏิสัมพันธ์กับคนรอบข้าง.
		%หลายคนเลือกที่จะแก่งแย่งยศ ตำแหน่ง สาย
		หลายคนเลือกใช้ชีวิตเห็นแก่ตัว 
		เลือกเป้าหมายชีวิตเป็นความร่ำรวย สถานะ ชื่อเสียง
		ตอบสนองต่ออัตตาที่ขยายไม่รู้จบ
		แล้วเรียกมันว่า ความสำเร็จ.
		หลายคนทิ้งคุณค่าของชีวิต ทิ้งความสงบสุข เพื่อใช้ชีวิตที่ฟุ้งเฟ้อ.
		หลายคนทิ้งความกล้าที่จะทำในสิ่งที่ถูกต้อง ทิ้งความซื่อสัตย์มั่นคงที่จะยืนหยัดในหลักการที่อ้าง %ทั้งใจ วาจา และการกระทำ
		ทิ้งเมตตา ทิ้งปัญญา อันเป็นคุณธรรมอันสูงสุด ทั้งโดยรู้ตัวและไม่รู้ตัว.
		หลายคนกลัวความตาย แต่กลับไม่เคยใช้ชีวิตให้มีคุณค่าเลย.
		ประเด็นนี้ก็เป็นอีกปริศนาของชีวิตที่ยากจะอธิบาย
		และข้อสังเกตนี้ก็ได้ถูกกล่าวไว้อย่างงดงามโดยท่านดาไลลามาองค์ที่สิบสี่ แห่งธิเบตดังนี้.
		
		%@28:38
		%Along with these, we see decreases in fear of death, the decreased interest in material possessions, decreased interest in status, power, prestige, and fame, and decreased interest in competition.
		
		%@28:50
		
		%A second reason that NDEs are important to us is what they suggest about survival of bodily death.
		%As Dr. Tucker mentioned, our Division was founded to explore the possibility that something may survive after death, and NDEs do provide some evidence on that question.
		
		%@29:10
		%For example, we have enhanced cognition when a brain is impaired, 
		%such as by anesthesia or cardiac arrest, which suggests that the mind is not just what the brain does. 
		
		%Secondly, we have accurate perceptions from an out-of-body perspective. A recent review of over 100 published cases of people who had left their bodies during an NDE and reported seeing things showed that greater than 90% were 100% accurate.
		
		%Further evidence of potential independence of mind and brain.
		
		%Third, we have accurate information that's imparted by deceased visitors in the NDE such as the location of an important document or a hidden treasure, which is evidence that these were encounters with interactive beings not just mental images of the decreased.
		
		%A shocking example of this are NDEs in which the person meets in the experience someone who was not known at the time to be dead. 
		
		%An example with experiencer I mentioned before, who saw her cousin, Albin, who she had known had died.
		
		%Of course, she did know that he was a soldier, so it's conceivable she could have imagined that he had died. But that's not always the case.
		
		%We also have the NDE from a young girl, an only child who almost died during heart surgery and said that in her near-death experience during surgery, she met someone who identified himself as her brother.
		%When she told her father about this, he was so moved that he confessed to her that he had had a son she didn't know about who died before she was born.
		
		%We have identified dozens of cases of this type.
		%Some going back to ancient Greece.
		%The bottom line is that our culture tends to talk about death as if it's the end. The end of all existence.
		
		%But NDE suggests that it may be more like a change of state.
		
		%--- End the talk ---
		
		%แม้ประสบการณ์จะต่างกันไป แต่แบ่งได้ออกเป็น 7 กลุ่มหลักๆ คือ 
		%ความกลัว, สัตว์/พืช, แสงสว่าง, ความรุนแรง/การลงโทษ, เหมือนเคยเห็นมาก่อน(deja-vu), %ครอบครัว, และเหตุการณ์หลังหัวใจวาย.
		%: fear; animals/plants; bright light; violence/persecution; deja-vu; family; recalling events post-CA and 9% had NDEs, while 2% described awareness with explicit recall of 'seeing' and 'hearing' actual events related to their resuscitation. One had a verifiable period of conscious awareness during which time cerebral function was not expected.
		
		%พฺรหฺมวํโส (พระวิสุทธิสังวรเถร หรือ อาจารย์
		%พรหม Ajahn Brahm
		%Physics of the Mind
		
%		\hspace{-0.5in}
%		\begin{center}
%			\begin{tabular}{ >{\arraybackslash}m{3.4in}  >{\arraybackslash}m{2.5in} }
%				``[What surprises me most is] Man. Because he sacrifices his health in order to make money. Then he sacrifices money to recuperate his health. And then he is so anxious about the future that he does not enjoy the present; the result being that he does not live in the present or the future; he lives as if he is never going to die, and then dies having never really lived.''
%				&
%				``[สิ่งที่ทำให้อาตมาแปลกใจที่สุดคือ] คน. 
%				เพราะว่า 
%				คนสละสุขภาพไปเพื่อหาเงิน 
%				แล้วทีหลังก็สละเงินไปเพื่อฟื้นฟูสุขภาพ
%				และคนก็มัวแต่กังวลกับอนาคต จนไม่มีความสุขกับปัจจุบัน
%				ผลก็คือเขาไม่ได้อยู่ในปัจจุบันไม่ได้อยู่ในอนาคต
%				เขาใช้ชีวิตอยู่เหมือนกับว่าเขาจะไม่มีวันตาย
%				แล้วก็ตายไปแบบไม่เคยมีชีวิตจริง ๆ''
%				\\
%				---Tenzin Gyatso, the 14th Dalai Lama
%				&
%				---เทนซิน กิยันโซ่, ดาไลลามาที่สิบสี่
%			\end{tabular} 
%		\end{center}
%		\index{words of wisdom}
		
\vspace{0.5cm}		
\begin{Parallel}[c]{0.52\textwidth}{0.4\textwidth}
	\selectlanguage{english}
	\ParallelLText{
		``[What surprises me most is] Man. Because he sacrifices his health in order to make money. Then he sacrifices money to recuperate his health. And then he is so anxious about the future that he does not enjoy the present; the result being that he does not live in the present or the future; he lives as if he is never going to die, and then dies having never really lived.''
		\begin{flushright}
			---Tenzin Gyatso, the 14th Dalai Lama
		\end{flushright}
	}
	\selectlanguage{thai}
	\ParallelRText{
		``[สิ่งที่ทำให้อาตมาแปลกใจที่สุดคือ] คน. 
		เพราะว่า 
		คนสละสุขภาพไปเพื่อหาเงิน 
		แล้วทีหลังก็สละเงินไปเพื่อฟื้นฟูสุขภาพ
		และคนก็มัวแต่กังวลกับอนาคต จนไม่มีความสุขกับปัจจุบัน
		ผลก็คือเขาไม่ได้อยู่ในปัจจุบันไม่ได้อยู่ในอนาคต
		เขาใช้ชีวิตอยู่เหมือนกับว่าเขาจะไม่มีวันตาย
		แล้วก็ตายไปแบบไม่เคยมีชีวิตจริง ๆ.''
		\begin{flushright}
			---เทนซิน กิยันโซ่, ดาไลลามาที่สิบสี่
		\end{flushright}
	}
\end{Parallel}
\index{english}{words of wisdom!Tenzin Gyatso}
\index{english}{quote!living life}
		
		
	\end{shaded}
}%small


%\section{Glossary}
\section{อภิธานศัพท์}

\begin{description}
		
	
\item[การตรวจับวัตถุในภาพ (object detection):]
\index{thai}{การตรวจับวัตถุในภาพ}\index{english}{object detection}
ภาระกิจการระบุชนิดของวัตถุและตำแหน่งในภาพ

\item[โยโล่ (YOLO):]
\index{thai}{โยโล่}\index{english}{YOLO}
\index{thai}{การตรวจับวัตถุในภาพ!โยโล่}\index{english}{object detection!YOLO}
แบบจำลองที่สำคัญในการตรวจับวัตถุในภาพ ซึ่งมีแนวคิดที่สำคัญคือวางกรอบปัญหาเป็นงานการหาค่าถดถอย และช่วยลดขั้นตอนการทำงานที่ซับซ้อนลงได้
ส่งผลให้แบบจำลองสามารถทำงานได้รวดเร็ว และการแก้ไขปรับปรุงก็ทำได้สะดวก

\item[กล่องสมอ (anchor box):]
\index{thai}{กล่องสมอ}\index{english}{anchor box}
เทคนิคที่ยอมให้มีการทายวัตถุในภาพที่มีตำแหน่งซ้อนทับกันได้ 
โดยใช้กลไกของรูปร่างและขนาดเริ่มต้นที่ต่างกันของ\textit{กล่องขอบเขต} เพื่อกำหนดความรับผิดชอบต่อวัตถุ
คล้ายการปักสมอของแต่ละ\textit{กล่องขอบเขต} ว่ากล่องใดจะรับผิดชอบขนาดหรือรูปทรงคร่าว ๆ แบบใด

\item[โครงข่ายปรปักษ์เชิงสร้าง (Generative Adversarial Networks คำย่อ GANs):]
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง}\index{english}{Generative Adversarial Networks}\index{english}{GAN}
กลไกการฝึกโครงข่ายสองโครงข่าย โดยฝึกในลักษณะที่ทั้งสองโครงข่ายมีเป้าหมายขัดแย้งกัน.
โครงข่ายหนึ่ง เรียกว่า โครงข่ายก่อกำเนิด ทำหน้าที่สร้างจุดข้อมูลขึ้นมา เลียนแบบจุดข้อมูลจริง
ในขณะที่อีกโครงข่ายหนึ่ง เรียกว่า โครงข่ายแบ่งแยก ทำหน้าที่ตรวจสอบ ว่าจุดข้อมูลที่เห็นถูกสุ่มจากชุดข้อมูลจริง หรือถูกสร้างขึ้น.
โครงข่ายก่อกำเนิด มีเป้าหมายเป็นการสร้างจุดข้อมูลเลียนแบบให้เหมือนข้อมูลจริง จนโครงข่ายแบ่งแยกจำแนกไม่ออก.
โครงข่ายแบ่งแยก มีเป้าหมายเป็นการจำแนกจุดข้อมูลได้ถูกต้องมากที่สุด

\item[โครงข่ายแบ่งแยก (discriminator):]
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!โครงข่ายแบ่งแยก}\index{english}{Generative Adversarial Networks!discriminator}
\index{thai}{โครงข่ายแบ่งแยก}\index{english}{discriminator}
โครงข่ายหนึ่งในกลไกการฝึกแบบปรปักษ์ ทำหน้าที่จำแนกจุดข้อมูลที่เห็นว่า ถูกสุ่มจากชุดข้อมูลจริง หรือถูกสร้างขึ้น

\item[โครงข่ายก่อกำเนิด (generator):]
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!โครงข่ายก่อกำเนิด}\index{english}{Generative Adversarial Networks!generator}
\index{thai}{โครงข่ายก่อกำเนิด}\index{english}{generator}
โครงข่ายหนึ่งในกลไกการฝึกแบบปรปักษ์ ทำหน้าที่สร้างจุดข้อมูลเลียนแบบจุดข้อมูลจริงจนโครงข่ายแบ่งแยกจำแนกได้แย่ที่สุด

\item[พีชคณิตเวกเตอร์ (Vector arithmetic):]
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!พีชคณิตเวกเตอร์}\index{english}{Generative Adversarial Networks!vector arithmetic}
สำหรับโครงข่ายปรปักษ์เชิงสร้าง 
พีชคณิตเวกเตอร์ อ้างถึง ปฏิบัติการเชิงเส้นที่ทำกับเวกเตอร์ลักษณะซ่อนเร้น แล้วนำเวกเตอร์ผลลัพธ์ไปเข้าโครงข่ายก่อกำเนิด เพื่อสร้างจุดข้อมูลขึ้นมา

\item[ลักษณะซ่อนเร้น (latent representation):]
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!ลักษณะซ่อนเร้น}\index{english}{Generative Adversarial Networks!latent representation}
ลักษณะของข้อมูล ที่ไม่ได้แสดง หรือกำหนดอย่างชัดแจ้ง.
ในบริบทของโครงข่ายปรปักษ์เชิงสร้าง หมายถึง ค่าของเวกเตอร์ที่ใช้เป็นอินพุตของโครงข่ายก่อกำเนิด

\item[ปริภูมิซ่อนเร้น (latent space):] หรือปริภูมิตัวแทน (representation space)
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!ปริภูมิซ่อนเร้น}\index{english}{Generative Adversarial Networks!latent space}
ปริภูมิของลักษณะซ่อนเร้น

\item[การพังทลายของภาวะ (mode collapse):]
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!การพังทลายของภาวะ}\index{english}{Generative Adversarial Networks!mode collapse}
\index{thai}{การพังทลายของภาวะ}\index{english}{mode collapse}
สถานการณ์ที่โครงข่ายก่อกำเนิดสร้างจุดข้อมูลคล้าย ๆ กัน แม้ว่าจะรับอินพุตที่ต่างกัน


\item[คอนโวลูชั่นก้าวเศษ (fractionally-strided convolution):] หรือคอนโวลูชั่นสลับเปลี่ยน (transposed convolution)
\index{thai}{คอนโวลูชั่นก้าวเศษ}\index{english}{fractionally-strided convolution}
\index{thai}{คอนโวลูชั่นสลับเปลี่ยน}\index{english}{transposed convolution}
การดำเนินคอนโวลูชั่นด้วยการแปลงอินพุตและค่าน้ำหนักของฟิลเตอร์เป็นเมทริกซ์ โดยจัดรูปเมทริกซ์ทั้งสองให้ถูกต้อง 
แล้วทำการคูณเมทริกซ์อินพุตเข้ากับ\textit{การสลับเปลี่ยน}ของเมทริกซ์ค่าน้ำหนัก.
หากเลือกอภิมานพารามิเตอร์ได้ถูกต้อง การดำเนินการเช่นนี้ อาจมองเสมือนเป็นการทำคอนโวลูชั่นที่ใช้ขนาดก้าวย่างเล็กกว่าหนึ่ง (เหมือนการเติมพิกเซลค่าศูนย์เข้าไประหว่างพิกเซลของอินพุต ในกรณีข้อมูลภาพ)


\item[การถอดคอนโวลูชั่น (deconvolution):]
\index{thai}{การถอดคอนโวลูชั่น}\index{english}{deconvolution}
การถอดคอนโวลูชั่น มีหลายความหมาย.
ในขณะที่บางครั้ง การถอดคอนโวลูชั่นอาจหมายถึงคอนโวลูชั่นก้าวเศษ
แต่ความหมายที่ถูกยอมรับอย่างกว้างขวาง  คือการถอดค่าพารามิเตอร์ของโครงข่ายคอนโวลูชั่นย้อนกลับ 
เพื่อศึกษากลไกการทำงานของโครงข่ายคอนโวลูชั่น ว่า
ฟิลเตอร์แต่ละตัวที่ใช้ในโครงข่ายคอนโวลูชั่น 
ได้เรียนรู้เพื่อจะตรวจจับลักษณะรูปแบบเช่นไร





\item[การจับคู่ลักษณะสำคัญ (feature matching):]
\index{thai}{การจับคู่ลักษณะสำคัญ}\index{english}{feature matching}
\index{thai}{โครงข่ายปรปักษ์เชิงสร้าง!การจับคู่ลักษณะสำคัญ}\index{english}{Generative Adversarial Networks!feature matching}
ในบริบทของโครงข่ายปรปักษ์เชิงสร้าง
การจับคู่ลักษณะสำคัญ หมายถึงการดัดแปลงฟังก์ชันจุดประสงค์ของโครงข่ายก่อกำเนิด โดย แทนที่เป้าหมายการทำให้โครงข่ายแบ่งแยกทายผิดมากที่สุด 
ด้วยเป้าหมายการทำให้ความต่างระหว่าง
ค่าเฉลี่ยของลักษณะสำคัญภายในโครงข่ายแบ่งแยก เมื่อเห็นจุดข้อมูลจริง 
กับค่าเฉลี่ยของลักษณะสำคัญเมื่อเห็นจุดข้อมูลที่สร้างขึ้น
มีค่าน้อยที่สุด.
ตัวอย่างเช่น การใช้ฟังก์ชันสูญเสีย $\mathrm{Loss}_{\mathcal{G}} = \| E_{\bm{X}}[ \bm{f}(\bm{X})] -  E_{\bm{z}}[ \bm{f}(\mathcal{G}(\bm{z}))]\|^2$ เมื่อ $\bm{X}$ คือข้อมูลจริง
และ $\bm{z}$ แทนเวกเตอร์ค่าสุ่ม
ส่วน $\mathcal{G}(\cdot)$ คือการคำนวณของโครงข่ายก่อกำเนิด
และ $\bm{f}(\cdot)$ คือลักษณะสำคัญที่ได้จากโครงข่ายแบ่งแยก 
%(เช่น จากชั้นคำนวณก่อนชั้นเอาต์พุตสุดท้าย)

\item[การแยกแยะหมู่เล็ก (minibatch discrimination):]
\index{thai}{การแยกแยะหมู่เล็ก}\index{english}{minibatch discrimination}
การเพิ่มสัญญาณข้อมูลที่บอกความแตกต่างระหว่างจุดข้อมูลใด ๆ กับจุดข้อมูลอื่น ๆ ภายในหมู่เล็กเดียวกัน
เพื่อลดบรรเทาปัญหาการพังทลายของภาวะ

\item[การทำฉลากราบรื่น (label smoothing):]
\index{thai}{การทำฉลากราบรื่น}\index{english}{label smoothing}
การปรับค่าเป้าหมายของฉลากเฉลย เพื่อบรรเทาปัญหาที่แบบจำลองมีความมั่นใจสูงเกินไป


%\item[การทำฉลากราบรื่นทางเดียว (one-sided label smoothing):]
%\index{การทำฉลากราบรื่นทางเดียว}\index{one-sided label smoothing}
%การปรับค่าเป้าหมายของฉลากเฉลย 

\item[การทำหมู่เล็กเสมือนจริง (virtual minibatch):]
\index{thai}{การทำหมู่เล็กเสมือนจริง}\index{english}{virtual minibatch}
การใช้หมู่อ้างอิงที่เลือกมาก่อนกระบวนการฝึก เพื่อใช้การคำนวณแบชนอร์ม ร่วมกับจุดข้อมูลที่สนใจ
	
\end{description}


