\section{แบบฝึกหัด}
\label{section: deep exercises}

%For any scientist, the real challenge is not to stay within the secure garden of the known but to venture out into the wilds of the unknown."- Du Sautoy 2017
%
%“Everyone makes mistakes. The wise are not people who never make mistakes, but those who forgive themselves and learn from their mistakes.”
%— Ajahn Brahm

%\begin{Parallel}[c]{0.4\textwidth}{0.4\textwidth}
%	\selectlanguage{english}
%	\ParallelLText{
%		``Complaining is finding faults, wisdom is finding solutions.''
%		\begin{flushright}
%			---Ajahn Brahm
%		\end{flushright}
%	}
%	\selectlanguage{thai}
%	\ParallelRText{
%		``การพร่ำบ่น เป็นการหาข้อบกพร่อง\\
%		ปัญญา เป็นหาการวิธีแก้ปัญหา.''
%		\begin{flushright}
%			---อาจารย์ พรหม
%		\end{flushright}
%	}
%\end{Parallel}
%\index{words of wisdom!Ajahn Brahm}
%\index{quote!wisdom}
%\vspace{1cm}

\begin{Parallel}[c]{0.45\textwidth}{0.4\textwidth}
	\selectlanguage{english}
	\ParallelLText{
		``For any scientist, the real challenge is not to stay within the secure garden of the known but to venture out into the wilds of the unknown.''
		\begin{flushright}
			---Marcus Du Sautoy
		\end{flushright}
	}
	\selectlanguage{thai}
	\ParallelRText{
		``สำหรับนักวิทยาศาสตร์ ความท้าทายจริง ๆ ไม่ใช่การพักอยู่ภายในสวนที่ปลอดภัยของสิ่งที่รู้
		แต่เป็นการท่องออกไปในป่าของความไม่รู้.''
		\begin{flushright}
			---มาร์คัส ดู โซวทอย
		\end{flushright}
	}
\end{Parallel}
\index{english}{words of wisdom!Marcus Du Sautoy}
\index{english}{quote!science}
\vspace{1cm}



\begin{Exercise}
	\label{ex: vanishing gradient}
	\index{english}{vanishing gradient problem}
	\index{thai}{ปัญหาการเลือนหายของเกรเดียนต์}
	
จงศึกษาตัวอย่างและแสดง\textit{ปัญหาการเลือนหายของเกรเดียนต์}
พร้อมเปรียบเทียบผลลัพธ์จากการบรรเทา โดยเปลี่ยนมาใช้ฟังก์ชันกระตุ้น\textit{เรลู}.

%
\begin{figure}[H]
	\begin{center}
	\includegraphics[width=4in]{05Deep/relu/data_new.png}
	\end{center}
	\caption[ตัวอย่างข้อมูลสำหรับแสดงปัญหาการเลือนหายของเกรเดียนต์]{ตัวอย่างข้อมูลงานจำแนกประเภทเพื่อแสดงปัญหาการเลือนหายของเกรเดียนต์.
		ข้อมูลสร้างจาก จุดข้อมูลที่ $i^{th}$ ของกลุ่ม $c$ 
		นั่นคือ $\bm{x}_c(i) = [r_c(i) \cdot \sin \theta_c(i), r_c(i) \cdot \cos \theta_c(i)]^T$
		โดย $c$ เป็นดัชนีของกลุ่ม
		และทุก ๆ กลุ่มมี $r_c(i) = (i-1)/N$ 
		กับ $\theta_c(i) = (i-1) \cdot \frac{4 \pi}{3 N} + c \cdot \frac{2 \pi}{3} + \epsilon$
		สำหรับ $i \in \{1, \ldots, N\}$ และ $N$ คือจำนวนจุดข้อมูลของแต่ละกลุ่ม.
		ส่วนสัญญาณรบกวน $\epsilon \sim \mathcal{N}(0, 0.2)$.
	}
	\label{fig: deep vanishing gradient data}
\end{figure}
%

ตัวอย่างเช่น
(1) เขียนโปรแกรมเพื่อสร้างข้อมูล.
รูป~\ref{fig: deep vanishing gradient data}
แสดงตัวอย่างข้อมูล%
\footnote{%
ดัดแปลงจาก \url{https://cs224d.stanford.edu/notebooks/vanishing_grad_example.html} (ข้อมูลเมื่อ 24 พ.ค. 2560).
}
ที่เป็นปัญหาการจำแนกกลุ่ม โดยอินพุตมี $2$ มิติ และเอาต์พุตเป็นชนิดมี $3$ ชนิด
ซึ่งสร้างจากตัวอย่างคำสั่งข้างล่าง
\begin{Verbatim}[fontsize=\small]
N = 100
X = np.zeros((2, N*3))                # Initialize dummy input
y = np.zeros((1, N*3), dtype='uint8') # Initialize dummy output
sec = 2*np.pi/3

for k in range(3):
    ix = range(N*k,N*(k+1))  ## Indices of class k
    r = np.linspace(0.0,1,N) ## Radius
    t = np.linspace(k*sec,(k+2)*sec, N) + np.random.randn(N)*0.2 
	X[:, ix] = np.c_[r*np.sin(t), r*np.cos(t)].T   
	y[0, ix] = k
\end{Verbatim}

หมายเหตุ ไม่จำเป็นต้องสร้างข้อมูลตามตัวอย่างในรูป.

จากนั้น (2)
ทดลองสร้าง ฝึก และทดสอบโครงข่ายประสาทเทียมความลึกต่าง ๆ
โดยเพิ่มความลึกขึ้นเรื่อยๆ และสังเกตความยากของการฝึก.
ดูหัวข้อ~\ref{sec: relu} ประกอบ.
(ตัวอย่างโปรแกรม ศึกษาได้จากหัวข้อ~\ref{sec: ann exercises}.)

สุดท้าย (3)
ทดลองเปลี่ยนฟังก์ชันกระตุ้นเป็น\textit{เรลู}
(ตัวอย่างโปรแกรมการคำนวณเรลู แสดงในรายการ~\ref{code: svm primal gd}.)
สังเกตผล เปรียบเทียบ และอภิปราย.

	
\end{Exercise}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{Exercise}
	\label{ex: vanishing gradient 2}
	\index{english}{relu}
	\index{thai}{เรลู}
	
	จากแบบฝึกหัด~\ref{ex: vanishing gradient}
	ตั้งสมมติฐานถึงสาเหตุของปัญหาการฝึกโครงข่ายประสาทเทียมลึก
	ออกแบบการทดลอง เพื่อพิสูจน์และศึกษาสมมติฐานนั้น
	ดำเนินการทดลอง สังเกตผล วิเคราะห์ สรุป วิจารณ์และอภิปราย.
	ศึกษาและทดลองทั้งฟังก์ชันกระตุ้นซิกมอยด์ และเรลู 
	พร้อมสังเกตขนาดเกรเดียนต์ที่ชั้นต่าง ๆ ขณะฝึก.
	อภิปรายถึงสาเหตุอื่นที่อาจเป็นไปได้ นอกจากขนาดของเกรเดียนต์.
	ดูรูป~\ref{fig: deep ex vanishing gradient sigmoid}
	และผลในหัวข้อ~\ref{sec: relu} ประกอบ.
	
	รายการ~\ref{code: class ANN}
	แสดงโปรแกรมโครงข่ายประสาทเทียมที่ปรับปรุงใหม่ โดยเขียนอยู่ในรูปแบบโปรแกรมเชิงวัตถุ
	และที่เมท็อด \texttt{train} มีอาร์กิวเมนต์ \verb|track_grad| ที่สามารถสั่งให้เก็บขนาดของเกรเดียนต์ไว้เพื่อตรวจสอบภายหลังได้.
	ตัวอย่างคำสั่งข้างล่าง ฝึกและทดสอบโครงข่ายสามชั้น (จำนวนหน่วยซ๋อนเป็น $4$ และ $8$ ชั้นตามลำดับ)
สำหรับข้อมูล \verb|datax| และ \verb|y_onehot|
ที่อินพุตมีขนาดสองมิติและเอาต์พุตอยู่ในรูปแบบ\textit{รหัสหนึ่งร้อน} 
สำหรับงานจำแนกกลุ่มที่มีสามกลุ่ม โดยมีจำนวนข้อมูลฝึกเป็น $300$ จุดข้อมูล
\begin{Verbatim}[fontsize=\small]
net = w_initn([2, 4, 8, 3])
net['act1'] = sigmoid
net['act2'] = sigmoid
net['act3'] = softmax
ann = ANN(net, NB=300, shuffle='once')

# Train net
train_losses, maggrads = ann.train(datax, y_onehot, cross_entropy, 
lr=0.3/300, epochs=500, track_grad=True)

yp = ann.predict(testx)
yc = np.argmax(yp, axis=0)	
accuracy = np.mean(yc == testy[0,:])
print('Test accuracy: ', accuracy)
\end{Verbatim}
เมื่อ \verb|testx| และ \verb|testy|
เป็นอินพุตและเอาต์พุตของข้อมูลทดสอบ และเฉลย \verb|testy| ระบุฉลากที่ถูกต้องของจุดข้อมูล.
โปรแกรม \verb|w_initn|, \verb|sigmoid|, \verb|softmax|, และ \verb|cross_entropy|
แสดงในรายการ~\ref{code: w_initn},
~\ref{code: sigmoid},
~\ref{code: softmax}
และ~\ref{code: cross entropy}
ตามลำดับ.
โปรแกรม \texttt{cross\_entropy} ในรายการ~\ref{code: cross entropy}
คำนวณผลรวมของค่าฟังก์ชันสูญเสียต่อจุดข้อมูลออกมา
การกำหนดค่าอัตราการเรียนรู้ \texttt{lr=0.3/300}
ให้ผลในการฝึก
เสมือนว่าค่าน้ำหนักถูกปรับจากค่าเฉลี่ยของค่าฟังก์ชันสูญเสียต่อจุดข้อมูล
ด้วยอัตราการเรียนรู้ $0.3$.
นั่นคือ $w - (\alpha/N) \cdot \sum_n \nabla E$
$\equiv$ $w - \alpha \cdot \frac{1}{N} \sum_n \nabla E$.
แม้ว่าผลจริงไม่ได้แตกต่างกัน
แต่การใช้ค่าเฉลี่ย (ในวิธีที่แสดงนี้) ช่วยให้การเลือกอัตราเรียนรู้ทำได้สะดวกขึ้น.
ค่าอัตราเรียนรู้ สามารถเลือกได้โดยไม่ต้องคำนึงถึงจำนวนจุดข้อมูลฝึก.

หมายเหตุ นอกจากการเขียนในรูปโปรแกรมเชิงวัตถุ และเพิ่ม \verb|track_grad| แล้ว
ส่วนหนึ่งที่สำคัญคือ โปรแกรมในรายการ~\ref{code: class ANN}
ได้เตรียมความสามารถใน\textit{การฝึกหมู่เล็ก} (หัวข้อ~\ref{sec: minibatch})
ซึ่ง\textit{การฝึกหมู่เล็ก} ไม่ใช่จุดประสงค์ของแบบฝึกหัดนี้ 
และ ดังเช่นที่แสดงในตัวอย่างคำสั่งข้างต้น 
สามารถกำหนดให้ทำ\textit{การฝึกแบบหมู่} ได้โดยการกำหนดจำนวนหมู่เล็ก เท่ากับ(หรือมากกว่า)
จำนวนของจุดข้อมูลฝึก ดังเช่น
\begin{Verbatim}[fontsize=\small]
ann = ANN(net, NB=300, shuffle='once')
\end{Verbatim}
เมื่อ $300$ คือจำนวนจุดข้อมูลฝึก.
	
\lstinputlisting[language=Python, caption={[คลาสโครงข่ายประสาทเทียม]คลาส สำหรับคำนวณการฝึกและการทำนายของโครงข่ายประสาทเทียม}, label={code: class ANN}]{05Deep/code/code_ann1.py}
\index{english}{artificial neural network!code!class}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!คลาส}

รูป~\ref{fig: deep ex vanishing gradient sigmoid}
แสดงตัวอย่างการนำเสนอผล.
จากผลที่แสดงในรูป~\ref{fig: deep ex vanishing gradient sigmoid}
อาจอภิปราย ได้ดังนี้
(1) ภาพกลางแสดงในเห็นชัดเจนว่า ส่วนใหญ่ขนาดของเกรเดียนต์ในชั้นแรก น้อยกว่าชั้นสุดท้าย
และน้อยกว่ามากๆ โดยส่วนใหญ่.
แต่แนวโน้ม ไม่ได้เป็นไปในทางเดียว
นั่นคือ พบขนาดเกรเดียนต์ในชั้นแรกที่ใหญ่ที่สุด เมื่อใช้ความลึก $6$ ชั้น (ซึ่งมีขนาดถึงเกือบ $0.8$ หรือเกือบ $80\%$ ของขนาดเกรเดียนต์ชั้นสุดท้าย) และผลลัพธ์แสดงการลดลงในทั้งสองทิศทาง
โดยที่ความลึกสิบชั้น ขนาดเกรเดียนต์ในชั้นแรกมีค่าต่ำมากเมื่อเทียบกับชั้นสุดท้าย.
(2) ภาพซ้าย และภาพขวา แสดงสาเหตุในเห็นอีกมุมหนึ่ง 
คือไม่ใช่แค่ขนาดที่น้อยอย่างเดียว
แต่เป็น เมื่อไรที่ชั้นคำนวณต้น ๆ จะได้เกรเดียนต์ขนาดใหญ่.
%
%
%สมัยฝึกที่ได้เกรเดียนต์ขนาดใหญ่ในชั้นแรกด้วย.
ภาพซ้าย แสดงให้เห็นว่า 
เกรเดียนต์ชั้นแรกที่มีขนาดใหญ่จะมาช้าลง
ในโครงข่ายที่ลึกขึ้น.
ภาพขวา ยืนยันเรื่องที่เกรเดียนต์ขนาดใหญ่มาช้า ในโครงข่ายลึก.
สังเกตว่า
ชั้นสุดท้าย (เส้นหนาสีแดง) จะเห็นเกรเดียนต์ขนาดใหญ่ที่สุด ในสมัยฝึกต้นๆ (เห็นเร็ว) แทบจะทุกระดับความลึก (ยกเว้นความลึก $8$).
แต่ชั้นแรก (เส้นประสีน้ำเงิน) จะเห็นเกรเดียนต์ขนาดใหญ่ที่สุด ช้าลงเรื่อยๆ (สมัยฝึกสูง) เมื่อความลึกเพิ่มขึ้นเรื่อยๆ โดยแนวโน้มแทบจะเป็น\textit{ลำดับทางเดียว} (monotonic).
การที่เห็นเกรเดียต์ขนาดใหญ่ช้า อาจหมายถึง
การปรับค่าน้ำหนักของชั้นได้ช้าด้วย
ซึ่งตีความได้ว่า การใช้โครงข่ายที่ลึกนั้น ต้องการการฝึกที่ยาวนานขึ้น
และการฝึกที่ยาวนานขึ้น โดยทั่วไปแล้ว หมายถึง การฝึกที่ยาก.
	
\begin{figure}[H]
	\begin{center}
		\begin{tabular}{ccc}
			\includegraphics[width=0.3\columnwidth]{05Deep/relu/sigmoid_dEwL2toL5.png}
			&
			\includegraphics[width=0.3\columnwidth]{05Deep/relu/sigmoid_mags.png}
			&
			\includegraphics[width=0.3\columnwidth]{05Deep/relu/sigmoid_epochmags.png}	
		\end{tabular}		
		\caption[ขนาดของเกรเดียนต์ชั้นที่หนึ่ง ปัญหาการเลือนหายของเกรเดียนต์]{ปัญหาการเลือนหายของเกรเดียนต์.
		ภาพซ้าย แสดงขนาดเฉลี่ยของเกรเดียนต์ชั้นที่หนึ่ง ต่อสมัยฝึก ของโครงข่ายประสาทเทียมความลึกต่าง ๆ.
		ภาพกลาง แสดงอัตราส่วนระหว่างขนาดที่ใหญ่ที่สุดจากเกรเดียนต์ชั้นที่หนึ่ง กับขนาดที่ใหญ่ที่สุดจากเกรเดียนต์ชั้นสุดท้าย เมื่อใช้ความลึกต่าง ๆ.
		ภาพขวา แสดงสมัยฝึกที่เกรเดียนต์มีขนาดใหญ่ที่สุด ของชั้นแรก และชั้นสุดท้าย เมื่อใช้ความลึกต่าง ๆ.
		}
		\label{fig: deep ex vanishing gradient sigmoid}
	\end{center}
\end{figure}

	
\end{Exercise}

\begin{Exercise}
	\label{ex: relu}
	\index{english}{relu}
	\index{thai}{เรลู}
	
	จากแบบฝึกหัด~\ref{ex: vanishing gradient} และ~\ref{ex: vanishing gradient 2}
ออกแบบการทดลอง เพื่อวัดผลการแก้ปัญหาการฝึกโครงข่ายลึก และผลการบรรเทาปัญหาการเลือนหายของเกรเดียนต์
เมื่อใช้ฟังก์ชันกระตุ้นเรลู เปรียบเทียบกับซิกมอยด์
ดำเนินการทดลอง สังเกต วัดผล สรุปและนำเสนอผลให้ชัดเจน
ทั้งประเด็นใหญ่ (การฝึกโครงข่ายลึก)
และประเด็นย่อย (การเลือนหายของเกรเดียนต์).

\end{Exercise}

\begin{Exercise}
	\label{ex: minibatch}
	\index{english}{minibatch}
	\index{thai}{การฝึกแบบหมู่เล็ก}

	จากหัวข้อ~\ref{sec: minibatch}
ออกแบบการทดลอง เพื่อศึกษาผลของขนาดหมู่เล็ก ต่อเวลาในการฝึก ความยากง่ายในการฝึก
และคุณภาพการฝึก โดยมีปัจจัยประกอบคือ 
(1) ความลึกของโครงข่ายประสาทเทียม	
และ (2) จำนวนข้อมูลฝึก.
เลือก (หรือสร้าง) ข้อมูลขึ้นมา
ดำเนินการทดลอง
สังเกตและบันทึกผล
สรุปและอภิปราย.

ด้วยข้อมูลที่มีเพิ่มมากขึ้น 
ชุดข้อมูลที่มีขนาดใหญ่มากๆ อาจพบการฝึกแบบหมู่เล็กที่ทำเพียงสมัยเดียว 
หรือแม้แต่บางครั้งอาจจะไม่สามารถฝึกได้ครบทุกหมู่เล็ก (ไม่ครบสมัย และไม่ได้เห็นข้อมูลครบทั้งหมด).
สำหรับชุดข้อมูลที่มีขนาดใหญ่มากๆ 
อาจพบปัญหาประสิทธิภาพของการคำนวณ
และหากเลือกใช้ข้อมูลเพียงบางส่วน อาจเกิดปัญหาการ\textit{อันเดอร์ฟิต}ได้.
อภิปราย ประเด็นการทำงานกับข้อมูลขนาดใหญ่มาก และศึกษาเพิ่มเติมจากบทความวิจัยต่าง ๆ.
\index{english}{underfitting}
\index{thai}{การอันเดอร์ฟิต}
\index{english}{large dataset!issues}
\index{thai}{ข้อมูลขนาดใหญ่!ปัญหา}

	
\end{Exercise}


%\begin{Exercise}
%	\label{ex: mnist different Ms}
%	\index{MNIST}
%	\index{เอมนิสต์}
%	
%	คล้ายกับแบบฝึกหัด~\ref{ex: minibatch}
%จงดำเนินการศึกษาผลของ\textit{ขนาดหมู่เล็ก}ต่อการฝึก
%สำหรับข้อมูล\textit{เอมนิสต์}.
%	
%ตัวอย่าง
%เช่น
%การศึกษา โดยเปรียบเทียบ\textit{การฝึกแบบหมู่}, \textit{การฝึกแบบออนไลน์}, และ\textit{การฝึกทีละหมู่เล็ก} โดยใช้ข้อมูลลายมือเขียนตัวเลข \textit{เอมนิสต์} 
%(ดูแบบฝึกหัด~\ref{ex: mnist} ประกอบสำหรับข้อมูลชุด\textit{เอมนิสต์}). 
%	\index{MNIST}
%	\index{เอมนิสต์}
%	
%ข้อมูลชุดเอมนิสต์ แบ่งเป็นสองชุดย่อย คือ ชุดฝึกหัด ($60000$ จุดข้อมูล) และชุดทดสอบ ($10000$ จุดข้อมูล)
%โดยแต่ละจุดข้อมูลแทนภาพของลายมือเขียนตัวเลข
%ประกอบด้วย อินพุต $784$ ค่า ซึ่งแทนค่าเข้มของพิกเซลขนาด $28\times28$ แต่ละค่าอยู่ในช่วง $0$ ถึง $255$ และเอาต์พุตที่ระบุตัวเลขที่ลายมือเขียน.
%นั่นคือ แต่ละจุดข้อมูลประกอบด้วย อินพุต $\bm{x} \in \{0, 1, 2, \ldots, 255\}^{784}$ และเอาต์พุต $y \in \{0, 1, 2, \ldots, 9\}$.
%ภาพในรูป~\ref{fig: mnist examples} แสดงตัวอย่างของข้อมูลชุดเอมนิสต์ เมื่อนำอินพุตมาจัดเรียงเป็นภาพขนาด $28\times28$.
%	
%เมื่อนำโครงข่ายประสาทเทียมไปฝึกจำแนกภาพเขียนตัวเลข โดยฝึกแบบหมู่
%แต่ละสมัยฝึก
%ปรับค่าน้ำหนักของโครงข่ายแค่ครั้งเดียว
%และใช้ข้อมูลทั้งหมด $60000$ จุดข้อมูลคำนวณทีเดียว.
%%	และ
%%	นั่นคือ แต่ละสมัยฝึกจะทำ 
%%	%$w_{ji} \leftarrow w_{ji} - \alpha \sum_{n=1}^N \frac{\partial E_n}{\partial w_{ji}}$ 
%%	สมการ~\ref{eq: ANN update w grad desc batch} ครั้งเดียว.
%%	
%หากทำการฝึกแบบออนไลน์
%จะมีการปรับค่าน้ำหนักของโครงข่าย $60000$ ครั้งต่อสมัยฝึก
%แต่ละครั้งของการปรับ ใช้ข้อมูลทีละหนึ่งจุดข้อมูลสำหรับการคำนวณ.
%%	นั่นคือ แต่ละสมัยฝึกจะทำ %$w_{ji} \leftarrow w_{ji} - \alpha \frac{\partial E_n}{\partial w_{ji}}$ 
%%	สมการ~\ref{eq: ANN update w grad desc} 
%%	%สำหรับ $n = 1, 2, \ldots, N$.
%%	$60000$ ครั้ง
%%	
%หากทำการฝึกแบบหมู่เล็กโดยเลือกขนาดหมู่เล็กเป็น $1000$
%ข้อมูลฝึกทั้งหมด $60000$ จุดข้อมูล จะแบ่งออกได้เป็น $60$ หมู่เล็ก แต่ละหมู่เล็กมี $1000$ จุดข้อมูล.
%เมื่อทำการฝึก
%แต่ละสมัยฝึก จะปรับค่าน้ำหนัก $60$ ครั้ง แต่ละครั้งสำหรับแต่ละหมู่เล็ก.
%
%ตัวอย่างการนำเสนอผล เช่น		
%ภาพต่าง ๆ ในรูป~\ref{fig: deep Mini-Batch Training Time} 
%ที่เปรียบเทียบจำนวนสมัยฝึก (ภาพต่าง ๆ ทางด้านซ้าย) และเวลาในการฝึก (ภาพต่าง ๆ ทางด้านขวา) เมื่อใช้หมู่เล็กขนาดต่าง ๆ 
%ได้แก่ การฝึกแบบหมู่หรือออฟไลน์ (เทียบเท่า $B = 60000$ โดย $B$ แทนขนาดหมู่เล็ก), 
%หมู่เล็กขนาด $10000$, 
%หมู่เล็กขนาด $1000$, 
%หมู่เล็กขนาด $100$, 
%หมู่เล็กขนาด $10$, 
%และการฝึกแบบออนไลน์ (เทียบเท่า $B = 1$). 
%	
%รูป~\ref{fig: deep Mini-Batch Training Time and Accuracy} แสดงตัวอย่าง
%การนำเสนอ การเปรียบเทียบเวลาที่ใช้ในการฝึก
%และคุณภาพการฝึก (ความแม่นยำในการทำนายข้อมูลชุดทดสอบ).
%
%Terminating condition!!!
%
%สังเกตว่า 
%(1) เมื่อใช้\textit{หมู่เล็ก}ขนาดเล็กลง จะต้องการจำนวนสมัยฝึกน้อยลง เพื่อที่จะทำเกิดการลู่เข้า.
%(2) การใช้\textit{หมู่เล็ก}ขนาดเล็กลง แม้จะต้องการจำนวนสมัยฝึกน้อยลง แต่เวลาที่ใช้ในการประมวลผลแต่ละสมัยฝึกจะนานขึ้น.
%(3) การฝึกด้วยการใช้หมู่เล็ก ช่วยให้การฝึกได้คุณภาพการทำนายที่ดีขึ้น
%ดูอภิปรายในหัวข้อ~\ref{sec: online and batch training} และ~\ref{sec: minibatch} ประกอบ.
%
%% ซึ่งอาจเป็นผลโดยอ้อมจากการช่วยปรับปรุงเวลาในการฝึกโดยรวม (ปรับปรุงจาก การฝึกแบบออฟไลน์) 
%%	รวมถึงเวลาการฝึกต่อสมัยฝึก ที่ช่วยปรับปรุงการฝึกแบบออนไลน์ ซึ่งใช้เวลาต่อสมัยฝึกนานมาก.
%%	นั่นคือ การฝึกแบบออนไลน์จะใช้เวลาในการฝึกต่อสมัยฝึก เป็น $34.62/0.647 \approx 53.51$ เท่าของการฝึกแบบออฟไลน์.
%	
%	%
%	\begin{figure}[H]
%		\begin{center}
%			\includegraphics[width=6.5in]{05Deep/deepBenefitDemo03aTrainingTime.png}
%			\caption[การฝึกทีละหมู่เล็ก (mini-batch) และความเร็วในการฝึก]{ภาพแสดงค่าฟังก์ชันสูญเสียต่อสมัยฝึก (ภาพต่าง ๆ ทางด้านซ้าย)
%				ภาพแสดงค่าฟังก์ชันสูญเสียต่อเวลา (ภาพต่าง ๆ ทางด้านขวา)
%				ของการฝึกแบบออฟไลน์ (\texttt{60k}), หมู่เล็กขนาด $10000$ (\texttt{10k}), ขนาด $1000$ (\texttt{1k}), ขนาด $100$ (\texttt{100}), ขนาด $10$ (\texttt{10}), และแบบออนไลน์ (\texttt{1}) ตามระบุในภาพ.
%				เวลาเฉลี่ย (ในหน่วยวินาที) สำหรับการประมวลผลแต่ละสมัยฝึกคือ
%				$0.647$, $0.617$, $0.660$, $0.673$, 
%				$4.78$, $34.62$ สำหรับ \texttt{60k}, \texttt{10k}, \texttt{1k}, \texttt{100}, \texttt{10}, และ \texttt{1} ตามลำดับ.
%			}
%			\label{fig: deep Mini-Batch Training Time}
%		\end{center}
%	\end{figure}
%	%
%	
%	%
%	\begin{figure}[H]
%		\begin{center}
%			\includegraphics[width=6.5in]{05Deep/deepBenefitDemo04amPlots.png}
%			\caption[เวลาและคุณภาพการฝึก ในการฝึกแบบหมู่เล็ก]{ภาพบนแสดงลอการิทึมของฟังก์ชันสูญเสียต่อเวลา เปรียบเทียบให้เห็นระยะเวลาที่ใช้ในการฝึกจนลอการิทึมของฟังก์ชันสูญเสียลู่เข้า (การฝึกสมบูรณ์) เมื่อใช้ขนาดหมู่เล็กต่าง ๆ.
%				ภาพล่างซ้ายเปรียบเทียบเวลาฝึกเฉลี่ยต่อสมัยฝึก.
%				ภาพล่างขวาเปรียบเทียบค่าความแม่นยำในการทายข้อมูลชุดทดสอบ.
%				สัญญลักษณ์ 60k แทนการฝึกแบบออฟไลน์, 10k แทนหมู่เล็กขนาด $10000$ , 1k แทนหมู่เล็กขนาด $1000$, 100 แทนหมู่เล็กขนาด $100$, 10 แทนหมู่เล็กขนาด $10$, และ 1 แทนการฝึกแบบออนไลน์.
%			}
%			\label{fig: deep Mini-Batch Training Time and Accuracy}
%		\end{center}
%	\end{figure}
%	%
%	
%	ในทางปฎิบัติ แทนที่จะใช้\textit{วิธีลงเกรเดียนต์} (Gradient Descent Method) การฝึกหมู่เล็กมักใช้กับ\textit{วิธีลงเกรเดียนต์เฟ้นสุ่ม} (Stochastic Gradient Descent Method) 
%	ที่คล้ายกับการคำนวณที่บรรยายด้วยสมการ~\ref{eq: deep minibatch} แต่ว่าทำการสลับลำดับของข้อมูลในทุก ๆ สมัยฝึก.
%	รูป~\ref{fig: deep Mini-Batch GD v.s. SGD} แสดงความก้าวหน้าในการฝึกด้วย\textit{วิธีลงเกรเดียนต์} เปรียบเทียบกับ\textit{วิธีลงเกรเดียนต์เฟ้นสุ่ม}.
%	สังเกตว่า ความก้าวหน้าในการฝึกด้วย\textit{วิธีลงเกรเดียนต์เฟ้นสุ่ม}จะมีลักษณะสั่นมากกว่า 
%	ซึ่งลักษณะเช่นนี้เชื่อว่า จะช่วยให้\textit{วิธีลงเกรเดียนต์เฟ้นสุ่ม}สามารถทำงานกับปัญหาที่มีค่า\textit{ตัวทำน้อยที่สุด}หลายค่า (ปัญหาที่ไม่เป็นคอนเวกซ์ non-convex problem) ได้ดีกว่า\textit{วิธีลงเกรเดียนต์}.
%	
%	
%	%
%	\begin{figure}[H]
%		\begin{center}
%			\includegraphics[width=5in]{05Deep/deepBenefitDemo06aGDvsSGD.png}
%			\caption[วิธีลงเกรเดียนต์เฟ้นสุ่ม (stochastic gradient descend method)]{ภาพซ้ายความก้าวหน้าการฝึก (ค่าฟังก์ชันสูญเสียกับสมัยฝึก) เมื่อฝึกด้วยวิธีลงเกรเดียนต์
%				ภาพขวา เมื่อฝึกด้วยวิธีลงเกรเดียนต์เฟ้นสุ่ม
%				% test accuracy = 0.93 for both 03f (GD) and 03d (SGD)
%			}
%			\label{fig: deep Mini-Batch GD v.s. SGD}
%		\end{center}
%	\end{figure}
%	%
%	
%	
%	
%	
%	
%\end{Exercise}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\paragraph{ไพทอร์ช.}
โปรแกรมการเรียนรู้เชิงลึก สามารถเขียนด้วย\textit{นัมไพ}ได้
แต่เนื่องจากการประยุกต์ใช้ที่เด่นๆ ข้องเกี่ยวกับข้อมูลที่มีมิติและจำนวนมหาศาล
การคำนวณด้วยจีพียู จะช่วยการทำงานกับข้อมูลเหล่านั้นให้เสร็จได้เร็วขึ้นมาก.
หัวข้อนี้ แนะนำมอดูล\textbf{ไพทอร์ช} (PyTorch) ซึ่งเป็นหนึ่งในเครื่องมือที่นิยมใช้กับการเรียนรู้เชิงลึก.
มอดูล\textit{ไพทอร์ช} ช่วยอำนวยความสะดวก ตั้งแต่การย้ายการคำนวณไปทำที่\textit{จีพียู}
การหาค่าเกรเดียนต์อัตโนมัติ ไปจนถึงโปรแกรมสำเร็จรูปสำหรับกลไกการเรียนรู้เชิงลึกเด่น ๆ
ซึ่งจะช่วยให้การใช้งาน และการเรียนรู้\textit{การเรียนรู้เชิงลึก}ทำได้สะดวกมากยิ่งขึ้น.

อย่างไรก็ตาม ถึงแม้\textit{ไพทอร์ช} จะได้เตรียมโปรแกรมสำเร็จต่าง ๆ ไว้ให้
แต่การได้เขียนโปรแกรมจากปฏิบัติการพื้นฐานขึ้นเอง ก็ยังเป็นกระบวนการเรียนรู้ที่สำคัญ
ที่ช่วยให้เข้าใจอย่างแท้จริง.
ดังนั้น การดำเนินเนื้อหาจะเป็นลักษณะเช่นเดิม นั่นคือ เริ่มจากการเขียนโปรแกรมกลไกต่าง ๆ ขึ้นเอง 
จากปฏิบัติการพื้นฐาน
แล้วค่อยทดลองใช้เครืื่องมือสำเร็จที่มี
ในลักษณะค่อย ๆ ขยับทีละขั้น เพื่อสร้างทั้งความเข้าใจ ความคุ้นเคย และสำคัญไม่แพ้กันคือ ความมั่นใจ.
%วิธีนี้จะช่วยสร้างพื้นฐานความเข้าใจที่แข็งแรง และช่วยให้รู้จักและคุ้นเคยกับเครื่องมือที่สะดวก เหมาะกับการใช้งานในทางปฏิบัติ.

การติดตั้ง\textit{ไพทอร์ช} แนะนำให้ศึกษาจากเวป \url{https://pytorch.org/}
โดยหากระบบมี\textit{จีพียู} และยังไม่ได้เตรียมการใช้งาน
แนะนำให้ติดตั้งและเตรียมการใช้งาน\textit{จีพียู} ก่อนติดตั้ง\textit{ไพทอร์ช}.
หลังติดตั้งเรียบร้อย
เช่นเดียวกับการใช้งานโมเดูลเพิ่มเติมอื่น ๆ
เราต้องนำเข้า มอดูล\textit{ไพทอร์ช}ก่อน ด้วยคำสั่งเช่น
\verb|import torch|
เมื่อนำเข้าสมบูรณ์
สามารถทดสอบง่าย ๆ ได้โดยการตรวจสอบเวอร์ชั่นของ\textit{ไพทอร์ช} เช่น
\begin{Verbatim}[fontsize=\small]
>>> print(torch.__version__)
1.0.0
\end{Verbatim}
ซึ่ง \texttt{1.0.0} คือเวอร์ชั่นที่ใช้\footnote{%
ตัวอย่างคำสั่งและโปรแกรมต่าง ๆ ที่จะแสดงนี้ ทดสอบกับ \textit{ไพทอร์ช} เวอร์ชั่น 1.0.0.
}
หาก\textit{ไพทอร์ช}ที่ติดตั้งเป็นเวอร์ชั่นอื่นก็จะได้ค่าอื่นออกมา.

รายการ~\ref{code: activation functions torch}
แสดงโปรแกรมฟังก์ชันกระตุ้นเรลู ซอฟต์แมกซ์ และครอสเอนโทรปี
พร้อมฟังก์ชันกำหนดค่าเริ่มต้น ซึ่งทั้งหมดเปลี่ยนเครื่องมือจาก\textit{นัมไพ}มาเป็น\textit{ไพทอร์ช}.
หมายเหตุ ฟังก์ชันครอสเอนโทรปี ใช้ \texttt{eps} เป็นกลไกในการลดปัญหาการคำนวณเชิงเลข.
นั่นคือ กรณีที่ค่าที่ทายเป็นศูนย์ สำหรับเฉลยเป็นหนึ่ง
(ทายผิดมากๆ อาจเกิดตอนเริ่มต้น) จะทำให้เกิด
$-\log(0) \rightarrow \infty$ .
กรณีเช่นนี้ จะทำให้การคำนวณพัง และไม่สามารถคำนวณต่อไปได้.
กลไกในการแก้คือใช้ค่าเล็กๆ เติมเข้าไป $-\log(0 + \epsilon) \rightarrow v_{\max}$ 
ซึ่ง $v_{\max}$ คือค่ามากที่สุด ($\approx 103$) เท่าที่ \texttt{-torch.log} จะสามารถคำนวณได้ก่อนจะให้ค่าออกมาเป็น \texttt{inf}.
ค่า \texttt{1e-45} ที่เลือกใช้ มาจากค่าบวกที่เล็กที่สุด 
ที่เลขทศนิยมขนาดสามสิบสองบิตจะแทนได้
ซึ่งตัวเลขนี้จะต่างจาก \texttt{1e-323} ในรายการ~\ref{code: cross entropy} ที่สำหรับเลขทศนิยมขนาดหกสิบสี่บิต
ซึ่งเป็นข้อมูลดีฟอล์ตของนัมไพ.
 %(ซึ่งประมาณ $1.4 \times 10^{-45}$).
รายการ~\ref{code: class ANN torch}
แสดงโปรแกรมคำนวณโครงข่ายประสาทเทียม ด้วยไพทอร์ช.
สังเกตว่า การสร้างเทนเซอร์ใหม่ จะมีการกำหนด \texttt{device} ด้วย
ซึ่ง การกำหนดนี้จะช่วยให้เราสามารถเปลี่ยนการคำนวณระหว่าง ซีพียู และจีพียูได้สะดวกขึ้น.
ดูแบบฝีกหัด~\ref{ex: torch GPU} %ex: torch mnist GPU} 
สำหรับการคำนวณด้วยจีพียู.

\lstinputlisting[language=Python, caption={[ฟังก์ชันกระตุ้น เขียนด้วยไพทอร์ช]ฟังก์ชันกระตุ้น เขียนด้วยไพทอร์ช}, label={code: activation functions torch}]{05Deep/code/code_torch.py}
\index{english}{artificial neural network!code!pytorch}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!ไพทอร์ช}

รายการ~\ref{code: class ANN torch}
แสดงโปรแกรมโครงข่ายประสาทเทียม
ที่เขียนด้วยไพทอร์ช.
เมื่อเปรียบเทียบโปรแกรมในรายการ~\ref{code: class ANN torch}
กับโปรแกรมในรายการ~\ref{code: class ANN}
จะพบว่า
(1) คลาส \verb|tANN1| \textit{รับมรดก}%
\footnote{%
การรับมรดก (inheritance) เป็นกลไก\textit{การเขียนโปรแกรมเชิงวัตถุ} (object-oriented programming) ที่สำคัญ ช่วยให้เราสามารถใช้โปรแกรมเดิมซ้ำได้ โดยเปลี่ยนเฉพาะส่วนที่จำเป็น.
}
มาจากคลาส \texttt{ANN} (รายการ~\ref{code: class ANN})
เพื่อลดความซ้ำซ้อน
และ
(2) เมท็อด \verb|train| และ \verb|predict| เพียงเปลี่ยนมาใช้คำสั่งของไพทอร์ชเท่านั้น%
\footnote{%
เพื่อลดความซับซ้อนของโปรแกรม
สำหรับชั้นซ่อน 
คลาส \texttt{tANN1} รับฟังก์ชันกระตุ้น \texttt{trelu} ได้เท่านั้น.
}.
นอกจากนั้น เพื่อความกระชับ เมท็อด \verb|train|
ได้ตัด \verb|track_grad| ออก (ไม่มี \verb|track_grad| ในเมท็อด \verb|train| เช่นในรายการ~\ref{code: class ANN torch}.
หมายเหตุ \verb|track_grad| ใช้ประกอบการศึกษาปัญหาการเลือนหายของเกรเดียนต์ ดูแบบฝึกหัด~\ref{ex: vanishing gradient 2} เพิ่มเติม).
ข้อควรระวังคือ เมื่อใช้ไพทอร์ช ข้อมูลเทนเซอร์ที่ประมวลผลทุกตัว ต้องอยู่ในรูปแบบเทนเซอร์ของไพทอร์ช.

ตัวอย่างคำสั่งต่อไปนี้ ฝึก และทดสอบโครงข่ายประสาทเทียมที่เขียนด้วยไพทอร์ช
\begin{lstlisting}[language=Python, , caption={[ตัวอย่างโปรแกรมรันโครงข่ายประสาทเทียมที่เขียนด้วยไพทอร์ช]ตัวอย่างโปรแกรมรันโครงข่ายประสาทเทียมที่เขียนด้วยไพทอร์ช}, label={code: torch ann run example}]
dev = torch.device('cpu')
net = tw_initn1([2, 8, 8, 3], dev=dev)
net['act1'] = trelu
net['act2'] = trelu
net['act3'] = tsoftmax
ann = tANN1(net, NB=50, shuffle='once')

t_losses = ann.train(x, y_onehot, tcross_entropy, 
                     lr=0.0017, epochs=500)
yp = ann.predict(ttestx)
ypn = yp.to(torch.device('cpu')).data.numpy()
yc = np.argmax(ypn, axis=0)
accuracy = np.mean(yc == testy[0,:])
print('**Test accuracy: ', accuracy)
\end{lstlisting}
เมื่อ \texttt{x}, \verb|y_onehot|, และ \texttt{ttestx}
เป็นอินพุตของข้อมูลฝึก, เอาต์พุตของข้อมูลฝึก, และอินพุตของข้อมูลทดสอบ ในรูปแบบของไพทอร์ช.
ส่วน \texttt{testy} เป็นเอาต์พุตของข้อมุลทดสอบในรูปแบบนัมไพ.

ข้อมูลสามารถแปลงไปมาระหว่างรูปแบบของนัมไพและไพทอร์ช ได้เช่น
คำสั่ง 
\begin{Verbatim}[fontsize=\small]
ypn = yp.to(torch.device('cpu')).data.numpy()
\end{Verbatim}
แปลง \verb|yp| จากรูปแบบไพทอร์ช ออกมาเป็นข้อมูลในรูปแบบนัมไพอาร์เรย์.
การแปลงจากข้อมูลนัมไพอาร์เรย์ ก็สามารถแปลงเป็นไพทอร์ช ได้เช่น
\begin{Verbatim}[fontsize=\small]
x = torch.from_numpy(trainx).float().to(dev)
\end{Verbatim}
เป็นการแปลงข้อมูลนัมไพอาร์เรย์ \verb|trainx| มาเป็นรูปแบบไพทอร์ช.

\lstinputlisting[language=Python, caption={[คลาสโครงข่ายประสาทเทียมแบบไพทอร์ช]คลาส สำหรับคำนวณการฝึกและการทำนายของโครงข่ายประสาทเทียม ด้วยไพทอร์ช}, label={code: class ANN torch}]{05Deep/code/code_ann_torch.py}
\index{english}{artificial neural network!code!pytorch}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!ไพทอร์ช}

\begin{Exercise}
	\label{ex: torch}
	\index{english}{pytorch}
	\index{thai}{ไพทอร์ช}

ศึกษาโปรแกรมในรายการ~\ref{code: class ANN torch}
เปรียบเทียบกับโปรแกรมในรายการ~\ref{code: class ANN}.
จงออกแบบการทดลองเพื่อทดสอบเปรียบเทียบโปรแกรมทั้งสองแบบ
ทั้งในเชิงเวลาในการฝึก เวลาในการอนุมาน คุณภาพการฝึก
โดยคำนึงถึงปัจจัยประกอบคือ 
ความลึกและความซับซ้อนของโครงข่ายประสาทเทียมที่เลือกใช้
และจำนวนจุดข้อมูลกับจำนวนมิติของอินพุต.
ดำเนินการทดลอง
สังเกต บันทึกผล สรุปและอภิปราย.
	
\end{Exercise}

\paragraph{การคำนวณด้วยจีพียู.}
จุดประสงค์หลักของการใช้ไพทอร์ช 
คือ การที่ไพทอร์ชสามารถส่งการคำนวณไปทำใน\textit{จีพียู}ได้
โดยไม่ต้องยุ่งเกี่ยวกับรายละเอียดปลีกย่อยระดับล่างของการเขียนโปรแกรมขนานและการเขียนโปรแกรม\textit{จีพียู}.

คำสั่ง
\verb|torch.cuda.device_count()|
ตรวจสอบจำนวน\textit{จีพียู}ที่สามารถใช้งานได้.
คำสั่ง
\verb|dev = torch.device('cuda:0')|
เตรียมตัวแปร\textit{วัตถุ} \texttt{dev} สำหรับการอ้างถึงอุปกรณ์\textit{จีพียู}
และเพื่อจะคำนวณด้วย\textit{จีพียู}
ตัวแปรเทนเซอร์ทุกตัว จะต้องกำหนดอุปกรณ์เป็น\textit{จีพียู}
ดังตัวอย่างเช่น 
\texttt{x = torch.randn(D, N, device=dev, dtype=torch.float)}
เมื่อ \texttt{D} และ \texttt{N} เป็นจำนวนส่วนประกอบในลำดับมิติที่หนึ่งและสองตามลำดับ.
หรือแม้แต่การแปลงตัวแปรจาก\textit{นัมไพอาร์เรย์}
ตัวอย่างเช่น
\verb|torchx = torch.from_numpy(datax).float().to(dev)|
เมื่อ \verb|datax| เป็นข้อมูลในรูปแบบ\textit{นัมไพอาร์เรย์} ที่ต้องการ.
สังเกตว่า นอกจากการกำหนดอุปกรณ์คำนวณแล้ว
ชนิดของข้อมูลก็ถูกกำหนดเป็นเลขทศนิยมขนาดสามสิบสองบิต (32-bit floating point number).

\begin{Exercise}
	\label{ex: torch GPU}
	
	คล้ายกับแบบฝึกหัด~\ref{ex: torch}
จงออกแบบการทดลองเพื่อทดสอบเปรียบเทียบโปรแกรมในรายการ~\ref{code: class ANN torch}
เมื่อทำการคำนวณด้วย\textit{จีพียู} 
เปรียบเทียบกับ เมื่อทำการคำนวณด้วย\textit{ซีพียู}
ทั้งในเชิงเวลาในการฝึก เวลาในการอนุมาน คุณภาพการฝึก
โดยคำนึงถึงปัจจัยประกอบคือ 
ความลึกและความซับซ้อนของโครงข่ายประสาทเทียมที่เลือกใช้
และจำนวนจุดข้อมูลกับจำนวนมิติของอินพุต.
ดำเนินการทดลอง
สังเกต บันทึกผล สรุปและอภิปราย.

หมายเหตุ
ดังที่ได้อภิปราย 
การเปลี่ยนอุปกรณ์คำนวณ 
สามารถทำได้โดยการระบุอุปกรณ์ที่เทนเซอร์ทุกตัว ตัวอย่างเช่น
คำสั่งในรายการ~\ref{code: torch ann run example}
สามารถเปลี่ยนอุปกรณ์คำนวณเป็น\textit{จีพียู}
ได้โดยแก้ไขคำสั่งกำหนดอุปกรณ์ในบรรทัดที่หนึ่งเป็น
%\begin{Verbatim}[fontsize=\small]
\verb|dev =|
\texttt{torch.device}
\verb|('cuda')|
%\end{Verbatim}
%(ทดสอบ ``นอกคำสั่ง'' `นอกคำสั่ง' \verb|"'in code'"|)
และเพิ่มคำสั่ง
\begin{Verbatim}[fontsize=\small]
x = x.to(dev)
y_onehot = y_onehot.to(dev)
ttestx = ttestx.to(dev)
\end{Verbatim}
เพื่อระบุอุปกรณ์ให้กับเทนเซอร์ของข้อมูลที่จะนำไปคำนวณ.


%ตัวอย่างคำสั่งข้างล่าง แสดงการฝึก และการทดสอบโครงข่ายประสาทเทียม
%เมื่อทำการคำนวณด้วย\textit{จีพียู}
%\begin{Verbatim}[fontsize=\small]
%dev = torch.device("cuda")
%
%net = tw_initn1([2, 8, 8, 3], dev=dev)
%net['act1'] = trelu
%net['act2'] = trelu
%net['act3'] = tsoftmax
%ann = tANN1(net, NB=50, shuffle='once')
%
%t_losses = ann.train(x, y_onehot, tcross_entropy, lr=0.5, epochs=500)
%
%yp = ann.predict(ttestx)
%ypn = yp.to(torch.device('cpu')).data.numpy()
%yc = np.argmax(ypn, axis=0)
%accuracy = np.mean(yc == testy[0,:])
%print('**Test accuracy: ', accuracy)
%\end{Verbatim}
%เมื่อ \texttt{x}, \verb|y_onehot|, และ \texttt{ttestx}
%เป็นอินพุตของข้อมูลฝึก, เอาต์พุตของข้อมูลฝึก, และอินพุตของข้อมูลทดสอบ ในรูปแบบของไพทอร์ช.
%ส่วน \texttt{testy} เป็นเอาต์พุตของข้อมุลทดสอบในรูปแบบนัมไพ.
	

\end{Exercise}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\paragraph{การหาเกรเดียนต์อัตโนมัติ.}
นอกจากความสามารถในการเปลี่ยนอุปกรณ์การคำนวณเป็น\textit{จีพียู}แล้ว
ความสามารถที่สะดวกมากอย่างหนึ่งของ\textit{ไพทอร์ช} คือ การหาค่าเกรเดียนต์ได้โดยอัตโนมัติ 
(ผ่านกลไกของมอดูลย่อย \texttt{torch.autograd}).
นั่นหมายถึง เราไม่จำเป็นต้องคำนวณและเตรียมโปรแกรมเพื่อคำนวณเกรเดียนต์เอง ดังเช่น
โปรแกรมที่เขียนสำหรับเมท็อด \texttt{train} ในรายการ%~\ref{code: class ANN} หรือ
~\ref{code: class ANN torch}.

การหาเกรเดียนต์อัตโนมัติด้วยไพทอร์ช 
(1) จะต้องระบุในตัวแปรที่ต้องการคำนวณเกรเดียนต์
โดยกำหนด \verb|requires_grad| ของเทนเซอร์ให้ค่าเป็น \texttt{True}
ตัวอย่างเช่น หากต้องการคำนวณเกรเดียนต์ $\nabla_{\bm{w}} E$ ซึ่งเป็นเกรเดียนต์ของค่า $E$ ต่อตัวแปร $\bm{w}$
อาจจะระบุที่ตัวแปร $\bm{w}$ โดยตรงด้วย \verb|w.requires_grad|
\texttt{ = True}
หรืออาจจะระบุไปพร้อมการกำหนดค่าเริ่มต้น ด้วย
\begin{Verbatim}[fontsize=\small]
w = torch.randn(M, D, requires_grad=True)
\end{Verbatim}
%\verb|w = torch.randn(M, D, requires_grad=True)|
ก็ได้.
การกำหนด \verb|requires_grad| เป็น \texttt{True}
จะบอกให้ไพทอร์ชติดตามการคำนวณที่เกี่ยวข้องกับตัวแปร เพื่อนำมาคำนวณหาค่าเกรเดียนต์ได้ถูกต้อง.

จากนั้นหลังการคำนวณค่าเป้าหมาย $E$ เสร็จสิ้น (2) ต้องระบุให้\textit{ไพทอร์ช}คำนวณเกรเดียนต์
ด้วยคำสั่ง เช่น \verb|E.backward()| เมื่อ \verb|E| เป็นตัวแปรเทนเซอร์แทนค่าเป้าหมาย $E$.
ค่าเกรเดียนต์ $\nabla_{\bm{w}} E$ ที่คำนวณได้ จะเก็บไว้ที่\textit{ลักษณะประจำ} (attribute) \verb|grad|
ของตัวแปร เช่น ในตัวอย่างนี้ คือ \verb|w.grad|.
แต่การปรับค่าพารามิเตอร์ ต้องทำนอกการขอบเขตของการคำนวณเกรเดียนต์อัตโนมัติ
และหลังการปรับค่า ต้องล้างค่าเกรเดียนต์ออกสำหรับการคำนวณครั้งต่อไป.
ตัวอย่างเช่น เมื่อต้องการปรับค่าพารามิเตอร์ อาจทำโดย
\begin{Verbatim}[fontsize=\small]
with torch.no_grad():
    w -= learning_rate * w.grad
    w.grad.zero_()
\end{Verbatim}
เมื่อ \verb|learning_rate| เป็นค่าอัตราการเรียนรู้.

แบบฝึกหัด~\ref{ex: torch mnist GPU autograd} 
แสดงตัวอย่างโปรแกรมโครงข่ายประสาทเทียมที่เขียนโดยใช้การหาเกรเดียนต์อัตโนมัติ
และการเรียกใช้.

\begin{Exercise}
	\label{ex: torch mnist GPU autograd}

รายการ~\ref{code: class ANN torch autograd}
แสดงโปรแกรมโครงข่ายประสาทเทียมที่เขียนด้วยไพทอร์ชและใช้การหาเกรเดียนต์อัตโนมัติ
โดยเพื่อลดความซ้ำซ้อน
คลาส \texttt{tANN2} \textit{รับมรดก} จากคลาส \texttt{tANN1} (รายการ~\ref{code: class ANN torch}).

นอกจาก คลาส \texttt{tANN2}
สังเกตว่า 
ฟังก์ชันต่างๆ ในเส้นทางของการแพร่กระจายย้อยกลับ ต้องถูกเขียนใหม่
และการเขียนเมท็อด \verb|backward| ต้องเขียนการคำนวณอนุพันธ์ย้อน
เช่น $\frac{\partial E}{\partial a}$
ซึ่ง $\frac{\partial E}{\partial a} = \frac{\partial z}{\partial a} \cdot \frac{\partial E}{\partial z}$
$=h'(a) \cdot \frac{\partial E}{\partial z}$.
กลไกของการหาเกรเดียนต์อัตโนมัติ จะคำนวณส่วน $\frac{\partial E}{\partial z}$ มาให้.
(เปรียบเทียบกับ \texttt{drelu} ในรายการ~\ref{code: activation functions torch} ซึ่งคำนวณ $h'(a)$.
ดูสมการ~\ref{eq: backprop delta q < L} ประกอบ.) 
%
%ไม่ใช่ $h'(a) = \frac{\partial h(a)}{\partial a}$.
ตัวอย่างนี้ แสดงฟังก์ชัน\textit{เรลู} และฟังก์ชัน\textit{เอกลักษณ์}
ฟังก์ชันอื่น ๆ ก็สามารถทำได้ในลักษณะเดียวกัน. %
%\footnote{
%ฟังก์ชันอื่นๆ เช่น ฟังก์ชันซอฟต์แมกซ์และฟังก์ชันครอสเอนโทรปี
%ก็สามารถทำได้ 
%เพียงแต่การคำนวณอนุพันธ์ของฟังก์ชันซอฟต์แมกซ์และฟังก์ชันครอสเอนโทรปี
%จะทำได้มีประสิทธิภาพมากกว่าหากทำรวมกัน
%การแยกหาเฉพาะอนุพันธ์ของฟังก์ชันซอฟต์แมกซ์ สามารถทำได้ แต่จะลดประสิทธิภาพการคำนวณลง.
%แม้แต่การใช้งานมอดูลสำเร็จของไพทอร์ช ก็แนะนำให้ใช้วิธีการคำนวณเป็นคู่.
%}

ดังที่ได้อภิปราย ตัวแปรที่ต้องการคำนวณเกรเดียนต์ต้องถูกระบุอย่างชัดเจน
ซึ่งดำเนินการในโปรแกรม \verb|tw_initn2| (เปรียบเทียบกับ \verb|tw_initn1| จากรายการ~\ref{code: activation functions torch}).

การใช้งานสามารถทำได้ในลักษณะเดิม ตัวอย่างเช่น
\begin{Verbatim}[fontsize=\small]
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

net = tw_initn2([1, 16, 1], dev=device)
net['act1'] = auto_relu.apply
net['act2'] = auto_identity.apply

ann = tANN2(net, NB=50, shuffle='once')
train_losses = ann.train(tx, ty, sse, lr=0.2/50, epochs=500)

yp = ann.predict(torch.from_numpy(testx).float().to(device))
yn = yp.to(torch.device('cpu')).data.numpy()
print('test rmse', np.sqrt(np.mean((yn - testy)**2)))
\end{Verbatim}
เมื่อ \texttt{tx} กัย \texttt{ty} เป็นอินพุตและเอาต์พุตของข้อมูลฝึกในรูปแบบไพทอร์ช
และ 
\texttt{testx} กับ \texttt{testy} เป็นอินพุตและเอาต์พุตของข้อมูลทดสอบในรูปแบบนัมไพ.

\lstinputlisting[language=Python, caption={[โปรแกรมโครงข่ายประสาทเทียมด้วยไพทอร์ชและการหาเกรเดียนต์อัตโนมัติ]คลาสโครงข่ายประสาทเทียม 
สำหรับการหาค่าถดถอย ที่เขียนด้วยไพทอร์ชและการหาเกรเดียนต์อัตโนมัติ.}, label={code: class ANN torch autograd}]{05Deep/code/code_torch_autograd.py}
\index{english}{artificial neural network!code!class!pytorch|autograd}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!คลาส!ไพทอร์ช!การหาเกรเดียนต์อัตโนมัติ}

จากโปรแกรมตัวอย่างข้างต้น 
จงทดสอบโปรแกรม เปรียบเทียบกับการคำนวณเกรเดียนต์ด้วยมือ (รายการ~\ref{code: class ANN torch})
โดย ออกแบบการทดลอง เลือกหรือสร้างข้อมูล ดำเนินการทดลอง สังเกต บันทึกผล สรุปและอภิปราย.
\textit{หมายเหตุ} ตัวอย่างโปรแกรมในรายการ~\ref{code: class ANN torch autograd}
มีฟังก์ชัน \verb|identity| และ \verb|sse|.
ดังนั้นงานการหาค่าถดถอย สามารถทำได้ทันที
แต่งานอื่นๆ เช่น การจำแนกค่าทวิภาค (ต้องการฟังก์ชันซิกมอยด์และครอสเอนโทรปีสำหรับสองค่า) หรือการจำแนกกลุ่ม (ต้องการฟังก์ชันซอฟต์แมกซ์และครอสเอนโทรปี)
ซึ่งสามารถทำได้เช่นเดียวกัน แต่ต้องเตรียมฟังก์ชันที่เกี่ยวข้องให้พร้อมก่อน.
	
\end{Exercise}

\paragraph{มอดูลย่อย \texttt{nn}.}
การหาเกรเดียนต์อัตโนมัติ ช่วยลดภาระทั้งการวิเคราะห์เกรเดียนต์ และการเขียนโปรแกรมลงไปมาก.
แม้จะลดภาระลงไปมาก แต่การโปรแกรมโครงข่ายประสาทเทียม 
จากปฏิบัติการพื้นฐาน (ดังเช่นที่ทำตัวอย่างในรายการ~\ref{code: class ANN torch autograd})
ถือเป็นการเขียนโปรแกรมในระดับล่าง 
ซึ่งเป็น\textit{ภาระเชิงปัญญา} (cognitive burden).
เพื่อช่วยลดภาระนี้ รวมถึงช่วยในแง่ของ\textit{ลำดับชั้นของความคิด}%
\footnote{%
\textit{ลำดับชั้นของความคิด} เป็นแนวคิดทางวิศวกรรมคอมพิวเตอร์ และวิศวกรรมทั่วไป (และจริง ๆ แล้วก็รวมถึงกิจกรรมต่าง ๆ ไปจนถึงอารยธรรมของมนุษยชาติ)
ที่จะมองหรือแก้ปัญหาในหลาย ๆ ระดับของรายละเอียด
โดยการคิดในระดับบน จะละการพิจารณารายละเอียดของระดับล่างที่เกินความจำเป็นออก.
การละรายละเอียดระดับล่างออก ช่วยลด\textit{ภาระเชิงปัญญา} ทำให้สามารถมองปัญหาไปได้ไกลขึ้น กว้างขึ้น และเป็นองค์รวมมากขึ้น.
}
(hierarchy of abstraction)
\index{thai}{ลำดับชั้นของความคิด}
\index{english}{hierarchy of abstraction}
การประยุกต์ใช้งานโครงข่ายประสาทเทียมลึก
จะทำได้มีประสิทธิภาพกว่า เมื่อใช้มอดูลสำเร็จ เช่น มอดูล \texttt{nn}.
มอดูล \texttt{nn}
มีโครงสร้างและฟังก์ชันสำเร็จต่างๆ สำหรับกลไกที่มีการใช้อย่างแพร่หลาย.
ตัวอย่างคำสั่ง กำหนดโครงข่ายด้วยไพทอร์ช \texttt{nn}
แสดงในรายการ~\ref{code: class ANN torch nn}
โดยตัวอย่างคำสั่ง สำหรับการฝึกและทดสอบ
แสดงในรายการ~\ref{code: class ANN torch nn train test}.
%
หมายเหตุ 
ในรายการ~\ref{code: class ANN torch nn train test}
โปรแกรมทำ \verb|model.zero_grad()| ในช่วงปลายสมัย (หลังจากทำอย่างอื่นเสร็จ) 
เพื่อให้เปรียบเทียบได้ตรงมาตรงไปกับการฝึกที่แสดงในรายการ~\ref{code: class ANN torch autograd}. 
อย่างไรก็ตาม
ความนิยม คือทำการล้างค่าเกรเดียนต์ช่วงต้นสมัยฝึก (ทำก่อนที่จะทำอย่างอื่น).
%
\lstinputlisting[language=Python, caption={[โปรแกรมโครงข่ายประสาทเทียมด้วยไพทอร์ช \texttt{nn}]ตัวอย่างการใช้ไพทอร์ช \texttt{nn}
เพื่อกำหนดโครงข่ายประสาทเทียมสำหรับการจำแนกกลุ่ม
โดยอินพุตมีสองมิติและเอาต์พุตมีสามมิติ ชั้นซ่อนมี $8$ และ $16$ หน่วยตามลำดับ.
ฟังก์ชันกระตุ้นเป็นเรลู.
ฟังก์ชันกระตุ้นเอาต์พุตเป็นซอฟต์แมกซ์.
}, label={code: class ANN torch nn}]{05Deep/code/code_nn1a.py}
\index{english}{artificial neural network!code!class!pytorch|nn}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!คลาส!ไพทอร์ช!nn}

%
\lstinputlisting[language=Python, caption={[ตัวอย่างคำสั่งการฝึกและทดสอบโครงข่ายประสาทเทียม ที่เขียนด้วยมอดูล \texttt{nn}]ตัวอย่างคำสั่งการฝึกและทดสอบโครงข่ายประสาทเทียมของรายการ~\ref{code: class ANN torch nn}
โดยใช้ฟังก์ชันสูญเสียเป็นครอสเอนโทรปี.
ข้อมูลฝึก อินพุต \texttt{tdatax} เป็นไพทอร์ชเทนเซอร์สัดส่วน $D \times N$
เมื่อ $D$ เป็นจำนวนมิติ และ $N$ เป็นจำนวนข้อมูล.
ฉลากเฉลยของเอาต์พุต	\texttt{tdatay} เป็นไพทอร์ชเทนเซอร์สัดส่วน $1 \times N$.
	%ของเลขจำนวนเต็ม (นั่นคือ \verb|tyc.type()| จะให้ \verb|torch.cuda.LongTensor|)
	%และมีสัดส่วนเป็น $N$ (นั่นคือ \verb|tyc.shape| จะให้ \verb|torch.Size([2000])| เมื่อ $N = 2000$.)
เนื่องจาก
มอดูล \texttt{nn}
รับค่าอินพุตในสัดส่วน $N \times D$
และ \texttt{torch.nn.NLLLoss} รับฉลากเฉลยของเอาต์พุต
ในรูปเลขจำนวนเต็ม ในสัดส่วน $N$
ดังนั้น คำสั่งตัวอย่างจึงใช้ \texttt{tdatax.transpose(0,1)} และ \texttt{tdatay[0].long()} สำหรับการป้อนข้อมูลฝึก.
ข้อมูลทดสอบ อินพุต \texttt{ttestx} เป็นไพทอร์ชเทนเซอร์สัดส่วน $D \times N'$ เมื่อ $N'$ คือจำนวนข้อมูลทดสอบ.
ส่วนฉลากเฉลยของข้อมูลทดสอบ \texttt{ttesty} เป็นไพทอร์ชเทนเซอร์สัดส่วน $1 \times N'$.
ตัวแปร \texttt{nepochs} และ \texttt{lr} คือจำนวนสมัยฝึก และค่าอัตราเรียนรู้.
}, label={code: class ANN torch nn train test}]{05Deep/code/code_nn1b.py}
\index{english}{artificial neural network!code!class!pytorch|nn}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!คลาส!ไพทอร์ช!nn}


โปรแกรมในรายการ~\ref{code: class ANN torch nn}
คำนวณซอฟต์แมกซ์ด้วย
\verb|torch.nn.Softmax(dim = 1)|
และคำนวณครอสเอนโทรปีด้วย
\verb|loss =| \verb|loss_fn(torch.log(yhat),tdatay[0].long())|
โดย \verb|loss_fn = torch.nn.NLLLoss()|.
การจัดการคำนวณเช่นนี้ 
เพื่อให้โปรแกรมในรายการ~\ref{code: class ANN torch nn}
สามารถเปรียบเทียบกับโปรแกรมที่เขียนจากปฏิบัติการพื้นฐานได้สะดวกขึ้น.
แต่ในทางปฏิบัติ 
การคำนวณจะมีประสิทธิภาพมากกว่า
หากทำโดยใช้ \verb|nn.LogSoftmax| คู่กับ \verb|nn.NLLLoss|
หรือสะดวกกว่า
โดยใช้
\verb|nn.CrossEntropyLoss|
ซึ่งคำนวณซอฟต์แมกซ์และครอสเอนโทรปีรวมกันเลย.

หมายเหตุ 
โดยดีฟอล์ต
ทั้ง \verb|nn.NLLLoss| และ \verb|nn.CrossEntropyLoss|
คำนวณค่าสูญเสียเฉลี่ยต่อของหมู่เล็กออกมา (ดีฟอล์ต เป็น \texttt{reduction='mean'}.
ดูรายละเอียดการทำงานของแต่ละฟังก์ชันได้จาก 
\url{https://pytorch.org/docs/stable/nn.html}.)
%และ จะเฉลี่ยค่าสูญเสียของแต่ละจุดข้อมูลต่อหมู่เล็กออกมา 
%(สามารถเปลี่ยนได้ โดยกำหนดค่าอาร์กิวเมนต์ \texttt{reduction='mean'} 
%loss_fn = torch.nn.NLLLoss(reduction='sum'))
%
%คำนวณซอฟต์แมกซ์ด้วย
%\verb|torch.nn.LogSoftmax(dim = 1)|
%และครอสเอนโทรปีด้วย
%\verb|loss_fn = torch.nn.NLLLoss()|
%กับ
%\verb|loss = loss_fn(yhat, tdatay[0].long())|.
%หรือสะดวกกว่า
%โดยการคำนวณซอฟต์แมกซ์และครอสเอนโทรปีรวมกันเลย
%ด้วย
%\verb|loss_fn = torch.nn.CrossEntropyLoss()|
%กับ
%\verb|loss = loss_fn(yhat, tdatay[0].long())|
%และตัดบรรทัด \verb|torch.nn.Softmax(dim = 1)|
%ในรายการ~\ref{code: class ANN torch nn} ออกเลย.
%
ในเชิงตรรกะการทำงานแล้ว
การใช้ผลรวมหรือค่าเฉลี่ย ต่างกันเพียงค่าคงที่ที่นำไปหารค่าฟังก์ชันสูญเสียเท่านั้น.
แต่ในทางปฏิบัติ ความต่างนี้มีผลโดยตรง
คือ
(1)
หากเขียนโปรแกรมเอง
ผลรวม อาจทำได้อย่างมีประสิทธิภาพมาก
ผ่านการจัดการคูณเมทริกซ์ 
แต่ค่าเฉลี่ยต้องเพิ่มการหารเข้ามา
ซึ่งการหารนี้ อาจทำได้อย่างมีประสิทธิภาพมาก
โดยทำที่อัตราการเรียนรู้.
(2)
ไม่ว่าจะเขียนโปรแกรมเอง
หรือใช้โปรแกรมสำเร็จ
การใช้ค่าเฉลี่ย จะให้ผลคำนวณที่ค่อนข้างคงที่ เมื่อเทียบกับจำนวนข้อมูล.
นั่นคือ หากใช้ผลรวม เมื่อจำนวนข้อมูลมาก
ค่าสูญเสียที่เห็น (ซึ่งคือผลรวมค่าสูญเสีย)
จะมีตัวเลขใหญ่.
นั่นคือ
เมื่อเพิ่มจำนวนข้อมูลฝึกเข้าไป
ค่าสูญเสียขณะฝึกที่เห็น
จะมีค่ามากขึ้น
เมื่อเปรียบเทียบกับการฝึกด้วยข้อมูลน้อย ๆ
(ซึ่งไม่ได้แปลว่า การฝึกแย่ลง).
แต่หากใช้ค่าเฉลี่ย 
ค่าสูญเสียที่เห็น (ซึ่งคือค่าสูญเสียเฉลี่ย)
จะมีตัวเลขที่อยู่ในระดับเปรียบเทียบได้
ไม่ว่าจะใช้จำนวนจุดข้อมูลฝึกเท่าไร.
(3)
การเลือกค่าอัตราเรียนรู้
จะทำได้สะดวกกว่าในกรณีค่าเฉลี่ย.
นั่นคือ หากพบค่าอัตราเรียนรู้ที่ใช้ได้ดีกับชุดข้อมูล เมื่อมีจำนวนข้อมูลน้อยๆ 
แล้วถ้ามีจำนวนข้อมูลเพิ่มขึ้นมามาก
การใช้ค่าอัตราเรียนรู้เดิม โดยทั่วไป ก็จะสามารถใช้ได้ดี.
แต่หากใช้ผลรวม
เมื่อจำนวนข้อมูลเพิ่มขึ้น จะทำให้ผลรวมค่าสูญเสียและผลรวมเกรเดียนต์มากขึ้น
โดยธรรมชาติ เพราะมีพจน์ที่จะรวมมากขึ้น.
ดังนั้น ค่าอัตราเรียนรู้เดิม อาจจะใช้ได้ไม่ดี และอาจจะต้องปรับลดลงเป็นอัตราส่วนตามจำนวนข้อมูลที่เพิ่มขึ้น.
การรู้ระลึกถึงประเด็นผลรวมหรือค่าเฉลี่ยนี้
จะช่วยให้การเลือกค่าอัตราเรียนรู้
และการอ่านผลความก้าวหน้าการฝึก
ทำได้ดียิ่งขึ้น.

การใช้ \verb|nn.Sequential|
แม้จะสะดวก แต่หากต้องการกำหนด\textit{ทอพอโลยี} (topology การเชื่อมต่อ)
ที่อิสระ ยืดหยุ่น และหลากหลายมากขึ้น
การใช้ \verb|nn.Module| (ดังแสดงในรายการ~\ref{code: class ANN torch nn.Module}) อาจจะเหมาะสมกว่า.
ตัวอย่าง\textit{ทอพอโลยี}ที่เกินกว่า \verb|nn.Sequential| จะสามารถบรรยายได้
มีมากมาย รวมถึง \textit{อเล็กซ์เน็ต}\cite{Alexnet2012} (หัวข้อ~\ref{sec: AlexNet}).

การบันทึกแบบจำลองที่ฝึกแล้วก็สามารถทำได้ เช่น
\begin{Verbatim}[fontsize=\small]
torch.save(net.state_dict(), './sav/nn1.pth')
\end{Verbatim}
เมื่อ \texttt{net} เป็นแบบจำลองที่ต้องการบันทึกค่าเก็บไว้
และ \verb|'.sav/nn1.pth'| เป็นเส้นทางและชื่อไฟล์ที่บันทึก.
%
การเรียกใช้แบบจำลองที่บันทึกไว้สามารถทำได้ เช่น
\begin{Verbatim}[fontsize=\small]
net = Net().to(device)
net.load_state_dict(torch.load('.sav/nn1.pth'))
\end{Verbatim}
เมื่อ \texttt{Net()} เป็นโครงสร้างของแบบจำลอง.
สังเกตว่า การบักทึกค่า จะบันทึกเฉพาะค่าของพารามิเตอร์
ดังนั้น การเรียกใช้แบบจำลองจึงประกอบด้วยการสร้างตัวแปรวัตถุของแบบจำลองขึ้นมาใหม่
และกำหนดค่าของพารามิเตอร์ตามค่าที่บันทึกไว้.


\lstinputlisting[language=Python, caption={[โปรแกรมโครงข่ายประสาทเทียมด้วยไพทอร์ช \texttt{nn.Module}]	
	ตัวอย่าง แสดงโครงข่ายสามชั้น แบบเดียวกับโปรแกรมในรายการ~\ref{code: class ANN torch nn}
	แต่ใช้การกำหนด\textit{ทอพอโลยี}เอง (เมท็อด \texttt{forward}) โดยคลาส\textit{รับมรดก}จาก \texttt{nn.Module} ซึ่งยืดหยุ่นกว่า\textit{ทอพอโลยี}ของ \texttt{nn.Sequential}.
%	สังเกตว่าการเชื่อมต่อต่าง ๆ ถูกกำหนดขึ้นเอง จากสมการที่คำนวณในเมท็อด \texttt{forward}.
}, label={code: class ANN torch nn.Module}]{05Deep/code/code_nn2.py}
\index{english}{artificial neural network!code!class!pytorch|nn}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!คลาส!ไพทอร์ช!nn}

%หมายเหตุ
%สำหรับฟังก์ชันเรลู สามารถใช้ \verb|nn.functional.relu| แทนได้ \verb|nn.ReLU()| ได้
%แต่เพื่อให้รายการ~\ref{code: class ANN torch nn.Module} เปรียบเทียบได้ง่ายกับรายการ~\ref{code: class ANN torch nn}
%การนำเสนอ จึงเลือกรูปแบบข้างต้น.
%
%
% ได้ง่าย.
%และจะทำให้วากยสัมพันธ์กระชับขึ้น
%นั่นคือ
%ตัวอย่างเช่น
%แทนที่จะเป็น 
%\begin{Verbatim}[fontsize=\small]
%z1 = torch.nn.ReLU()(self.fc1(x))
%\end{Verbatim}
%วากยสัมพันธ์จะเป็น 
%\begin{Verbatim}[fontsize=\small]
%z1 = torch.nn.functional.relu(self.fc1(x))
%\end{Verbatim}

\begin{Exercise}
	\label{ex: pytorch nn}

จงทดสอบโปรแกรมโครงข่ายประสาทเทียม
ที่เขียนโดยใช้มอดูล \texttt{nn} 
เปรียบเทียบกับโปรแกรมที่เขียนการคำนวณเกรเดียนต์เอง (เช่น โปรแกรมในรายการ~\ref{code: class ANN torch})
โดย ออกแบบการทดลอง เลือกหรือสร้างข้อมูล ดำเนินการทดลอง สังเกต บันทึกผล สรุปและอภิปราย.

\end{Exercise}

\paragraph{มอดูลช่วยจัดหมู่ย่อย \texttt{utils.data.DataLoader}.}
การทำการฝึกหมู่เล็ก (ดังเช่น โปรแกรมในรายการ~\ref{code: class ANN})
ก็สามารถดำเนินการได้ด้วยมอดูลย่อย \texttt{utils.data.DataLoader}.
การใช้งาน % \texttt{utils.data.DataLoader}
จะต้องสร้างตัวแปรวัตถุของ \verb|DataLoader| 
โดยการสร้างตัวแปรวัตถุนี้ ต้องกำหนดข้อมูลที่ต้องการเข้าไป
และข้อมูลนี้ต้องอยู่ในรูป\textit{แม่แบบ}ของ \verb|utils.data.Dataset|
ที่ตัวอย่างคำสั่งข้างล่างใช้คลาส \texttt{MyDataset} (รายการ~\ref{code: MyDataset}) เข้ามาช่วย.
%
\begin{Verbatim}[fontsize=\small]
mydat = MyDataset()
mydat.assign_data(DX, DY)
datloader = torch.utils.data.DataLoader(mydat, batch_size=50, 
                shuffle=True, num_workers=0)
\end{Verbatim}
เมื่อกำหนดขนาดหมู่เล็กเป็น $50$.
ตัวแปร \texttt{DX} และ \texttt{DY}
เป็นข้อมูลอินพุตและเอาต์พุต ชนิดไพทอร์ชเทนเซอร์ สัดส่วน $N \times D_x$ และ $N \times D_y$
ตามลำดับ
โดย $N$ เป็นจำนวนจุดข้อมูล
และ
$D_x$ กับ $D_y$ เป็นมิติของอินพุตและเอาต์พุต.

การเรียกใช้ ก็สามารถทำได้ เช่นเดียวกับตัวแปร\textit{วนซ้ำ}%
\footnote{%
ตัวแปร\textit{วนซ้ำ} (iterable variable)
หมายถึง
ตัวแปรวัตถุ ที่สามารถให้ค่าสมาชิกของมันออกมาได้ทีละตัว
ซึ่งสามารถใช้งานได้สะดวกกับการวนซ้ำด้วยคำสั่ง \texttt{for}.
ไพธอน มีข้อมูลหลายชนิดที่เป็นตัวแปร\textit{วนซ้ำ} เช่น ลิสต์ ทูเพิล และดิกชันนารี.
}%
อื่น ๆ ของไพธอน เช่นตัวอย่าง
\begin{Verbatim}[fontsize=\small]
for t in range(num_epochs):
    for data in trainloader:
        inputs, labels = data
        yhat = net(inputs)
        loss = loss_fn(yhat, labels[:,0])
        loss.backward()
        with torch.no_grad():
            for param in net.parameters():
                param -= learn_rate * param.grad
        net.zero_grad()
\end{Verbatim}
เมื่อ \verb|num_epochs| และ \verb|learn_rate| เป็นจำนวนสมัยฝึกและอัตราการเรียนรู้ ตามลำดับ.
ในตัวอย่างคำสั่งนี้ โปรแกรม \verb|loss_fn| รับเฉลยในรูปแบบไพทอร์ชเทนเซอร์ หนึ่ง\textit{ลำดับชั้น}%
\footnote{%
นั่นคือ เมื่อตรวจดูสัดส่วน 
เช่น รันคำสั่ง \texttt{labels[:,0].shape} 
แล้วจะเห็นสัดส่วนเป็น \texttt{torch.Size([50])}
ไม่ใช่ \texttt{torch.Size([50, 1])} ที่หมายถึง ไพทอร์ชเทนเซอร์ สอง\textit{ลำดับชั้น}.
}
ดังนัั้น คำสั่ง \verb|loss = loss_fn(yhat, labels[:,0])| จึงต้องจัดฉลากเฉลยให้อยู่ในรูปแบบดังกล่าว.


\lstinputlisting[language=Python, caption={[คลาส \texttt{MyDataset} เพื่อใช้กับ \texttt{utils.data.DataLoader}]
คลาส \texttt{MyDataset} เพื่อใช้กับ \texttt{utils.data.DataLoader}.
หมายเหตุ หากยังไม่ได้ทำการนำเข้า \texttt{torch.utils.data} อาจต้องทำการนำเข้าก่อน.
}, label={code: MyDataset}]{05Deep/code/MyDataset.py}
\index{english}{artificial neural network!code!class!pytorch|MyDataset}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!คลาส!ไพทอร์ช!MyDataset}

\begin{Exercise}
	\label{ex: torch dataloader}
	
	จากแบบฝึกหัด~\ref{ex: mnist}
	จงเขียนโปรแกรมโดยใช้มอดูล \texttt{nn} 
	และการหาเกรเดียนต์อัตโนมัติ 
	พร้อมด้วยจัดการข้อมูลฝึกด้วย \texttt{utils.data.DataLoader} 
	และเปรียบเทียบผล กับผลลัพธ์จากแบบฝึกหัด~\ref{ex: mnist} 
	สรุป และอภิปราย.
\end{Exercise}

\begin{Exercise}
	\label{ex: torch dataloader built-in mnist}
\index{english}{torchvision}
\index{english}{built-in datasets!MNIST}	
\index{thai}{ชุดข้อมูลโหลดสำเร็จ!MNIST}	
	
จากแบบฝึกหัด~\ref{ex: torch dataloader}
ที่เราดาวน์โหลดข้อมูลเอง เตรียมข้อมูลเอง จัดรูปแบบต่าง ๆ จนข้อมูลสามารถนำเข้าไปใช้กับ
ตัวแปรวัตถุของ \verb|DataLoader| ได้.
%ซึ่งสามารถนำไปประยุกต์ใช้กับข้อมูลใด ๆ ก็ได้.
อย่างไรก็ตาม 
พัฒนาการของการเรียนรู้ของเครื่องและการรู้จำรูปแบบ ก้าวหน้าไปมาก
และมีชุดข้อมูลที่มีการศึกษาอย่างกว้างขวาง และนิยมใช้เพื่อเรียนรู้ หรือเพื่อการทดสอบกลไกใหม่ ๆ.
%เพื่ออำนวยความสะดวก
สำหรับชุดข้อมูลที่นิยมหลาย ๆ ชุด ไพทอร์ชมีกลไกช่่วยเหลือ
ด้วยมอดูล \texttt{torchvision} เพื่อลดภาระในการเตรียมข้อมูลเหล่านี้ลง.
ตัวอย่างคำสั่งข้างล่าง เตรียมชุดข้อมูลเอมนิสต์ตั้งแต่ดาวน์โหลด (หากยังไม่มี)
ไปจนถึงจัดเข้าตัวแปรวัตถุของ \verb|DataLoader| และพร้อมที่จะถูกเรียกใช้งาน
\begin{Verbatim}[fontsize=\small]
import torchvision
import torchvision.transforms as transforms

transform = transforms.Compose( [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.MNIST(root='./data', train=True,
            download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=50,
            shuffle=True, num_workers=0)
testset = torchvision.datasets.MNIST(root='./data', train=False,
            download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=50,
            shuffle=False, num_workers=0)
\end{Verbatim}
เมื่อตัวแปร \verb|trainloader| และ \verb|testloader|
คือตัวแปรวัตถุของ \verb|DataLoader| สำหรับข้อมูลฝึกและข้อมูลทดสอบตามลำดับ.

จงเขียนโปรแกรม เพื่อฝึกและทดสอบชุดข้อมูลเอมนิสต์
โดยใช้ข้อมูลโหลดสำเร็จ.
สังเกตผล สรุป และอภิปราย.
หมายเหตุ การวัดค่าความแม่นยำของข้อมูลทดสอบที่แบ่งเป็นหมู่เล็ก จะช่วยลดภาระการใช้หน่วยความจำทีเดียวมาก ๆ ได้.

%correct = 0
%N = 0
%for data in trainloader:
%    # get the inputs; data is a list of [inputs, labels]
%    inputs, labels = data
%    yp = net(inputs)
%    _, yc = torch.max(yp, 1)
%    correct += torch.sum((yc == labels[:,0]).float()).item()
%
%    N += 1
%
%print(correct/(50*N))


\end{Exercise}

\paragraph{มอดูลย่อย \texttt{optim}.}
ดังที่อภิปรายในหัวข้อ~\ref{sec: adv training opt}
มีขั้นตอนวิธีมากมาย ที่สามารถนำมาฝึกแบบจำลองได้.
มอดูล \texttt{optim}
จัดเตรียมขั้นตอนวิธีที่นิยมต่าง ๆ ไว้ให้.
โดยตัวอย่างคำสั่งต่อไปนี้
แสดงการใช้งาน วิธีลงเกรเดียนต์%
\footnote{%
โปรแกรม \texttt{optim.SGD} หมายถึง 
\textit{วิธีลงเกรเดียนต์แบบสโทแคสติก} (stochastic gradient descent method)
ซึ่งมีกลไกหลัก คือ วิธีลงเกรเดียนต์ และเน้นการสุ่มลำดับข้อมูล (ดูหัวข้อ~\ref{sec: minibatch})
นอกจากนั้น \texttt{optim.SGD} ยังมีกลไกโมเมนตัมด้วย (หัวข้อ~\ref{sec: momentum}).
}
%
ที่ใช้อัตราเรียนรู้เป็น $0.001$ และโมเมนตัมเป็น $0.0$
โดย \verb|net| คือแบบจำลองที่ต้องการฝึก 
\begin{Verbatim}[fontsize=\small]
device = torch.device('cuda')
net = torch.nn.Sequential( torch.nn.Linear(784, 8), torch.nn.ReLU(),
                           torch.nn.Linear(8, 10) ).to(device)
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.0)
\end{Verbatim}
และการฝึกก็สามารถทำได้ดังแสดงในรายการ~\ref{code: train optim}.
สังเกต โปรแกรมในรายการ~\ref{code: train optim} ล้างค่าเกรเดียนต์ \verb|net.zero_grad()| ตั้งแต่ต้นของลูป.

\lstinputlisting[language=Python, caption={[ตัวอย่างคำสั่งฝึกแบบจำลอง ด้วยมอดูล \texttt{optim}]ตัวอย่างการฝึกแบบจำลอง ด้วยมอดูล \texttt{optim}
โดย \texttt{nepochs} เป็นจำนวนสมัยฝึก.
% และ \texttt{nms} เป็นจำนวนหมู่เล็ก.
อินพุต \texttt{inputs} และเอาต์พุต \texttt{labels} มีีสัดส่วน \texttt{(N, 784)}
และสัดส่วน \texttt{N} ตามลำดับ
เมื่อ \texttt{N} เป็นขนาดหมู่เล็ก ที่กำหนดไว้กับ \texttt{trainloader}.
}, label={code: train optim}]{05Deep/code/code_train_optim.py}
\index{english}{artificial neural network!code!pytorch!optim}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!ไพทอร์ช!optim}

\begin{Exercise}
	\label{ex: torch optim}

	จงเลือกหรือสร้างข้อมูล เลือกแบบจำลอง ฝึกโดยใช้การหาค่าดีที่สุดจากมอดูล \texttt{optim}
	ทดสอบ สรุปและอภิปราย.
	
\end{Exercise}

\begin{Exercise}
	\label{ex: implement dropout}
	
	จากหัวข้อ~\ref{sec: dropout}
	จงศึกษาและเขียนโปรแกรมสำหรับกลไก\textit{การตกออก}
	จงเลือกหรือสร้างข้อมูล ทำแบบจำลอง โดยใช้เทคนิค\textit{การตกออก}ที่เขียนขึ้น
	ทดสอบ สังเกตผล สรุป และอภิปราย.
	หมายเหตุ การใช้\textit{การตกออก} อาจทำให้ต้องการแบบจำลองที่ใหญ่ขึ้น(ซับซ้อนขึ้น) จากการทำแบบจำลองที่ไม่ใช้\textit{การตกออก} รวมถึงอาจทำให้ต้องการจำนวนสมัยฝึกที่มากขึ้น.
	\textit{คำใบ้} การฝึกอาจทำได้ช้าลง แต่ให้สังเกตการลดลงของค่าฟังก์ชันสูญเสีย
	และในการทดสอบ อย่าลืมชดเชย การตกออก.
	แบบฝึกหัดนี้ ต้องการให้ได้ทดลองฝึกเขียนโปรแกรมด้วยตนเอง แต่หากต้องการ 
	แบบฝึกหัด~\ref{ex: implement dropout example} แสดงตัวอย่างโปรแกรม.

\end{Exercise}


\begin{Exercise}
	\label{ex: implement dropout example}

	จงศึกษา และเปรียบเทียบโปรแกรมที่เขียนขึ้นสำหรับแบบฝึกหัด~\ref{ex: implement dropout}
	กับโปรแกรมตัวอย่าง (รายการ~\ref{code: implement dropout} และการนำไปใช้ในแบบจำลอง แสดงในรายการ~\ref{code: NN with implemented dropout}.
	การฝึกและทดสอบ แสดงในรายการ~\ref{code: train test NN with implemented dropout})
	ทั้งวิธีการเขียน และพฤติกรรมการทำงาน.
	
	สังเกตว่า ถึงแม้ชื่อคือ \textit{การตกออก} แต่ค่าความน่าจะเป็น (ตัวแปร \texttt{oneprob} ในรายการ~\ref{code: implement dropout} ซึ่งจะรับค่า \texttt{0.8} และ \texttt{0.5} ในรายการ~\ref{code: NN with implemented dropout}) ระบุถึง%ความน่าจะเป็นของ $m=1$ หรือ
	ความน่าจะเป็นของการคงอยู่.
	\textit{ข้อควรระวัง} การใช้งานมอดูลสำเร็จ ควรศึกษาตรวจสอบพฤติกรรมการทำงานให้ชัดเจนก่อน.
%	เช่น ไพทอร์ช ใช้ค่าความน่าจะเป็นของการคงอยู่
%	และตัวอย่างโปรแกรมในแบบฝึกหัดนี้ ก็เขียนขึ้นเพื่อให้สอดคล้องกับไพทอร์ช. 
%%	ซึ่งครอบคลุมในแบบฝึกหัด~\ref{ex: dropout built-in}.
%	แต่มอดูลอื่นๆ อาจไม่ได้ยึดตามแนวปฏิบัตินี้.
%	 และอาจเลือกใช้%
%%	 \textit{เทนเซอร์โฟลว์} (Tensorflow) ซึ่งเป็นอีกมอดูลที่ได้รับความนิยมมาก 
%ใช้ค่าความน่าจะเป็นของการตกออกได้.
	
	
\lstinputlisting[language=Python, caption={[ตัวอย่างโปรแกรมการตกออก]ตัวอย่างโปรแกรมการตกออก.
สำหรับอนุพันธ์ $\frac{\partial E}{\partial z'} = \frac{\partial E}{\partial z} \cdot \frac{\partial z}{\partial z'}$
เมื่อ $E$ คือค่าฟังก์ชันสูญเสีย
และ $z'$ กับ $z$ คือ ค่าหน่วยย่อยหลังทำการตกออก และก่อนทำการตกออก ตามลำดับ.
ค่า $\frac{\partial z}{\partial z'} = m$
เมื่อ $m$ คือ \textit{หน้ากาก} หรือค่าสัมประสิทธิ์ของการตกออก ($m \in \{0, 1\}$ และ $m$ มีการแจกแจงแบบ\textit{แบร์นูลลี่} และความน่าจะเป็นของค่าหนึ่ง แทนด้วยอาร์กิวเมนต์ \texttt{onprob}).
}, label={code: implement dropout}]{05Deep/code/code_imp_dropout1.py}
\index{english}{artificial neural network!code!dropout}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!การตกออก}

\lstinputlisting[language=Python, caption={[ตัวอย่างโปรแกรมโครงข่ายประสาทเทียมที่ใช้การตกออกที่เขียนขึ้นเอง]ตัวอย่างโปรแกรมโครงข่ายประสาทเทียมที่ใช้การตกออกที่เขียนขึ้นเอง.
สังเกต 
(1) การตกออก ทำเฉพาะตอนฝึก
(2) การอนุมาน ต้องชดเชย\textit{การตกออก}.
โปรแกรม ใช้กลไกของ \texttt{nn.Module} ที่มีสถานะ \texttt{self.training}
ในการตรวจสอบว่า กำลังฝึก หรือกำลังใช้งานอนุมาน.
}, label={code: NN with implemented dropout}]{05Deep/code/code_dropout1_net.py}
\index{english}{artificial neural network!code!dropout}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!การตกออก}

\lstinputlisting[language=Python, caption={[ตัวอย่างการฝึกและทดสอบโครงข่ายประสาทเทียมที่ใช้การตกออกที่เขียนขึ้นเอง]ตัวอย่างการฝึกและทดสอบโครงข่ายประสาทเทียมที่ใช้การตกออกที่เขียนขึ้นเอง.
สังเกต เพื่อระบุว่า การคำนวณเป็นการฝึก หรืออนุมาน
จะใช้
คำสั่ง \texttt{net.train()}
และคำสั่ง \texttt{net.eval()}
ซึ่งคำสั่งทั้งสอง จะเข้าไปเปลี่ยนค่า \texttt{net.training}
ที่โปรแกรมภายในคลาส \texttt{Net} สามารถนำไปตรวจสอบได้.
}, label={code: train test NN with implemented dropout} ]{05Deep/code/code_run_nn_dropout1.py}
\index{english}{artificial neural network!code!dropout}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!การตกออก}

\end{Exercise}

\begin{Exercise}
	\label{ex: dropout implement example 2}

	ดังที่อภิปรายในหัวข้อ~\ref{sec: dropout}
การตกออก อาจดำเนินการชดเชย โดยใช้การหารค่าความน่าจะเป็น ออกจากค่าหน่วยย่อย ตอนฝึก
แทนการคูณเข้า ขณะทำการอนุมาน.
ตัวอย่างโปรแกรมในรายการ~\ref{code: implement dropout multiply w}
แสดงโปรแกรมการตกออก ที่เขียนโดยใช้การหาร ตอนฝึก เพื่อชดเชยค่าที่ตกออกไป.
จงเปรียบเทียบความต่างกับโปรแกรมในรายการ~\ref{code: implement dropout}
ทั้งวิธีการเขียน และพฤติกรรมการทำงาน.

\lstinputlisting[language=Python, caption={[ตัวอย่างโปรแกรมการตกออก โดยการชดเชยล่วงหน้า]ตัวอย่างโปรแกรมการตกออก  โดยการหารค่าความน่าจะเป็น ขณะฝึก เพื่อชดเชยการตกออก.
หมายเหตุ เพื่อให้แนวคิดตรรกะการทำงานชัดเจน โปรแกรมในตัวอย่างใช้การหาร.
ในทางปฏิบัติ การคูณด้วย $1.25$ และ $2$ จะให้ประสิทธิภาพและเสถียรภาพดีกว่า การหารด้วย $0.8$ และ $0.5$ ตามลำดับ.	
}, label={code: implement dropout multiply w}]{05Deep/code/code_dropout2_net.py}
\index{english}{artificial neural network!code!dropout}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!การตกออก}

\end{Exercise}

\paragraph{การตกออก ด้วย \texttt{nn.Dropout}.}
มอดูล \texttt{nn} มีมอดูลย่อยสำหรับทำ\textit{การตกออก} 
คือ \texttt{nn.Dropout}.
ตัวอย่างคำสั่งข้างล่าง แสดงการใช้ \texttt{nn.Dropout} เพื่อใช้งานกลไก\textit{การตกออก}
ในลักษณะเดียวกับโปรแกรมในรายการ~\ref{code: NN with implemented dropout}.
\begin{Verbatim}[fontsize=\small]
class Net(torch.nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.do0 = torch.nn.Dropout(p=0.2)
        self.fc1 = torch.nn.Linear(784, 16)
        self.do1 = torch.nn.Dropout(p=0.5)
        self.fc2 = torch.nn.Linear(16, 10)

    def forward(self, x):
        xm = self.do0(x)
        z1 = torch.relu(self.fc1(xm))
        z1m = self.do1(z1)
        z2 = self.fc2(z1m)
        return z2
\end{Verbatim}
สังเกตการใช้ \texttt{nn.Dropout}
ไม่ต้องกำหนดการคำนวณแยกระหว่างการฝึก และการอนุมาน (เช่นที่ต้องทำในรายการ~\ref{code: NN with implemented dropout})
เพราะว่า
\texttt{nn.Dropout}
มีกลไกภายในที่จัดการเรื่องนี้ให้.

นอกจากนั้น 
\verb|nn.Dropout|
รับความน่าจะเป็นที่จะตกออก (เปรียบเทียบกับ โปรแกรมในรายการ~\ref{code: implement dropout} ที่เป็นความน่าจะเป็นของการคงอยู่)
ดังนั้น ณ ที่นี้ \verb|self.do0| สำหรับอินพุตจึงใช้ \verb|p=0.2| ซึ่งคือ โอกาสตกออกเป็น $0.2$ (หรือโอกาสคงอยู่ $0.8$).

%x = torch.rand(10)
%print('x:', x)
%d = torch.nn.Dropout(p=0.8)
%print('drop out:', d(x))


%
%อย่างไรก็ตาม เพื่อให้การฝึกและการอนุมานทำได้อย่างถูกต้อง
%การใช้แบบจำลองที่มี \texttt{nn.Dropout} ต้องระบุโหมดการทำงานให้ชัดเจน ดังตัวอย่างคำสั่งข้างล่าง
%สำหรับการฝึก
%\begin{Verbatim}[fontsize=\small]
%net = Net()
%net.train() # Set mode to training
%for t in range(nepochs):
%    for i, data in enumerate(trainloader):
%        x, y = data
%        yhat = net(x)
%        loss = loss_fn(yhat, y)
%        loss.backward()
%        optimizer.step()
%    # end for data
%# end for t
%\end{Verbatim}
%สังเกตการใช้ \texttt{net.train()} เพื่อระบุโหมดการทำงาน เป็นการฝึก
%(ซึ่ง ภายใน คือ การกำหนดค่า \texttt{net.training} ให้เป็น \texttt{True}).
%การอนุมาน สามารถทำได้ ดังตัวอย่างคำสั่งข้างล่าง
%\begin{Verbatim}[fontsize=\small]
%net.eval() # Set mode to evaluation
%correct = 0
%num = 0
%for data in testloader:
%    x, y = data
%    yp = net(x)
%    _, yc = torch.max(yp, 1)
%    correct += torch.sum((yc == y).float())
%    num += len(y)
%print('Accuracy', correct/num)
%\end{Verbatim}
%สังเกตการใช้ \texttt{net.eval()} เพื่อระบุโหมดการทำงาน เป็นการอนุมาน
%(ซึ่ง กำหนดค่า \texttt{net.training} ให้เป็น \texttt{False}).

\begin{Exercise}
	\label{ex: dropout built-in}
	จากแบบฝึกหัด~\ref{ex: implement dropout}
	จงทำแบบจำลองที่ใช้กลไก\textit{การตกออก} โดยใช้ \texttt{nn.Dropout}
	เปรียบเทียบโปรแกรม การทำงาน และผลการทำงาน
	สรุปผล และอภิปราย.
	
\end{Exercise}

\begin{Exercise}
	\label{ex: dropout behavior}

จงศึกษาการทำงานและผลของการใช้\textit{การตกออก}
โดยเปรียบเทียบกับ (1) การไม่ใช้เทคนิค\textit{การตกออก}
และ
(2) การทำค่า\textit{น้ำหนักเสื่อม}.
ทดสอบกับข้อมูลที่มีความยากต่าง ๆ กัน มีปริมาณข้อมูลต่าง ๆ กัน และเมื่อแบบจำลองมีความซับซ้อนต่าง ๆ กัน.
สังเกตผล สรุปและอภิปราย.

\end{Exercise}



\begin{Exercise}
	\label{ex: dropout vs noise}

จงเขียนโปรแกรมโครงข่ายประสาทเทียม
ที่มีชั้นสัญญาณรบกวน 
ที่รับค่าหน่วยย่อย 
$\bm{z}$
เป็นอินพุต
และให้ค่า $\bm{z}'$ เป็นเอาต์พุต
โดย $\bm{z}' = \bm{m} \odot \bm{z}$
เมื่อ $\bm{m}$ เป็นเมทริกซ์ขนาดเดียวกับ $\bm{z}$
และแต่ละส่วนประกอบ $m \sim \mathcal{N}(1, \sigma)$
และ $\sigma$ เป็นอภิมานพารามิเตอร์ กำหนดจากผู้ใช้.

ออกแบบการทดลอง เพื่อทดสอบประสิทธิภาพการใช้ชั้นสัญญาณรบกวน เปรียบเทียบกับ\textit{การตกออก}
ทั้งเรื่องการฝึก และผลของแบบจำลองที่ฝึกได้.
ดำเนินการทดลอง สังเกตผล สรุปและอภิปราย.
ศึกษางานวิจัยของศรีวาสทาวาและคณะ\cite{srivastavaEtAl2014a}
อภิปรายผลที่ได้ เปรียบเทียบกับผลจากศรีวาสทาวาและคณะ.

รายการ~\ref{code: implement noise multiply w}
แสดงตัวอย่างโปรแกรม.
สังเกตว่า การใช้ชั้นสัญญาณรบกวน สะดวกกว่า\textit{การตกออก}
ในแง่ที่ไม่ต้องทำการชดเชยขณะใช้งานอนุมาน.

\lstinputlisting[language=Python, caption={[ตัวอย่างโปรแกรมชั้นสัญญาณรบกวน]ตัวอย่างโปรแกรมชั้นสัญญาณรบกวน.
}, label={code: implement noise multiply w}]{05Deep/code/code_noise1.py}
\index{english}{artificial neural network!code!noise layer}
\index{thai}{โครงข่ายประสาทเทียม!โปรแกรม!ชั้นสัญญาณรบกวน}

\end{Exercise}

\begin{Exercise}
	\label{ex: ann predicts dists}
	
\textbf{การทำนายการแจกแจง.}
แม้การหาค่าถดถอย การจำแนกค่าทวิภาค และการจำแนกกลุ่ม เป็นกลุ่มภาระกิจที่มีการใช้งานมากที่สุด
แต่การใช้งานโครงข่ายประสาทเทียม ไม่ได้จำกัดอยู่แต่เฉพาะกลุ่มภาระกิจที่นิยมเหล่านี้.
โครงข่ายประสาทเทียม สามารถประยุกต์ใช้งานได้กว้างขวาง%
\footnote{%
เนื้อหา ในแบบฝึกหัดนี้ได้รับอิทธิพลหลัก ๆ จากกูดเฟโลและคณะ\cite[\textsection 6.2.2.4]{GoodfellowEtAl2016}.
}%
. หลักการของวิธี\textit{ค่าฟังก์ชันควรจะเป็นสูงสุด} (maximum likelihood)
\index{thai}{ค่าฟังก์ชันควรจะเป็นสูงสุด}
\index{english}{maximum likelihood}
เป็นแนวทางหนึ่งที่ทั่วไปมากพอ ที่สามารถใช้ออกแบบ\textit{ฟังก์ชันจุดประสงค์}สำหรับภาระกิจต่าง ๆ ที่ต้องการได้.

หลักการของวิธี\textit{ค่าฟังก์ชันควรจะเป็นสูงสุด} คือ
หากกำหนดให้ $\bm{X}$ และ $\bm{Y}$ เป็นข้อมูลที่สนใจ
และ
$p(\bm{Y}|\bm{X}; \bm{\theta})$
เป็น
ค่าประมาณ\textit{ความน่าจะเป็น} 
โดย $\bm{\theta}$ เป็นพารามิเตอร์แล้ว
ค่าของพารามิเตอร์ $\bm{\theta}$ สามารถหาได้จาก
\begin{eqnarray}
\bm{\theta}^\ast &=& \arg\max_{\bm{\theta}} p(\bm{Y}|\bm{X}; \bm{\theta})
\label{eq: maximum likelihood}
\end{eqnarray}
เมื่อ $\bm{\theta}^\ast$ คือค่าพารามิเตอร์ที่ดีที่สุด (สำหรับแบบจำลองและข้อมูลที่มี).

แบบฝึกหัดนี้
เราจะศึกษาการทำโครงข่ายประสาทเทียมสำหรับทำนาย\textit{การแจกแจง}ของข้อมูล.
นั่นคือ จากที่เคยใช้โครงข่ายประสาทเทียม $f$ ทำนายค่าเอาต์พุต $y$ จากอินพุต $x$
แบบฝึกหัดนี้จะใช้โครงข่ายประสาทเทียมทำนาย\textit{การแจกแจง}ของเอาต์พุต $y$ จากอินพุต $x$.
แนวทางคือ แทนที่จะใช้โครงข่ายประสาทเทียมทำนายค่าความน่าจะเป็น%
\footnote{%
เพื่อให้เนื้อหามีความทั่วไป และไม่เยิ่นเย้อมาก
ในที่นี้จะใช้คำว่า ความน่าจะเป็น ในความหมายของความน่าจะเป็น หรือในกรณีที่ตัวแปรที่เกี่ยวข้องเป็น\textit{ตัวแปรสุ่มต่อเนื่อง}
จะหมายถึง ความหนาแน่นความน่าจะเป็น.
ดูหัวข้อ~\ref{sec: continuous random variable} เพิ่มเติม สำหรับความต่างระหว่างความน่าจะเป็น
และความหนาแน่นความน่าจะเป็น.
} 
$p(y|x)$ 
โดยตรง 
เราจะใช้โครงข่ายประสาทเทียมทำนาย $\bm{\theta}(x)$ ซึ่งนำไปใช้คำนวณค่าประมาณความน่าจะเป็น $p(y; \bm{\theta}(x)) \approx p(y|x)$ อีกต่อหนึ่ง.

%
%และค่าพารามิเตอร์ $\bm{\theta}^\ast = \arg\min_{\bm{\theta}} -\log p(\bm{y}|\bm{x}; \bm{\theta})$.
แบบฝึกหัดนี้ การประมาณความน่าจะเป็น $p(y; \bm{\theta}(x))$ จะคำนวณด้วย \textit{แบบจำลองความหนาแน่นผสม} (mixture density model). 
\index{thai}{แบบจำลองความหนาแน่นผสม}
\index{english}{mixture density model}
\textit{แบบจำลองความหนาแน่นผสม} เป็นแบบจำลองทั่วไปในการประมาณค่าเอาต์พุต จากอินพุต
โดยรวมค่าประมาณจากส่วนผสมต่าง ๆ เข้าด้วยกัน
%ตามค่าน้ำหนัก 
%แต่ละส่วนผสมคำนวณด้วยฟังก์ชันความหนาแน่นของการแจกแจงเกาส์เซียน 
%และค่าน้ำหนักรวมกันเป็นหนึ่ง.
อาจมองว่า \textit{แบบจำลองความหนาแน่นผสม} มีพื้นฐานจาก\textit{กฎผลบวก} และ\textit{กฎผลคูณ}ของ\textit{ทฤษฎีเบส์}ได้
อันคือ $p(y|x) = \sum_{i=1}^M p(y|c=i) p(c=i|x)$
เมื่อ $c=i$ แทนส่วนผสม $i$ 
และ $M$ คือจำนวนส่วนผสมทั้งหมด.
ส่วนผสม $c=i$ อาจมองเสมือนว่าเป็นสถานะภายในของความสัมพันธ์ระหว่าง $x$ กับ $y$ ก็ได้.
ค่า $p(y|c=i)$ ถูกประมาณด้วยความหนาแน่นของการแจกแจงเกาส์เซียน.
ดังนั้น สรุปคือ \textit{แบบจำลองความหนาแน่นผสม} คำนวณ
\begin{eqnarray}
p(y; \bm{\theta}(x)) = \sum_{i=1}^M p(c=i|x) \cdot \mathcal{N}(y; \mu_i(x), \sigma_i(x)) 
\label{eq: GMM p(y; theta(x))}
\end{eqnarray}
เมื่อ $p(c=i|x)$ แทนความน่าจะเป็นของส่วนผสม $i$
และ
$\mathcal{N}(y; \mu_i(x), \sigma_i(x))$ เป็นค่าความหนาแน่นความน่าจะเป็นของการแจกแจงเกาส์เซียน ที่มีค่าเฉลี่ย $\mu_i(x)$ กับค่าเบี่ยงเบนมาตราฐาน $\sigma_i(x)$.
\textit{แบบจำลองเกาส์เซียนผสม} สามารถใช้ประมาณ\textit{ค่าความน่าจะเป็น}จากการแจกแจงใด ๆ ได้ หากมีจำนวนส่วนผสมเพียงพอ.
%โดยทั่วไป 
จำนวนส่วนผสม $M$ เป็นอภิมานพารามิเตอร์ของแบบจำลอง.

สังเกต รูปแบบสมการ~\ref{eq: GMM p(y; theta(x))} เขียนสำหรับกรณีเอาต์พุตมิติเดียว ($y \in \mathbb{R}$).
กรณีทั่วไป ก็สามารถคำนวณได้ในลักษณะเดียวกัน 
นั่นคือ 
$p(\bm{y}; \bm{\theta}(\bm{x})) = \sum_{i=1}^M p(c=i|\bm{x}) \cdot \mathcal{N}(\bm{y}; \bm{\mu}_i(\bm{x}), \bm{\Sigma}_i(\bm{x}))$.
%โดย $\bm{\mu}_i$ และ $\bm{\Sigma}_i$ แทนเวกเตอร์และเมทริกซ์ของค่าเฉลี่ยและความแปรปรวนร่วมเกี่ยว

สำหรับจุดข้อมูลที่ $n^{th}$
ค่าความน่าจะเป็น $p(y_n|x_n) \approx p(y_n; \bm{\theta}(x_n))$
และด้วยสมมติฐาน\textit{ไอ.ไอ.ดี.} (i.i.d. ย่อจาก independent and identically distributed random variables ซึ่ง ณ ที่นี้ หมายถึง สมมติฐานว่าจุดข้อมูลแต่ละจุดเป็นอิสระต่อกัน และมีการแจกแจงเหมือนกัน) \index{english}{i.i.d.}\index{thai}{ไอ.ไอ.ดี.}\index{english}{independent and identically distributed}
จะได้ว่า
\[
p([y_1, y_2, \ldots, y_N]|[x_1, x_2, \ldots, x_N]) = \prod_{n=1}^N p(y_n|x_n)
\]
%เนื่องจากค่าประมาณ\textit{ความน่าจะเป็น} มักจะมีค่าใกล้ ๆ ศูนย์ 
%ซึ่งในทางปฏิบัติ ค่าใกล้ ๆ ศูนย์มักส่งผลให้การคำนวณขาดเสถียรภาพ
%ในทางปฏิบัติ
เพื่อความสะดวกในการคำนวณ
\textit{ค่าลอการิทึมของฟังก์ชันควรจะเป็น} (log likelihood) 
\index{english}{log likelihood}
\index{thai}{ค่าลอการิทึมของฟังก์ชันควรจะเป็น}
จะถูกนิยมมากกว่า.
%นั่นคือ ทางปฏิบัติจะทำ $\bm{\theta}^\ast = \arg\max_{\bm{\theta}} \log p(\bm{y}|\bm{x}; \bm{\theta})$ แทนการคำนวณ~\ref{eq: maximum likelihood}.
นอกจากนั้น
สำหรับการฝึกแบบจำลอง นิยมวางกรอบเป็น\textit{ปัญหาค่าน้อยที่สุด}
ค่าฟังก์ชันสูญเสีย สามารถกำหนดเป็น \textit{ค่าลบลอการิทึมของฟังก์ชันควรจะเป็น} (negative log likelihood).
ดังนั้น ค่าฟังก์ชันสูญเสีย สามารถนิยามได้เป็น
%ได้แก่ $\mathrm{loss} = -\log p(y; \bm{\theta}(x))$.
\begin{eqnarray}
\mathrm{loss} &=& -\log \prod_{n=1}^N p(y_n|x_n)
\nonumber \\
&=& -\sum_n \log p(y_n|x_n)
\label{eq: neg log likelihood} \\
&=& -\sum_n \log \sum_{i=1}^M p(c=i|x_n) \cdot \mathcal{N}(y_n; \mu_i(x_n), \sigma_i(x_n))
\label{eq: neg log likelihood GMM}
\end{eqnarray}

สมการ~\ref{eq: neg log likelihood GMM} ได้จากการใช้\textit{แบบจำลองความหนาแน่นผสม}.
โครงข่ายประสาทเทียม สามารถใช้เพื่อประมาณ พารามิเตอร์ของ\textit{แบบจำลองความหนาแน่นผสม}
$\bm{\theta} = [p(c=i|x), \mu_i(x), \sigma_i(x)]^T$ สำหรับ $i=1, \ldots, M$.

จงศึกษาการทำโครงข่ายประสาทเทียม สำหรับประมาณการแจกแจง
ซึ่งมีรายละเอียด คือ
(1) จงสร้างข้อมูล $\{x_n,y_n\}$ สำหรับ $n=1, \ldots, N$ 
โดยกำหนดความสัมพันธ์ระหว่างตัวแปรต้น $x_n$ และตัวแปรตาม $y_n$
ดังนี้\\
%\begin{itemize}
%	\item 
	(a) สำหรับแต่ละค่าของตัวแปรต้น $x$ ตัวแปรตาม $y$ แสดงออกได้สองลักษณะ. \\
	(b) ลักษณะแรก $y \sim \mathcal{N}(\mu_0(x), \sigma_0(x))$ \\
	โดย $\mu_0(x) = 0.05 x^2 + 4$
	และ $\sigma_0(x) = 0.2 + \log\left(1 + \exp(x-5)\right)$.\\
	(c) ลักษณะที่สอง $y \sim \mathcal{N}(\mu_1(x), 0.5)$
โดย $\mu_1(x) = -0.05 x^2 - 4$. \\
	(d) โอกาสที่ $y$ จะแสดงออกในลักษณะแรก เป็น $0.25+ \frac{0.5}{1 + \exp(-0.4 x)} \times 100\%$. นอกนั้น $y$ จะแสดงออกในลักษณะที่สอง.\\
%\end{itemize}
(2) จงกำหนดโครงข่ายประสาทเทียม ฝึก ทดสอบ สังเกตผล สรุป และอภิปราย.

จากข้อกำหนดของข้อมูล
สังเกตว่า
(ก) ลักษณะข้อมูลเป็นไปตาม\textit{แบบจำลองความหนาแน่นผสม}
และจำนวนลักษณะแสดงออก คือจำนวนส่วนผสม นั่นคือ $M = 2$.
(ข) ความน่าจะเป็นของลักษณะแรก $p_0 = p(c=0|x) = 0.25+ \frac{0.5}{1 + \exp(-0.4 x)}$
และความน่าจะเป็นของลักษณะที่สอง $p_1 = p(c=1|x) = 1 - p(c=0|x)$.
ทั้ง $p_0$ และ $p_1$ เป็นฟังก์ชันของ $x$.
(ค) ลักษณะแรก ทั้งค่าเฉลี่ย $\mu_0$ และค่าเบี่ยงเบนมาตราฐาน $\sigma_0$ เป็นฟังก์ชันของ $x$.
ส่วนลักษณะที่สอง ค่าเฉลี่ย $\mu_1$ เป็นฟังก์ชันของ $x$ แต่ค่าเบี่ยงเบนมาตราฐาน $\sigma_1$ เป็นค่าคงที่.
(ง) ตัวแปรต้น $x \in \mathbb{R}$ ดังนั้น โครงข่ายประสาทเทียมรับอินพุตหนึ่งมิติ.
(จ) พารามิเตอร์ของ\textit{แบบจำลองความหนาแน่นผสม} จะมีทั้งหมด $6$ ตัว 
ได้แก่ $\bm{\theta} = [p_0, p_1, \mu_0, \mu_1, \sigma_0, \sigma_1]^T$
ซึ่งทั้ง $6$ ค่านี้ จะคำนวณมาจากโครงข่ายประสาทเทียม.
ดังนั้น โครงข่ายประสาทเทียมให้เอาต์พุตหกมิติ.
สรุปคือ โครงข่ายประสาทเทียม $f: \mathbb{R} \mapsto \mathbb{R}^6$.

รูป~\ref{fig: dist learn ann data}
แสดงตัวอย่างจุดข้อมูลที่สร้างตามข้อกำหนด.
สังเกตว่า ที่ตัวแปรต้น $x$ แต่ละค่า 
ตัวแปรตาม จะแสดงออกเป็นสองลักษณะ 
ซึ่งทั้งสองลักษณะมีการแจกแจงแบบสุ่ม
โดยลักษณะแรก มีค่ามากกว่าลักษณะที่สอง และแนวโน้มข้อมูลจะโค้งขึ้น 
ในขณะที่ลักษณะที่สอง แนวโน้มข้อมูลจะโค้งลง.
(เกี่ยวข้องกับ $\mu_0$ และ $\mu_1$.)
จุดข้อมูลลักษณะแรก จะเบาบาง (มีสัดส่วนจำนวนจุดน้อยกว่า)
จุดข้อมูลลักษณะที่สอง ในช่วงค่า $x < 0$.
จุดข้อมูลลักษณะที่สอง ดูเบาบางลง เมื่อ $x > 0$.
(เกี่ยวข้องกับ $p_0$ และ $p_1$.)
การแจกแจงของจุดข้อมูลลักษณะที่สอง ดูคงที่ตลอดช่วงค่าของ $x$
แต่จุดข้อมูลลักษณะแรก ดูเหมือนมีการแจกแจงเพิ่มขึ้นอย่างเห็นได้ชัดในช่วง $x$ มีค่ามาก ๆ.
(เกี่ยวข้องกับ $\sigma_0$ และ $\sigma_1$.)

%
\begin{figure}[H]
\begin{center}
\includegraphics[height=1.6in]{05Deep/ex/dist_learn_data.png}
\caption[ตัวอย่างจุดข้อมูล สำหรับโครงข่ายประสาทเทียมเพื่อทำนายการแจกแจง]{
ตัวอย่างจุดข้อมูล สำหรับโครงข่ายประสาทเทียม เพื่อทำนายการแจกแจง.
แกนนอน แสดงค่าตัวแปรต้น $x$
และแกนตั้ง แสดงค่าตัวแปรตาม $y$.
}
\label{fig: dist learn ann data}
\end{center}
\end{figure}

ตัวอย่างโปรแกรม
สำหรับสร้างข้อมูล 
แสดงในรายการ~\ref{code: dist learn relation}.
โปรแกรมเขียนเป็นคลาส และเมท็อดที่ใช้สร้างข้อมูล คือ \verb|sim_y| 
ซึ่งจะสร้างข้อมูลตัวแปรตาม ขึ้นมาจากข้อมูลตัวแปรต้นที่รับเข้าไป.
โปรแกรม สามารถทดสอบได้ง่ายๆ ด้วยคำสั่ง
\begin{Verbatim}[fontsize=\small]
r = relation()
xs = np.linspace(-10, 10, 1000)
ys = r.sim_y(xs)
\end{Verbatim}
ซึ่งค่า \texttt{xs} และ \texttt{ys} สามารถนำไปวาดกราฟ เพื่อดูความสัมพันธ์ได้.

\lstinputlisting[language=Python, caption={[โปรแกรมสร้างข้อมูลสำหรับการทำนายการแจกแจง]โปรแกรม \texttt{relation} เพื่อสร้างข้อมูลสำหรับการทำนายการแจกแจง}, label={code: dist learn relation}]{05Deep/code/code_relation.py}

ตัวอย่างโปรแกรมคำนวณฟังก์ชันสูญเสีย (คำนวณสมการ~\ref{eq: neg log likelihood GMM})
แสดงในรายการ~\ref{code: dist learn loss}.
สังเกต 
(1) แบบจำลองความหนาแน่นผสม ถูกโปรแกรมเป็นส่วนหนึ่งของฟังก์ชันสูญเสีย.
(2) ค่าความหนาแน่น $\mathcal{N}(\mu, \sigma) = \frac{1}{\sigma \sqrt{2 \pi}} \exp \left( -0.5 \left(\frac{y -  \mu}{\sigma}\right)^2 \right)$
คำนวณโดยปฏิบัติการพื้นฐาน ไม่ได้ใช้ฟังก์ชันสำเร็จ.

\lstinputlisting[language=Python, caption={[โปรแกรมคำนวณค่าลบลอการิทึมของฟังก์ชันควรจะเป็น]โปรแกรมคำนวณค่าลบลอการิทึมของฟังก์ชันควรจะเป็น ที่ใช้แบบจำลองความหนาแน่นผสมเป็นพื้นฐาน.
โปรแกรมรับค่า \texttt{yhat} ที่อยู่ในรูปไพธอนทูเพิล \texttt{(dmode, dmu, dsigma)}
เมื่อ \texttt{dmode},
\texttt{dmu}, 
และ \texttt{dsigma}
เป็นค่าทำนาย $[p_0, p_1]^T$, $[\mu_0, \mu_1]^T$,
และ $[\sigma_0, \sigma_1]^T$ ตามลำดับ.
ส่วนเฉลย \texttt{Y} เป็นค่าตัวแปรตามของจุดข้อมูลต่าง ๆ.
ค่า \texttt{eps} ใช้สำหรับป้องกัน 
\texttt{torch.log} ไม่ให้ค่าเป็น \texttt{-inf}.
%$\log(a) \to -\infty$ เมื่อ $a$ มีค่าน้อยมาก ๆ.
}, label={code: dist learn loss}]{05Deep/code/code_dist_learn_loss.py}

ค่าเอาต์พุตของโครงข่าย $\hat{y} = [p_0, p_1, \mu_0, \mu_1, \sigma_0, \sigma_1]^T$
มีลักษณะต่าง ๆ กัน.
ค่า $p_0$ และ $p_1$ เป็นค่าความน่าจะเป็น ซึ่ง $p_i \in [0,1]$ และ $\sum_i p_i = 1$.
ดังนั้น โปรแกรมตัวอย่าง (รายการ~\ref{code: dist ann}) ใช้ฟังก์ชันซอฟต์แมกซ์%
\footnote{%
เนื่องจาก $p_0$ และ $p_1$ 
ไม่ได้เปรียบเทียบกับรหัสหนึ่งร้อน
การใช้ซอฟต์แมกซ์ อาจเพิ่มการคำนวณโดยไม่จำเป็น
และอาจส่งผลเสียต่อเสถียรภาพและคุณภาพของฝึกอีกด้วย.
กรณีนี้
การทำ\textit{นอร์มอไลซ์}ให้เหมาะสม อาจจะเป็นทางเลือกที่ดีกว่า.
}
สำหรับ $[p_0, p_1]^T$ เพื่อคุมเงื่อนไขนี้.
ค่า $\mu_0$ และ $\mu_1$ ไม่มีข้อจำกัดอะไร.
ค่า $\sigma_0$ และ $\sigma_1$ เป็นค่าเบี่ยงเบนมาตราฐาน ซึ่ง $\sigma_i > 0$.
โปรแกรมตัวอย่าง ใช้\textit{ฟังก์ชันบวกอ่อน} $h(a) = \log(1 + \exp(a))$
สำหรับ $[\sigma_0, \sigma_1]^T$ เพื่อคุมเงื่อนไขนี้.

\lstinputlisting[language=Python, caption={[โปรแกรมโครงข่ายประสาทเทียม เพื่อทำนายการแจกแจง]โปรแกรมโครงข่ายประสาทเทียม เพื่อทำนายการแจกแจง.
โครงข่ายสองชั้น รับอินพุตหนึ่งมิิติ ใช้จำนวนหน่วยซ่อนเป็น $8$
ใช้เรลูเป็นฟังก์ชันกระตุ้นชั้นซ่อน และให้เอาต์พุตหกมิติ
โดยเอาต์พุตแยกออกเป็นสามชุด ได้แก่ 
\texttt{ymode}, \texttt{ymu}, และ \texttt{ysigma}
สำหรับ $[p_0, p_1]^T$, $[\mu_0, \mu_1]^T$,
และ $[\sigma_0, \sigma_1]^T$ ตามลำดับ.
}, label={code: dist ann}]{05Deep/code/code_dist_learn2.py}

ด้วยข้อมูล (รายการ~\ref{code: dist learn relation}),
แบบจำลอง (รายการ~\ref{code: dist ann}),
และฟังก์ชันสูญเสีย (รายการ~\ref{code: dist learn loss})
การฝึกก็สามารถทำได้ในลักษณะเดียวกับภาระกิจอื่น ๆ.
อย่างไรก็ตาม รายการ~\ref{code: dist ann train}
แสดงโปรแกรม \texttt{train} สำหรับตัวอย่างการฝึกโครงข่ายเพื่อทำนายการแจกแจง.
การฝึกสามารถทำได้ เช่นตัวอย่างคำสั่ง
\begin{Verbatim}[fontsize=\small]
device = torch.device('cuda')
net = Net().to(device)
net, train_losses = train(net, device, 500, 0.001)
\end{Verbatim}
สำหรับการรันด้วย\textit{จีพียู} $500$ สมัยฝึก ด้วยค่าอัตราเรียนรู้เป็น $0.001$.

หมายเหตุ 
การทำแบบฝึกหัดนี้ ไม่จำเพาะต้องใช้โครงสร้างแบบจำลองตามตัวอย่าง
หรือไม่จำเป็นต้องฝึกดังโปรแกรม \texttt{train}
ไม่จำเป็นต้องใช้ขั้นตอนวิธี\textit{อดัม}
หรือไม่จำเป็นต้องสร้างข้อมูลใหม่ทุกสมัยฝึก
สามารถเลือกวิธีทำ และดำเนินการได้อย่างอิสระ.
%ในการปรับค่าน้้ำหนัก.
%และสร้างข้อมูลใหม่ทุก ๆ สมัยฝึก.
%โครงสร้างของโครงข่าย และการฝึก
%สามารถเลือกโครงสร้างอื่น ๆ ใช้ขั้นตอนวิธีอื่น หรืออาจใช้ข้อมูลซ้ำในแต่ละสมัยฝึก. 

\lstinputlisting[language=Python, caption={[การฝึกโครงข่ายประสาทเทียม เพื่อทำนายการแจกแจง]โปรแกรม \texttt{train} ฝึกโครงข่ายประสาทเทียม เพื่อทำนายการแจกแจง.
.
โดย \texttt{train} รับ \texttt{net}, \texttt{device}, 
\texttt{nepochs}, และ \texttt{lr} สำหรับโครงสร้างของแบบจำลอง,
อุปกรณ์ที่ใช้รัน, จำนวนสมัยฝึก, และอัตราการเรียนรู้ ตาลำดับ.
โปรแกรม \texttt{train} ใช้ขั้นตอนวิธี\textit{อดัม}ในการปรับค่าน้ำหนัก.
และสร้างข้อมูลใหม่ทุก ๆ สมัยฝึก ด้วย \texttt{getdata}.
}, label={code: dist ann train}]{05Deep/code/code_dist_learn_train.py}

รูป~\ref{fig: dist learn ann results compared}
แสดงตัวอย่างผลลัพธ์%
\footnote{%
หลังจากฝึกไป $4000$ สมัยฝึก โดยเริ่มต้นค่าน้ำหนัก
ด้วย\textit{วิธีกำหนดค่าน้ำหนักเซเวียร์} ด้วยอัตรา $\sqrt{2}$
โดยการฝึก $2500$ สมัยแรก ฝึกกับข้อมูลที่ $\sigma_0 = \sigma_1 = 0.5$
และ $1500$ สมัยต่อมา จึงฝึกกับข้อมูลที่มีค่า $\sigma_0$ และ $\sigma_1$ ดังกำหนด.
การฝึกกับข้อมูลดังกำหนด ตั้งแต่แรก พบว่าให้ผลไม่ต่างกันอย่างมีนัยสำคัญ.
}
จากการฝึกแบบจำลองดังตัวอย่าง.
%torch.nn.init.xavier_normal_(m.weight, gain=np.sqrt(2))
%m.bias.data.fill_(0.01)
เนื่องจากลำดับของลักษณะไม่ได้สำคัญ
%นั่นคือ \texttt{mode 0} กับ
%\texttt{mode 1} ไม่ได้มีผลจริง ๆ
ดังนั้น เพื่อลดความสับสนจากลำดับ
ค่าเฉลยที่ใช้สร้างข้อมูลจะติดฉลากเป็น \texttt{mode 0} และ \texttt{mode 1}
ในขณะที่ ผลทำนายจากแบบจำลอง
จะติดฉลากเป็น \texttt{mode a} และ \texttt{mode b}.

จากการเปรียบเทียบ
จะเห็นว่า
แบบจำลองทำนายค่าเฉลี่ย
$\mu_0$ และ $\mu_1$ ได้ดีมาก
เปรียบเทียบ ภาพบนซ้ายกับภาพบนกลาง
จะเห็นแนวเส้นคล้ายกันมาก (เส้นทึบฟ้า \texttt{mode b} คล้ายเส้นทึบแดง \texttt{mode 0} และ เส้นทึบเขียว \texttt{mode a} คล้ายเส้นทึบน้ำเงิน \texttt{mode 1})
ความน่าจะเป็นของส่วนผสม
แบบจำลองก็ทำนายได้ดีพอสมควร 
เปรียบเทียบภาพล่างซ้ายและภาพล่างกลาง.

ภาพขวาบนและล่าง แสดงค่าเฉลี่ย (ภาพบน) และความน่าจะเป็นของส่วนผสม (ภาพล่าง)
ทั้งของเฉลยและที่ทำนายในภาพเดียวกัน.
%
ค่าเบี่ยงเบนมาตราฐาน แสดงด้วยความหนาของพื้นที่แรงเงา ในภาพบนซ้าย (เฉลย)
และภาพบนกลาง (ค่าทำนาย)
ซึ่ง
ลักษณะที่สอง (\texttt{mode 1} ภาพซ้าย และ \texttt{mode a} ภาพกลาง)
อาจจะมองเห็นความหนาได้ยาก
แต่ลักษณะแรก
โดยเฉพาะช่วงปลาย
เห็นชัดเจนว่า
เฉลยมีค่าเบี่ยงเบนมาตราฐานที่หนามาก
แต่ค่าที่ทำนาย แม้จะดูหนาขึ้นในช่วงปลาย แต่ก็ดูแคบกว่าเฉลยมาก.

รูป~\ref{fig: dist learn ann sigmas compared}
เน้นแสดงผลจากค่าเบี่ยงเบนมาตราฐาน (จุดข้อมูลแสดงด้วยขนาดที่เล็กลง และสีพื้นทีแรเงา เลือกให้เข้มขึ้น ในภาพซ้ายและภาพกลาง).
ภาพขวา แสดงค่าเบี่ยงเบนมาตราฐาน
ของทั้งเฉลยและทำนายในภาพเดียวกัน.
ถึงแม้ค่าที่ทำนายอาจจะยังดูห่างจากเฉลยมาก แต่เห็นได้ชัดว่าแบบจำลองสามารถจับแนวโน้มของ $\sigma_0$ (\texttt{sigma b}) ที่เพิ่มในช่วงปลาย
และ $\sigma_1$ (\texttt{sigma a}) ที่คงที่ตลอดช่วงได้.

%
%\begin{figure}[H]
%\begin{center}
%\includegraphics[width=0.8\textwidth]{05Deep/ex/dist_learn_pretrain2500_add1500.png}
%\caption[...]{...
%}
%\label{fig: dist learn ann results}
%\end{center}
%\end{figure}

%
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.8\textwidth]{05Deep/ex/dist_learn_Prediction_Compared.png}
\caption[ผลลัพธ์การเรียนการแจกแจง]{ผลลัพธ์การเรียนการแจกแจง.
ภาพบนซ้ายและกลาง แสดงจุดข้อมูล (จุดสีเทา) พร้อมค่าเฉลี่ย ($\mu_0$ เส้นสีแดง กับ $\mu_1$ สีน้ำเงินในภาพซ้าย และเส้นฟ้ากับสีเขียวในภาพกลาง)
และค่าเบี่ยงเบนมาตราฐาน ($\sigma_0$ และ $\sigma_1$) ซึ่งแสดงด้วยความกว้างของพื้นที่แรเงา.
ภาพบนขวา
แสดงค่าเฉลี่ยของทั้งค่าที่ทำนาย (ใช้สัญลักษณ์ \texttt{y a} และ \texttt{y b} สำหรับ \texttt{mode a} และ \texttt{mode b} ตามลำดับ) และค่าเฉลย
(ใช้สัญลักษณ์ \texttt{Y 0} และ \texttt{Y 1} สำหรับ \texttt{mode 0} และ \texttt{mode 1} ตามลำดับ).
ภาพล่างซ้ายและกลาง 
แสดงค่าความน่าจะเป็นของส่วนผสม
($p_0$ เส้นสีแดง กับ $p_1$ เส้นสีน้ำเงิน ในภาพซ้าย
และเส้นสีฟ้ากับเส้นสีเขียวในภาพกลาง).
ภาพล่างขวา
แสดงค่าความน่าจะเป็นของส่วนผสมทั้งค่าที่ทำนาย (ใช้สัญลักษณ์ \texttt{i=a} และ \texttt{i=b} สำหรับ \texttt{mode a} และ \texttt{mode b} ตามลำดับ) และค่าเฉลย
(ใช้สัญลักษณ์ \texttt{I=0} และ \texttt{I=1} สำหรับ \texttt{mode 0} และ \texttt{mode 1} ตามลำดับ).
}
\label{fig: dist learn ann results compared}
\end{center}
\end{figure}



%
\begin{figure}[H]
\begin{center}
\includegraphics[width=0.8\textwidth]{05Deep/ex/dist_learn_Sigma_compared.png}
\caption[ผลลัพธ์การเรียนค่าเบี่ยงเบนมาตราฐาน]{ผลลัพธ์การเรียนค่าเบี่ยงเบนมาตราฐาน.
ภาพซ้ายและกลาง
แสดง จุดข้อมูล (จุดสีเทา)
และค่าเบี่ยงเบนมาตราฐาน ที่แทนด้วยความหนาของพื้นที่แรเงา.
ภาพขวา แสดงค่าเบี่ยงเบนมาตราฐาน ในแกนตั้ง และค่าตัวแปรต้น $x$ ในแกนนอน.
ค่าเบี่ยงเบนมาตราฐานที่ทำนาย
ใช้สัญลักษณ์ \texttt{sigma a} และ \texttt{sigma b} สำหรับ \texttt{mode a} และ \texttt{mode b} ตามลำดับ.
ค่าเบี่ยงเบนมาตราฐานของเฉลย
ใช้สัญลักษณ์ \texttt{sigma 0} และ \texttt{sigma 1} สำหรับ \texttt{mode 0} และ \texttt{mode 1} ตามลำดับ.	
}
\label{fig: dist learn ann sigmas compared}
\end{center}
\end{figure}

\end{Exercise}

\paragraph{การกำหนดค่าเริ่มต้น.}
เมื่อเราทำการสร้างตัวแปร ค่าของตัวแปรจะถูกกำหนดขึ้นมาด้วย
เช่น 
คำสั่งกำหนดค่า
\texttt{fc1 = torch.nn.Linear(800,5000)} 
จะสร้างพารามิเตอร์ของชั้นคำนวณ
ได้แก่
\texttt{fc1.weight} 
และ
\texttt{fc1.bias}
ซึ่งเป็นเทนเซอร์ สัดส่วน $(800,5000)$
และ
$(5000)$
ตามลำดับ
พร้อมค่าเริ่มต้น.
โดยดีฟอลต์ของไพทอร์ช 
ค่าเริ่มต้นทั้งของค่าน้ำหนักและไบอัส
จะถูกกำหนดดังเช่นสมการ~\ref{eq: standard init}
นั่นคือ
$\theta \sim \mathcal{U}(-\frac{1}{\sqrt{m_i}}, -\frac{1}{\sqrt{m_i}})$
เมื่อ $\theta$ คือค่าน้ำหนักหรือไบอัสแต่ละค่า
และ $m_i$ คือจำนวนแผ่เข้าของชั้นคำนวณ.
ตัวอย่างนี้ $m_i = 800$ และหากตรวจสอบการกระจายของค่าเริ่มต้นที่สร้างขึ้น
ด้วยคำสั่ง เช่น \texttt{plt.hist(fc1.bias.detach())}
จะเห็นแผนภูมิแท่งคล้ายตัวอย่างในรูป~\ref{fig: torch init bias} (ภาพ ก).
สังเกต ค่าต่ำสุดสูงสุดประมาณ $-0.035$ และ $0.035$ ($\frac{1}{\sqrt{800}} \approx 0.035$). 
%
\begin{figure}[h!]
	\begin{center}
\begin{tabular}{cc}
		\includegraphics[height=1.5in]{05Deep/ex/init_bias.png}
		&
		\includegraphics[height=1.5in]{05Deep/ex/init_bias2.png}
\\
ก. & ข.		
\end{tabular}		
\caption[ตัวอย่างการแจกแจงค่าเริ่มต้นของไบอัส]{การแจกแจงค่าเริ่มต้นของไบอัส.
ภาพ ก. $b \sim \mathcal{U}(-0.035, 0.035)$ และภาพ ข. $b \sim \mathcal{U}(-0.01, 0.01)$}			\label{fig: torch init bias}
	\end{center}
\end{figure}
%

หากต้องการกำหนดค่าเริ่มต้นนี้เป็นอื่นก็สามารถทำได้ ดังตัอย่างคำสั่งเช่น
\begin{Verbatim}[fontsize=\small]
with torch.no_grad():        
    fc1.bias.data = 2*0.01*torch.rand(800) - 0.01
\end{Verbatim}
เปลี่ยนค่าไบอัสเป็น $b \sim \mathcal{U}(-0.01, 0.01)$
ซึ่งเมื่อตรวจสอบ จะเห็นภาพคล้ายตัวอย่างในรูป~\ref{fig: torch init bias} (ภาพ ข).
หมายเหตุ จุดสำคัญอยู่ที่ค่าสูงสุดต่ำสุด ไม่ใช่ความสูงต่ำของแผนภูมิแท่งแต่ละแท่ง (ที่โดยรวมแสดงการแจกแจงเอกรูป 
แต่จำนวนข้อมูลที่น้อย $800$ ค่า อาจทำให้เห็นความไม่สมดุลของแต่ละแท่งบ้าง).

การกำหนดค่าเริ่มต้นให้กับโครงข่ายประสาทเทียม
อาจทำได้ดังตัวอย่าง

\begin{lstlisting}[language=Python, , caption={[ตัวอย่างการกำหนดค่าเริ่มต้นให้โครงข่ายประสาทเทียม]ตัวอย่างการกำหนดค่าเริ่มต้นให้โครงข่ายประสาทเทียม}, 
label={code: torch init net}]
with torch.no_grad():        
    net.fc1.bias.data = torch.rand(net.fc1.bias.shape)
    net.fc2.bias.data = torch.rand(net.fc2.bias.shape)
\end{lstlisting}
เมื่อ \texttt{net} เป็นตัวแปรแทนโครงข่ายประสาทเทียม
ที่มีชั้นคำนวณ \texttt{fc1} และ \texttt{fc2}
และต้องการกำหนดค่าเริ่มต้นของไบอัสแต่ละค่า
ให้เป็นค่าสุ่มจากการแจกแจงเอกรูป $\mathcal{U}(0, 1)$.
การกำหนดค่าน้ำหนักก็สามารถทำได้ในลักษณะเดียวกัน.

อย่างไรก็ตาม เพื่อความสะดวก
สำหรับการกำหนดค่าเริ่มต้นชั้นคำนวณต่าง ๆ
ด้วยวิธีเดียวกัน
เมท็อด \texttt{apply} ของ \texttt{nn.Module}%
\footnote{%
\texttt{nn.Module} จะเป็นคลาสแม่ของคลาสโครงข่ายประสาทเทียมที่เราสร้างขึ้น
ดังนั้น ตัวแปรวัตถุของคลาสโครงข่ายประสาทเทียมที่เราสร้างขึ้น จึงสามารถใช้เมท็อดต่าง ๆ ของคลาส \texttt{nn.Module} ได้.
}
สามารถช่วยลดภาระ การโปรแกรมซ้ำซ้อนลงได้
ดังคำสั่ง
\begin{Verbatim}[fontsize=\small]
with torch.no_grad():        
    net.apply(initx)
\end{Verbatim}
เมื่อ \texttt{net} คือตัวแปรโครงข่ายประสาทเทียมที่ต้องการกำหนดค่าน้ำหนักเริ่มต้น
และ \verb|initx|
คือฟังก์ชันกำหนดค่าเริ่มต้นที่ต้องการใช้กับค่าน้ำหนัก (และไบอัส) ทุกชั้นคำนวณ.
รายการ~\ref{code: xavier init}
แสดงตัวอย่างโปรแกรมของฟังก์ชันที่ใช้กำหนดค่าน้ำหนักและไบอัส (วิธีเซเวียร์ ดูสมการ~\ref{eq: xavier initialization} ประกอบ).
เนื่องจาก เมท็อด \texttt{apply} จะรันฟังก์ชันกับทุก ๆ มอดูลย่อยของ \texttt{net} (ตัวอย่างข้างต้น คือ \texttt{fc1} และ \texttt{fc2}) และตัวของ \texttt{net} เอง 
ดังนั้น ในฟังก์ชันที่จะใช้กำหนดค่าเริ่มต้น 
จึงต้องทำการเลือกกรณี (ตรวจสอบ \texttt{type(m)})
เพื่อจะดำเนินการได้ถูกต้อง.
	
\begin{lstlisting}[language=Python, , caption={[ฟังก์ชันกำหนดค่าน้ำหนักเริ่มต้นเซเวียร์]ฟังก์ชันกำหนดค่าน้ำหนักเริ่มต้นเซเวียร์
}, 
label={code: xavier init}]
def initx(m): # xavier initialization
    if type(m) == nn.Linear:        
        no, ni = m.weight.data.size()
        s = torch.sqrt(torch.Tensor([6/(ni + no)]))
        m.weight.data = 2*s*torch.rand(no, ni) - s
        m.bias.data = 0.1*torch.randn(m.bias.data.size())        
\end{lstlisting}

\begin{Exercise}
	\label{ex: deep init}

จากตัวอย่างวิธีกำหนดค่าเริ่มต้น
จงเขียนโปรแกรมกำหนดค่าเริ่มต้นแบบไคมิง
แล้วศึกษางานของโกลโรต์และเบนจิโอ\cite{GlorotAISTATS2010}
จากนั้น 
เลือกชุดข้อมูล 
ออกแบบการทดลอง เพื่อศึกษาผลกระทบจากฟังก์ชันกระตุ้น
และวิธีการกำหนดค่าเริ่มต้น
แล้วนำเสนอสิ่งที่ได้เรียนรู้ อภิปราย และสรุปผล.

ตัวอย่างนำเสนอผลและอภิปราย.
รูป~\ref{fig: deep init motivation}
แสดงตัวอย่างผลที่คาดว่า
เป็นส่วนหนึ่งที่ทำให้โกลโรต์และเบนจิโอ\cite{GlorotAISTATS2010}
ตั้งสมมติฐานว่า 
หากความแปรปรวนของค่าน้ำหนัก
ที่ชั้นต่าง ๆ มีค่าใกล้เคียงกัน
จะช่วยให้การฝึกทำได้ง่ายขึ้น.
สังเกตว่า
ในกรณีที่การฝึกทำได้ดี
ความห่างระหว่างเปอร์เซ็นไทล์ที่ 25 และ 75 (สื่อถึงความแปรปรวน) ของชั้นคำนวณต่าง ๆ จะมีความห่างใกล้เคียงกัน 
แต่อาจจะมีการขยายไล่เป็นชั้น ๆ จากชั้นต้น ๆ ที่จะขยายก่อนและไล่ไปชั้นหลัง ๆ
ซึ่งต่างจากผลที่เห็น ในกรณีการฝึกล้มเหลว ที่ความแปรปรวนระหว่างชั้นคำนวณต่างกันอย่างชัดเจน นอกจากนั้น ก็ยังไม่เห็นการขยายของความแปรปรวน.


%ตัวอย่างการนำเสนอผลสรุปสุดท้าย
%แสดงในรูป~\ref{fig: deep init test acc}.
รูป~\ref{fig: deep init test acc}
แสดงตัวอย่างผลสรุปที่สำคัญ
ได้แก่
(1) ฟังก์ชันกระตุ้น \texttt{tanh} และ \texttt{relu} ทำงานดีกว่า \texttt{sigmoid} ไม่ว่าจะใช้โครงข่ายที่มีความลึกเท่าใด.
(2) ผลดีจากการกำหนดค่าเริ่มต้นด้วยวิธีเซเวียร์และไคมิง (สัญกรณ์ย่อ \texttt{x} และ \texttt{k} ในภาพ)
จะเห็นชัดเจนขึ้น เมื่อใช้งานกับโครงข่ายที่ลึกขึ้น.
(3)
ทั้งวิธีเซเวียร์ และวิธีไคมิน
ให้ผล ดังที่คาดหมาย
นั่นคือ
วิธีเซเวียร์ ช่วยในกรณี \texttt{tanh} เมื่อเปรียบเทียบกับวิธีพื้นฐาน (สมการ~\ref{eq: standard init} สัญกรณ์ย่อ \texttt{u} ในภาพ).
และวิธีไคมิน
ช่วยในกรณี
\texttt{relu}
เมื่อเปรียบเทียบกับทั้งวิธีเซเวียร์และวิธีพื้นฐาน.
สังเกตว่า ทั้งวิธีเซเวียร์และวิธีไคมินพัฒนา โดยอาศัยสมมติฐานเชิงเส้น
ที่แม้จะไม่ตรงกับสถานการณ์จริง
แต่ในทางปฏิบัติ
กลับพบว่า
ทั้งสองวิธีทำงานได้ดีอย่างชัดเจน.

นอกจาก ผลสรุปเรื่องวิธีการกำหนดค่าเริ่มต้น
อีกประเด็นหนึ่งที่โกลโรต์และเบนจิโอ\cite{GlorotAISTATS2010}ได้ศึกษา
ก็คือ 
การตรวจดูค่าโดยรวม
ของผลการกระตุ้นและค่าเกรเดียนต์ระหว่างฝึก (ดังเช่นที่แสดงในรูป~\ref{fig: deep init motivation})
และตรวจสอบการแจกแจงของผลการกระตุ้นภายหลังการฝึก (ดังเช่นรูป~\ref{fig: deep init z hist})
ที่ทั้งคู่คิดว่าน่าจะช่วยให้สามารถทำความเข้าใจพฤติกรรมการเปลี่ยนแปลงของโครงข่ายจากการฝึกได้ดีขึ้น.


รูป~\ref{fig: deep init z hist}
แสดงให้เห็นว่า
กรณีที่การฝึกทำได้ดี (โครงข่ายสองชั้นทุกแบบ,
โครงข่ายสี่ชั้น เมื่อใช้ \texttt{tanh} หรือ \texttt{relu},
โครงข่ายสิบสี่ชั้น เมื่อใช้ \texttt{tanh} และวิธีเซเวียร์
หรือเมื่อใช้ \texttt{relu} และวิธีไคมิง.
ดูรูป~\ref{fig: deep init test acc} ประกอบ)
หน่วยคำนวณส่วนใหญ่ (ในเกือบทุกกรณี ยกเว้น \texttt{tanh} และวิธีเซเวียร์)
อยู่ในระดับ\textit{อิ่มตัว} (saturation)
นั่นคือ 
ค่าผลการกระตุ้น $z = 0$ หรือ $z = 1$ สำหรับฟังก์ชันซิกมอยด์,
ค่าการกระตุ้น 
$z = -1$ หรือ $z = 1$ สำหรับฟังก์ชันไฮเปอร์บอลิกแทนเจนต์,
และค่าการกระตุ้น 
$z = 0$ สำหรับเรลู.

	
\end{Exercise}

\begin{figure}
	\begin{center}	
		\includegraphics[width=\columnwidth]{05Deep/init/motivation_equal_var.png}
		\\
		\includegraphics[width=4.8in]{05Deep/init/Legend_activation_perEpoch.png}
		%
		\includegraphics[width=1.8in]{05Deep/init/Legend_percentile_activation_perEpoch.png}
	\end{center}	\caption[ผลการกระตุ้นระหว่างการฝึก]{ค่าผลการกระตุ้นระหว่างการฝึก (แสดงด้วยค่าเปอร์เซ็นไทล์ที่ 25, 50, และ 75) เมื่อใช้ฟังก์ชันซิกมอยด์ (ภาพในแถวบน) และไฮเปอร์บอลิกแทนเจนต์ (ภาพในแถวถัดมา) โดยมีโครงข่ายมีความลึก $2$ ชั้น (ภาพซ้าย ระบุเหนือภาพด้วย \texttt{D2}), $4$ ชั้น (ภาพกลาง ระบุด้วย \texttt{D4}), และ $14$ ชั้น (ภาพขวา ระบุด้วย \texttt{D14}).
		ภาพในแถวล่าง แสดงสี สำหรับค่าผลการกระตุ้นที่ชั้นคำนวณต่างๆ 
		และสัญลักษณ์ที่ระบุค่าเปอร์เซ็นไทล์.
		ในหกแบบจำลองนี้ 
		มีสามแบบจำลองที่การฝึกทำได้สำเร็จดี ได้แก่
		แบบจำลองสองชั้นที่ใช้ซิกมอยด์ (ภาพซ้ายบน)
		แบบจำลองสองและสี่ชั้นที่ใช้ไฮเปอร์บอลิกแทนเจนต์
		(ภาพซ้ายและกลาง แถวที่สอง).
	}			
	\label{fig: deep init motivation}
\end{figure}
%


\begin{figure}
	\begin{center}	
		\begin{tabular}{c}
			\includegraphics[width=4.5in]{05Deep/init/init_depth2mnist.png}
			\\
			\includegraphics[width=4.5in]{05Deep/init/init_depth4mnist.png}
			\\
			\includegraphics[width=4.5in]{05Deep/init/init_depth14mnist.png}
		\end{tabular}
	\end{center}		\caption[ผลเปรียบเทียบฟังก์ชันกระตุ้นและวิธีกำหนดค่าเริ่มต้น]{ค่าความแม่นยำกับข้อมูลทดสอบ เมื่อใช้โครงข่ายความลึก $2$ ชั้น (ภาพบนสุด) $4$ ชั้น (ภาพกลาง) และ $14$ ชั้น (ภาพล่าง) ประกอบกับฟังก์ชันกระตุ้นในชั้นซ่อนแบบต่างๆ (\texttt{sigmoid} ซิกมอยด์, 
		\texttt{tanh} ไฮเปอร์บอลิกแทนเจนต์,
		และ
		\texttt{relu} เรลู
		) และวิธีกำหนดค่าเริ่มต้นแบบต่าง ๆ (\texttt{u} วิธีพื้นฐาน สมการ~\ref{eq: standard init},
		\texttt{x} วิธีเซเวียร์ สมการ~\ref{eq: xavier initialization},
		และ
		\texttt{k} วิธีไคมิง สมการ~\ref{eq: kaiming init}).
		ค่าความแม่นยำที่แสดง
		เป็นค่าเฉลี่ยจากการทำซ้ำสิบครั้ง.}			
	\label{fig: deep init test acc}
\end{figure}
%

\begin{figure}
	\begin{center}	
		\includegraphics[width=0.8\textwidth]{05Deep/init/testz_histogram.png}
	\end{center}		
	\caption[การแจกแจงของค่าการกระตุ้น]{แต่ละภาพ แสดงการแจกแจงของค่าการกระตุ้น สำหรับแต่ละกรณี (ความลึก ฟังก์ชันกระตุ้นที่ใช้ และวิธีกำหนดค่าเริ่มต้น ระบุเหนือแต่ละภาพ ด้วยรหัสเช่นเดียวกับรูป~\ref{fig: deep init motivation}~ และ~\ref{fig: deep init test acc}). แกนนอน แสดงค่าผลการกระตุ้น และแกนตั้ง แสดงค่าความถี่หารด้วยจำนวนทั้งหมด.}
	\label{fig: deep init z hist}
\end{figure}
%


หมายเหตุ การฝึกเขียนโปรแกรมเอง (เช่น รายการ~\ref{code: xavier init}) จะช่วยให้เข้าใจกลไกภายในได้ดี
แต่การใช้งานในทางปฏิบัติ
การใช้ฟังก์ชันสำเร็จรูป จะช่วยเพิ่มความสะดวกในการทำงานและการสื่อสารได้ดีขึ้น 
(โดยเฉพาะในกรณีทำงานด้วยกันหลายคน).
ไพทอร์ชมีฟังก์ชันสำเร็จรูป
สำหรับการกำหนดค่าเริ่มต้นด้วยวิธีที่รู้จักดีต่างๆ รวมถึงวิธีเซเวียร์และไคมิง เช่น
\verb|nn.init.xavier_uniform_(w)|
สำหรับการกำหนดค่าน้ำหนักเริ่มต้นให้กับพารามิเตอร์ \texttt{w} ด้วยวิธีเซเวียร์.




%%
%\begin{figure}
%	\begin{center}
%		\includegraphics[width=7in]{05Deep/deepActDemo01aActFns.png}
%		\caption[ฟังก์ชันกระตุ้นและเกรเดียนต์]{ฟังก์ชันกระตุ้นแบบต่าง ๆ และเกรเดียนต์
%		}
%		\label{fig: deep activation functions}
%	\end{center}
%\end{figure}
%%
%
%ทดสอบเบื้องต้น %See deepActDemo01a.py to deepActDemo01e.py
%No. of W =	2853
%\begin{tabular}{|c|c|c|c|c|c|}
%	\hline 
%	& ReLu &	SoftPlus &	LeakyReLu &	LinSigm	&	LogSigm \\
%	\hline 
%	Time &	60.12 &	112.15 &		72.72 &		91.98 &		112.74 \\
%	\hline 
%	Loss &	3.89 &	4.18 &		3.90 &		13.91 &		4.53 \\
%	\hline 
%	
%	Acc	&	0.99 &	0.99 &		0.99 &		0.99 &		0.99 \\
%	\hline 
%\end{tabular} 
%
%... end new content ...
%
%... itanha
%... ikaha

\begin{Exercise}
\label{ex: deep optim}

จงเลือกขั้นตอนวิธีการฝึก จากวิธีลงเกรเดียนต์กับกลไกโมเมนตัม,
วิธีอาร์เมเอสพรอป,
วิธีอาร์เมเอสพรอป กับกลไกโมเมนตัม,
วิธีอดัม หรือวิธีอื่น ๆ ที่สนใจ
แล้วเขียนโปรแกรมวิธีดังกล่าว
เปรียบเทียบผลการทำงานกับโปรแกรมสำเร็จของวิธีนั้น
(ได้แก่ \texttt{optim.SGD},
\texttt{optim.RMSprop}, และ \texttt{optim.Adam})
และเปรียบเทียบกับวิธีลงเกรเดียนต์
เลือกชุดข้อมูลขึ้นมาเพื่อทดสอบ
ออกแบบการทดลอง เพื่อวัดผลทั้งในเชิงความเร็วและคุณภาพในการเรียนรู้ รวมถึงความทนทานต่อค่าอภิมานพารามิเตอร์ต่างๆที่เลือกใช้
และความทนทานกับการกำหนดค่าเริ่มต้นแบบต่างๆ
อภิปราย และสรุป.
	
\end{Exercise}


\begin{Exercise}
	\label{ex: deep batch norm}

จงออกแบบการทดลอง 
เพื่อทดสอบการทำงานของแบชนอร์ม
วัดผลทั้งในความเร็วในการฝึก
คุณภาพการฝึก
ความทนทานต่อค่าอัตราการเรียนรู้
ผลจากขนาดของหมู่เล็ก
รวมถึงตำแหน่งที่ทำแบชนอร์ม (ทำที่ตัวกระตุ้น นั่นคือก่อนฟังก์ชันกระตุ้น เปรียบเทียบกับทำที่ผลการกระตุ้น นั่นคือหลังฟังก์ชันกระตุ้น)
ทดลองเขียนโปรแกรมแบชนอร์ม (ตัวอย่างแสดงในรายการ~\ref{code: class MyBN})
และเปรียบเทียบกับโปรแกรมแบชนอร์มสำเร็จรูป (เช่น
คำสั่ง \verb|self.bn1 = nn.BatchNorm1d(8)|
เปรียบเทียบกับ
\verb|self.bn1 = MyBN(8)| 
ในรายการ~\ref{code: ann batch norm}
เมื่อ \verb|MyBN| กำหนดดังแสดงในรายการ~\ref{code: class MyBN}).
สังเกตผล อภิปราย และสรุป.

\begin{lstlisting}[language=Python, , caption={[ตัวอย่างโปรแกรมโครงข่ายประสาทเทียมที่ใช้แบชนอร์ม]ตัวอย่างโปรแกรมโครงข่ายประสาทเทียมที่ใช้แบชนอร์ม.
แบชนอร์มเหมือนชั้นคำนวณที่เพิ่มขึ้น.
คลาส \texttt{MyBN} เป็นชั้นคำนวณแบชนอร์ม กำหนดดังแสดงในรายการ~\ref{code: class MyBN}.
หมายเหตุ การใช้แบชนอร์ม ทำให้ไบอัสเกินความจำเป็นและซ้ำซ้อน
และสามารถตัดออกได้.
แต่ในตัวอย่างนี้ไม่ได้ตัดค่าไบอัสออก.
หากต้องการตัดไบอัสออก สามารถทำได้โดยคำสั่ง เช่น \texttt{self.fc1 = nn.Linear(1, 8, bias=False)}
}, label={code: ann batch norm}]
class MyNetManualBN(nn.Module):
    def __init__(self):
        super(MyNetManualBN, self).__init__()        
        self.fc1 = nn.Linear(1, 8)
        self.bn1 = MyBN(8)
        self.fc2 = nn.Linear(8, 8)
        self.bn2 = MyBN(8)
        self.fc3 = nn.Linear(8, 1)

    def forward(self, x):
        self.a1 = self.fc1(x)
        self.b1 = self.bn1(self.a1)
        self.z1 = torch.relu(self.b1)
        self.a2 = self.fc2(self.z1)
        self.b2 = self.bn2(self.a2)
        self.z2 = torch.relu(self.b2)
        self.z3 = self.fc3(self.z2)
        return self.z3
\end{lstlisting}

\lstinputlisting[language=Python, caption={[คลาสแบชนอร์ม]
โปรแกรมแบชนอร์ม.
การใช้ \texttt{nn.Parameter}
ช่วยให้เมท็อด \texttt{parameters()} ของแบบจำลอง
รู้จักพารามิเตอร์ที่กำหนดขึ้น (และการปรับค่าพารามิเตอร์ตามเกรเดียนต์ก็จะถูกทำโดยอัตโนมัติ เช่นเดียวกับค่าน้ำหนักและไบอัส).
การใช้ \texttt{register\_buffer}
ลงทะเบียนตัวแปร
เพื่อให้ตัวแปรที่ลงทะเบียน ถูกรวมเข้าไป
เมื่อทำการกำหนดอุปกรณ์ (เช่น \texttt{net.to(device)}) 
หรือการบันทึกแบบจำลอง (เช่น 
\texttt{torch.save(net.state\_dict(), 'savnet.pth')})
แต่ไม่ถูกรวมเข้าไปในกลุ่มพารามิเตอร์ของแบบจำลอง(และไม่ถูกปรับค่าอัตโนมัติจากเกรเดียนต์).
}, label={code: class MyBN}]{05Deep/code/MyBN.py}
\index{english}{batch norm!code}
\index{thai}{แบชนอร์ม!โปรแกรม}



รูป~\ref{fig: deep ex batchnorm effective},
~\ref{fig: deep ex batchnorm on A vs Z},
~\ref{fig: deep ex batchnorm diff LRs},
และ~\ref{fig: deep ex batchnorm diff batch sizes}
แสดงตัวอย่างการนำเสนอผล.
รูป~\ref{fig: deep ex batchnorm effective}
แสดงค่าสูญเสียระหว่างการฝึก จากการทดสอบสิบซ้ำ
ภาพซ้าย เมื่อไม่ได้ใช้แบชนอร์ม
และภาพขวา เมื่อใช้แบชนอร์ม.
เห็นได้ชัดเจนว่า
แบชนอร์มช่วยให้การฝึกทำได้เร็วขึ้นและแน่นอนขึ้น.

รูป~\ref{fig: deep ex batchnorm on A vs Z}
แสดงค่าทดสอบ ซึ่งในที่นี้ใช้ค่าเฉลี่ยกำลังสองน้อยที่สุด.
ภาพแสดงด้วยแผนภูมิกล่อง
กล่องซ้ายสุด
แสดงค่าผิดพลาด
เมื่อไม่ใช้แบชนอร์ม.
กล่องกลาง
เมื่อใช้แบชนอร์ม (ทำที่ตัวกระตุ้น นั่นคือ ใช้ ทำที่ $\bm{A}$ เมื่อ
ชั้นคำนวณ ทำ $h(\bm{A})$
โดย $\bm{A} = \bm{W} \cdot \bm{Z} + \bm{b}$
หรือ ทำก่อนเข้าฟังก์ชันกระตุ้น).
กล่องขวา
เมื่อใช้แบชนอร์ม แต่ทำแบชนอร์มที่ผลการกระตุ้น
แทนที่จะทำที่ตัวกระตุ้น
(นั่นคือ ทำที่ $\bm{Z}$
หรือทำหลังฟังก์ชันกระตุ้น).
รูป~\ref{fig: deep ex batchnorm on A vs Z}
แสดงในเห็นว่า
ไม่เพียงแต่ แบชนอร์มช่วยให้การฝึกดำเนินการได้เร็วขึ้น
แบชนอร์มยังช่วยคุณภาพการฝึกด้วย
และเพื่อให้ได้ประสิทธิภาพที่ดี
การทำแบชนอร์มควรทำที่ค่าตัวกระตุ้น (ค่าก่อนเข้าฟังก์ชันกระตุ้น).



\begin{figure}[H]
	\begin{center}	
%\begin{tabular}{cc}
		\includegraphics[height=1.4in]{05Deep/batchnorm/TrainLosses200.png}
%		&
%\includegraphics[height=1.1in]{05Deep/batchnorm/TestMSE.png}
%\\
%ก & ข
%\end{tabular} 				
	\end{center}		
\caption[ค่าฟังก์ชันสูญเสียต่อสมัยฝึก เมื่อไม่ใช้และใช้แบชนอร์ม]{ค่าฟังก์ชันสูญเสียต่อสมัยฝึก จากการทดสอบซ้ำ 10 ครั้ง เมื่อไม่ใช้แบชนอร์ม (ภาพซ้าย) และใช้แบชนอร์ม (ภาพขวา).}
	\label{fig: deep ex batchnorm effective}
\end{figure}
%


\begin{figure}[H]
	\begin{center}	
%		\begin{tabular}{cc}
%			\includegraphics[height=1.1in]{05Deep/batchnorm/TrainLosses_onZvsA.png}
%			\includegraphics[height=1.4in]{05Deep/batchnorm/TestMSE.png}
%			&
			\includegraphics[height=1.4in]{05Deep/batchnorm/TestMSE_onZvsA.png}
%			\\
%			ก & ข
%		\end{tabular} 		
%		
	\end{center}		
\caption[ค่าผิดพลาดเมื่อไม่ใช้และใช้แบชนอร์ม]{แผนภูมิกล่อง แสดงค่าเฉลี่ยค่าผิดพลาดกำลังสอง จากการทดสอบ 10 ครั้ง
เมื่อไม่ใช้แบชนอร์ม (กล่องซ้าย), 	
เมื่อใช้\atom{แบชนอร์ม} (กล่องกลาง)
และเมื่อใช้แบชนอร์ม แต่ทำแบชนอร์มที่ผลการกระตุ้น (กล่องขวา).}
	\label{fig: deep ex batchnorm on A vs Z}
\end{figure}
%

\begin{figure}[H]
	\begin{center}	
	\includegraphics[height=2.4in]{05Deep/batchnorm/TestMSE_differentLRs_batchnorm4.png}
	\end{center}		
\caption[ค่าผิดพลาดเมื่อไม่ใช้และใช้แบชนอร์ม
กับอัตราเรียนรู้ต่าง ๆ]{
แผนภูมิกล่องแสดงค่าเฉลี่ยค่าผิดพลาดกำลังสอง จากการทดสอบ 10 ครั้ง เมื่อไม่ใช้แบชนอร์ม
และเมื่อใช้แบชนอร์ม 
กับอัตราเรียนรู้ต่าง ๆ.
ตัวเลขที่แสดง หมายถึง ค่าอัตราเรียนรู้ที่ใช้
และอักษร \texttt{B} ที่กำกับหมายถึง มีการใช้แบชนอร์ม.}
	\label{fig: deep ex batchnorm diff LRs}
\end{figure}
%

\begin{figure}[H]
	\begin{center}	
		\includegraphics[width=\textwidth]{05Deep/batchnorm/TestMSE_trainLOSS_batchsizes_Legend.png}
	\end{center}		
\caption[ค่าเฉลี่ยค่าผิดพลาด ระหว่างการฝึก เมื่อใช้และไม่ใช้แบชนอร์ม ที่ขนาดหมู่เล็กต่าง ๆ]{
ค่าเฉลี่ยค่าผิดพลาด ระหว่างการฝึก เมื่อใช้และไม่ใช้แบชนอร์ม ที่ขนาดหมู่เล็กต่าง ๆ (ภาพต่าง ๆ ในแถวบน).
ค่าเฉลี่ยค่าฟังก์ชันสูญเสีย ระหว่างการฝึก เมื่อใช้และไม่ใช้แบชนอร์ม ที่ขนาดหมู่เล็กต่าง ๆ (ภาพต่าง ๆ ในแถวล่าง).	
	.}
	\label{fig: deep ex batchnorm diff batch sizes}
\end{figure}
%

\begin{figure}[H]
	\begin{center}	
		\includegraphics[width=\textwidth]{05Deep/batchnorm/FinalTestMSE_Batchsizes.png}
	\end{center}		
	\caption[แบชนอร์มและขนาดของหมู่เล็ก]{
		แผนภาพกล่อง แสดงค่าผิดพลาด จากการทดสอบ 10 ครั้ง เมื่อใช้และไม่ใช้แบชนอร์ม
		กับขนาดหมู่เล็กต่าง ๆ.}
	\label{fig: deep ex batchnorm diff batch sizes final test MSE}
\end{figure}
%

\begin{figure}[H]
	\begin{center}	
		\includegraphics[width=\textwidth]{05Deep/batchnorm/FinalTestMSE_Batchsizes2.png}
	\end{center}		
	\caption[แบชนอร์มเปลี่ยนความสัมพันธ์ของการฝึกและขนาดหมู่เล็ก]{แผนภาพกล่อง แสดงค่าผิดพลาด จากการทดสอบ 10 ครั้ง เมื่อใช้ขนาดหมู่เล็กต่าง ๆ ในกรณีที่ใช้และไม่ใช้แบชนอร์ม.
	เปรียบเทียบกับรูป~\ref{fig: deep ex batchnorm diff batch sizes final test MSE} รูปนี้นำเสนอจากอีกมุมมองหนึ่ง นั่นคือ การเลือกใช้หรือไม่ใช้แบชนอร์ม ควรพิจารณาประกอบกับขนาดของหมู่เล็กที่จะเลือกใช้ด้วย.}
	\label{fig: deep ex batchnorm Batchsize}
\end{figure}
%

\begin{figure}[H]
	\begin{center}	
		\includegraphics[width=\textwidth]{05Deep/batchnorm/batchnorm_extcovshift.png}
	\end{center}		
	\caption[คุณภาพของแบชนอร์มกับการเลื่อนของความแปรปรวนร่วมเกี่ยวภายนอก]{
ภาพซ้าย แสดงการทำงานของแบชนอร์มกับการเลื่อนของความแปรปรวนร่วมเกี่ยวภายนอก.		อัตราการปรับปรุงคุณภาพการทำนายเมื่อใช้แบชนอร์มเทียบกับไม่ใช้ แสดงด้วยเส้นประสีแดง โดย 
ค่าเป็นบวกหมายถึงคุณภาพดีขึ้นเมื่อใช้แบชนอร์ม
ศูนย์หมายถึงคุณภาพเท่ากัน 
และค่าเป็นลบหมายถึงคุณภาพแย่ลง.
เส้นทึบสีน้ำเงิน แสดงค่ามากที่สุดของความต่างระหว่างค่าเฉลี่ยของหมู่กับ
ค่าเฉลี่ยของข้อมูลทั้งหมด (ความต่างคิดเป็นค่าสัมบูรณ์).
ภาพขวา แสดงค่ามากที่สุดของความต่าง (แกนนอน)
กับเปอร์เซ็นต์การปรับปรุงคุณภาพเมื่อใช้แบชนอร์ม (แกนตั้ง).
}
	\label{fig: deep ex batchnorm external covariance shift}
\end{figure}
%




รูป~\ref{fig: deep ex batchnorm diff LRs}
แสดงให้เห็นว่า แบชนอร์มทำงานได้ดีที่ค่าอัตราเรียนรู้ต่าง ๆ.
รูป~\ref{fig: deep ex batchnorm diff batch sizes}
แสดง การทำงานของแบชนอร์ม
ในสถานการณ์ของขนาดหมู่เล็กต่าง ๆ ในช่วงสมัยฝึกต่าง ๆ.
สังเกตว่า
%(1) เมื่อใช้หมู่เล็กขนาดใหญ่ (ภาพซ้ายสุดบนและล่าง)
%แบชนอร์มต้องการจำนวนสมัยฝึกที่มากขึ้น
เมื่อใช้หมู่เล็กขนาดเล็กเกินไป
(ภาพขวาสุด บนและล่าง)
แบชนอร์มทำงานได้ไม่ดี และนำไปสู่การฝึกที่แย่กว่าการฝึกที่ไม่ใช้แบชนอร์ม.
รูป~\ref{fig: deep ex batchnorm diff batch sizes final test MSE}
แสดงค่าความผิดพลาดเมื่อนำแบบจำลองที่ฝึกไปทดสอบ.
รูป~\ref{fig: deep ex batchnorm diff batch sizes final test MSE}
ยืนยันว่า
หากใช้แบชนอร์ม
แล้วเลือกขนาดหมู่เล็กที่เล็กเกินไป
จะทำให้ผลการฝึกแย่ลงได้.

แบชนอร์ม ออกแบบมาเพื่อแก้ไข\textit{การเลื่อนของความแปรปรวนร่วมเกี่ยวภายใน} ที่เกิดจากการปรับค่าพารามิเตอร์ระหว่างการฝึก
แต่การทำแบชนอร์ม
ที่ปรับค่าเฉลี่ยและความแปรปรวนของหมู่เล็ก ก็เสี่ยงที่จะทำสารสนเทศจากข้อมูลเสียหาย.
หากความต่างของค่าเฉลี่ยและความแปรปรวนระหว่างหมู่
มาจากตัวข้อมูลเอง ไม่ใช่มาจากการเปลี่ยนแปลงของค่าพารามิเตอร์ในชั้นคำนวณก่อนหน้า.

หากการแจกแจงสารสนเทศของข้อมูลในหมู่เล็กแต่ละหมู่
ค่อนข้างคงเส้นคงวา และสามารถแทนการแจกแจงสารสนเทศของข้อมูลโดยรวมได้
การเลื่อนของค่าเฉลี่ยและความแปรปรวนระหว่างหมู่
มาจากการเปลี่ยนแปลงของค่าพารามิเตอร์ของชั้นคำนวณก่อนหน้า
การทำแบชนอร์มจะมีประสิทธิผลตามที่ออกแบบไว้.

แต่หากการเลื่อนของค่าเฉลี่ยและความแปรปรวนระหว่างหมู่
มาจากสารสนเทศที่ต่างกันของข้อมูลระหว่างหมู่เอง
ความเสี่ยงของการทำ\atom{แบชนอร์ม} จะสูงขึ้นมาก
และเมื่อประกอบกับแนวทางปฏิบัติของการสุ่มหมู่เล็ก
ที่มักทำการสุ่มแค่ครั้งแรก และใช้ลำดับและการจัดกลุ่มนั้นตลอด
ยิ่งจะซ้ำเติมความเสี่ยงนี้เข้าไปอีก.

ตัวอย่างของกรณีที่ใช้ขนาดหมู่เล็กเป็นสิบ
ภาพขวาสุดที่แสดงในรูป~\ref{fig: deep ex batchnorm diff batch sizes final test MSE}
แสดงให้เห็นว่า เมื่อขนาดหมู่เล็กลง โอกาสที่การแจกแจงสารสนเทศของข้อมูลระหว่างหมู่จะะสม่ำเสมอหรือจะเป็นตัวแทนของข้อมูลทั้งหมดได้ จะน้อยลง
และเมื่อการแจกแจงสารสนเทศของข้อมูลระหว่างหมู่ไม่สม่ำเสมอ การทำแบชนอร์มจึงทำสารสนเทศบางอย่างเสียหายไป
และส่งผลให้การฝึกทำได้แย่.
รูป~\ref{fig: deep ex batchnorm Batchsize}
เปรียบเทียบให้เห็นว่า
ความสัมพันธ์ระหว่างคุณภาพการฝึกกับขนาดของหมู่เล็ก
เปลี่ยนไป เมื่อใช้แบชนอร์ม.
ในทางปฏิบัติ หลายครั้ง 
ขนาดของหมู่เล็ก อาจถูกจำกัดจากหน่วยความจำ
และการเลือกใช้หรือไม่ใช้แบชนอร์ม 
ควรคำนึงถึงความเสี่ยง
จากประเด็นความสม่ำเสมอระหว่างหมู่เล็ก
ของการแจกแจงสารสนเทศจากตัวข้อมูลเองประกอบ.

รูป~\ref{fig: deep ex batchnorm external covariance shift}
แสดงประเด็นความสัมพันธ์ระหว่างประสิทธิผลการทำงานของแบชนอร์มกับการแจกแจงข้อมูลระหว่างหมู่เล็ก.
จากรูป
เมื่อ
การแจกแจงข้อมูลระหว่างหมู่เล็ก
ทำให้เกิดความต่างระหว่างหมู่เล็กมาก 
ประสิทธิผลการทำงานของแบชนอร์มจะต่ำลง
และอาจต่ำจนการใช้แบชนอร์มจะเป็นผลเสียมากกว่าผลดี
ดังแสดงออกมาเป็นเปอร์เซ็นต์ปรับปรุงที่ติดลบ.

แล้วกรณีที่ข้อมูลมีรูปแบบแปลก ๆ ที่พบได้ยาก
หรือกรณีประเด็นเรื่องวิธีประมาณค่า $\mu_i$ และ $\sigma_i^2$ ที่ใช้ทำแบชนอร์มภายหลังการฝึก
อาจก่อให้เกิดความเสี่ยงอย่างไรบ้าง
จงระดมความคิิด อภิปราย และสรุป. 

\end{Exercise}

\begin{Exercise}
	\label{ex: prep reading}

\textbf{การศึกษาหัวข้อที่สนใจ.}%
\footnote{%
ดัดแปลงจาก \cite{Alake2020}.
%How You Should Read Research Papers According To Andrew Ng
%โดย Richmond Alake.\\
%\url{https://towardsdatascience.com}
%2 ก.ค. 2020.
}
บางครั้งในบางจังหวะเวลา
ศาสตร์ที่เราศึกษา
มีการเปลี่ยนแปลงพัฒนาที่รวดเร็วมาก
และอาจจำเป็นต้องศึกษาความก้าวหน้าและพัฒนาการล่าสุดจากแหล่งอื่น ๆ เพิ่มเติม.

จงเลือกหัวข้อเรื่องที่สนใจ
(เช่น 
การบรรยายภาพอัตโนมัติ,
การแต่งเพลงอัตโนมัติ,
การทำนายพฤติกรรมโปรตีน)
แล้วศึกษา ทำความเข้าใจในหัวเรื่องดังกล่าว.

การศึกษา ทำความเข้าใจ
อาจทำโดย
(1) ค้นหาและรวบรวมแหล่งข้อมูล
เกี่ยวกับหัวข้อที่สนใจ
ซึ่งแหล่งข้อมูลอาจรวมถึง
หนังสือ บทความวิชาการ
บทความทั่วไป วีดีโอ เว็บเพจ เป็นต้น.

(2) ศึกษาแต่ละแหล่งข้อมูลที่ได้มาคร่าว ๆ
(ถ้าเป็นบทความวิชาการ รวมถึงบทความวิจัย อย่างน้อย อ่านบทคัดย่อและบทนำ) 
และอาจจะทำบันทึกย่อ 
ว่า
แต่ละแหล่งข้อมูลเกี่ยวข้องกับหัวข้อที่สนใจมากน้อยขนาดไหน
และเราเข้าใจเนื้อหาเข้าใจมากน้อยขนาดไหน
รวมถึงอาจจัดลำดับความสำคัญ
และหมายเหตุถึงสิ่งที่คิดว่าจะดำเนินการต่อ
เช่น
ไม่ค่อยเกี่ยวข้อง ตัดทิ้งไปก่อน 
หรือ เกี่ยวข้องมาก ศึกษาให้เข้าใจ
หรือ เกี่ยวข้องประมาณ $50\%$ พอเข้าใจแล้ว
เก็บไว้เป็นตัวอย่าง
หรือ ไม่แน่ใจว่าเกี่ยวข้อง เข้าใจดี
ชอบเทคนิคที่เขาใช้ อาจใช้เป็นประโยชน์กับงานของเราได้ เก็บไว้อ้างอิงทีหลัง.
หรือ ไม่แน่ใจว่าเกี่ยวข้อง ไม่ค่อยเข้าใจ
เก็บไว้ดูอีกทีหลังจากเข้าใจหัวข้อนี้ดีขึ้น.

โดยทั่วไป ถ้าเป็นบทความวิชาการหรือบทความวิจัย ที่ไม่ใช่\textit{บทความทบทวน} หรือไม่ใช่\textit{บทความสำรวจ}
เราอาจจะต้องอ่านตั้งแต่สามจนถึงสิบบทความ จึงอาจจะพอเข้าใจหัวข้อนั้นในระดับเบื้องต้นได้.
นักศึกษาปริญญาเอก ซึ่งถูกคาดหวังว่าจะเข้าใจในหัวข้อเป็นอย่างดี
อาจต้องอ่านบทความ ไม่น้อยกว่า $100$ บทความ.
และก็ไม่แปลกที่จะเห็น
\textit{บทความทบทวน} หรือ\textit{บทความสำรวจ}ของหัวข้อใด ๆ 
ที่คณะผู้เขียนอาจต้องอ่านบทความต่าง ๆ ที่เกี่ยวข้องกับหัวข้อนั้น ๆ มากกว่า $300$ บทความ.


(3) หากไม่สามารถเข้าใจบทความวิชาการส่วนใหญ่ได้
ให้ระบุศาสตร์พื้นฐานที่อาจจะขาดไป
เช่น
บทความที่หนึ่ง เกี่ยวข้องมาก แต่ไม่เข้าใจเลย ดูเหมือนจะใช้ทฤษฎีความน่าจะเป็นและ\textit{แคลคูลัสของการแปรผัน} (calculus of variations).
บทความที่สอง เกี่ยวข้อง แต่อ่านไม่เข้าใจ ใช้พีชคณิตเชิงเส้น, ความน่าจะเป็น และ\textit{ทฤษฎีสารสนเทศ}.
บทความที่ห้า เกี่ยวข้องมาก แต่ยังอ่านไม่เข้าใจ ใช้ทฤษฎีความน่าจะเป็น,
\textit{กระบวนการ\atom{สโทแคสติก}} และ\textit{การหาค่าดีที่สุด}.
บทความที่แปด เกี่ยวข้องบ้าง แต่อ่านไม่เข้าใจ เพราะประยุกต์ใช้กับงานชีวการแพทย์
ใช้\textit{การหาค่าดีที่สุด}
และชีวเคมี.
เช่นนี้ ก็จะช่วยให้เราพอเห็นว่า
เราขาดพื้นฐานอะไรไปบ้าง
และเราสามารถจัดลำดับความสำคัญ
และเลือกที่จะศึกษาพื้นฐานเหล่านี้ก่อน.
หมายเหตุ เราไม่จำเป็นต้องสร้างพื้นฐานทุก ๆ อย่าง
เช่น เราอาจเลือกว่า สิ่งที่เราสนใจไม่ได้เกี่ยวข้องกับงานชีวการแพทย์
เราอาจจะไม่เลือกเรียนรู้พื้นฐานด้านชีวเคมี ก็ได้
หรือ 
เราคิดว่าทฤษฎี\textit{กระบวนการสโทแคสติก} มีใช้บ้างกับงานบางประเภท บางแนวทาง ซึ่งเราอาจจะยังไม่สนใจ
ก็สามารถทำได้.
แต่ระวังว่า
หากอ่านบทความวิชาการไม่รู้เรื่อง
และพบว่าพื้นฐานอะไรบ้างที่เราต้องการ
แต่เราไม่อยากเรียนรู้พื้นฐานเหล่านั้นเลย
(โดยเฉพาะพื้นฐานที่จำเป็น)
อาจเป็นสัญญาณเตือนว่า 
จริง ๆ แล้ว ใจเราอาจจะไม่อยากศึกษาหัวข้อที่เลือกจริง ๆ.

(4) จากแหล่งข้อมูลที่ได้ศึกษาเบื้องต้น
เลือกแหล่งที่เกี่ยวข้องมาก ๆ ออกมาศึกษาต่อ ให้ละเอียดขึ้น.
สำหรับบทความวิจัย
ให้ลองสรุปบทความ 
โดยระบุการค้นพบที่สำคัญ, วิธีที่ใช้,
และคุณค่าเมื่อมองจากภาพรวมใหญ่ของหัวข้อ รวมถึงความสัมพันธ์กับงานอื่น ๆ.
อาจอภิปรายประเด็นเพิ่มเติมด้วย 
เช่น ข้อจำกัด  หรือศักยภาพ
หรือการตีความจากมุมมองอื่น
หรืออาจจะเป็นความเห็นส่วนตัว
หรือสิ่งที่ชอบ ประเด็นที่ไม่ชอบ หากมี.


(5) ถ้าสามารถทำได้ หากลุ่มคนที่สนใจเรื่องเดียวกัน
และอภิปรายเรื่องที่เรียนรู้ต่าง ๆ ด้วยกัน (อาจเป็น\atom{กลุ่ม}ที่สามารถพบปะตัวต่อตัว หรือกลุ่มแบบออนไลน์ก็ได้).
เรื่องที่จะอภิปรายอาจจะเลือกอย่างอิสระตามความสนใจของกลุ่ม หรือหากไม่รู้จะเริ่มจากเรื่องใด
อาจลองพิจารณาจากคำถามเหล่านี้
เป้าหมายที่สำคัญของหัวข้อนี้คืออะไร?
หัวข้อนี้มีศักยภาพและประโยชน์ต่อสังคมในวงกว้างอย่างไร?
ความท้าทายที่สำคัญของหัวข้อนี้มีอะไรบ้าง?
แนวทางและวิธีการต่าง ๆ ที่ใช้เพื่อจัดการกับความท้าทาย มีอะไรบ้าง?
และแต่ละแนวทางมีข้อดีข้อเสียอะไร?
งานเด่น ๆ ในหัวข้อดีมีอะไรบ้าง ทำไมมันถึงเด่นกว่างานอื่น ๆ?
อะไรคือสิ่งที่คนในวงการนี้ สนใจและอยากได้มากที่สุด?
ทำไมถึงอยากได้?
ในความเห็นส่วนตัวแล้ว คิดว่า
นอกจากแนวทางหลัก ๆ แล้ว
มีแนวทางอื่นอีกไหม?
แนวทางไหนบ้างที่น่าสนใจ และทำไม?
เป็นต้น

คำแนะนำในการอ่านบทความวิจัย.
ก่อนอ่าน อาจจะถามตัวเองว่า
ต้องการอะไรบ้าง จากบทความที่กำลังจะอ่าน.
หากมีสิ่งที่ต้องการรู้เฉพาะจากบทความ
เช่น อยากรู้วิธีประเมินผล
เมื่ออ่านก็ให้ความสำคัญเป็นพิเศษกับวิธีประเมินผล และหลังอ่านเสร็จให้กลับมาตอบตัวเอง
ว่าได้รู้สิ่งที่ค้นหาว่าอย่างไร.

แต่หากเป็นการอ่านเพื่อความเข้าใจภาพโดยทั่วไป ไม่ได้มีประเด็นที่เจาะจงเป็นพิเศษ
อาจลองวิธีดังนี้
(1) อ่านผ่าน ๆ รอบแรก โดยอ่านชื่อเรื่อง บทคัดย่อ และรูปภาพ.
(2) อ่านบทนำ และบทสรุป
แล้วดูรูปภาพและเนื้อหาส่วนอื่น ๆ คร่าว ๆ.
(3) อ่านเนื้อหาต่าง ๆ ในบทความ
โดยอาจจะยังไม่ต้องสนใจรายละเอียด โดยเฉพาะนิพจน์หรือสมการคณิตศาสตร์มากนัก.
(4) ทำความเข้าใจส่วนต่าง ๆ รวมถึงพจน์ นิพจน์ และสมการคณิตศาสตร์ต่าง ๆ.
(5) ตั้งคำถามกับตัวเอง เช่น
บทความนี้พยายามศึกษาหรือแก้ปัญหาอะไรอยู่?
แนวทางหรือวิธีที่ใช้ มันมีอะไรเป็นปัจจัยสำคัญ?
เนื้อหาที่อ่านมีประโยชน์อะไรบ้างกับเรา?
มีอ้างอิงรายการไหนบ้างที่เราอยากจะตามศึกษาต่อ?
(6) หากสนใจบทความ
อาจจะลองอภิปรายเพิ่มเติม เช่น
ผลการศึกษาอาจมีข้อจำกัดอะไรบ้าง หรืออาจแสดงถึงศักยภาพอะไรบ้าง?
จุดน่าสนใจ ความคิดสร้างสรรค์ของงานนี้
มีที่ใดบ้าง?

หลังอ่านจบแล้ว อาจลองทบทวนดูว่า
มันช่วยตอบคำถามอะไรบ้างในภาพรวม
ยังมีอะไรบ้างที่เป็นสิ่งที่เราสงสัยอยู่?
สำหรับนักศึกษาปริญญาเอก
หากสิ่งที่เราสงสัย
เป็นสิ่งที่ในวงการก็ยังไม่รู้ (ศึกษาแหล่งข้อมูลให้มากพอ เพื่อแน่ใจว่า ในวงการยังไม่รู้)
และเป็นสิ่งที่หากรู้แล้วจะมีประโยชน์ 
สิ่งนั้นอาจเป็นตัวเลือกที่น่าสนใจสำหรับหัวข้อวิจัยได้ ถ้าเราพอที่จะช่วยคลายความสงสัยนั้นลงได้บ้าง (การเลือกหัวข้อวิจัยมีความเสี่ยงสูงมาก ควรปรึกษาอาจารย์ที่ปรึกษาก่อนตัดสินใจ).


\end{Exercise}

