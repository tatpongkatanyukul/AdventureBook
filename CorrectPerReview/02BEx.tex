\section{แบบฝึกหัด}

\subsection{แบบฝึกหัดเชิงทฤษฏี}

\begin{Parallel}[c]{0.55\textwidth}{0.36\textwidth}
	\selectlanguage{english}
	\ParallelLText{
		``As to methods there may be a million and then some, 
		but principles are few. The man who grasps principles can successfully select his own methods. The man who tries methods, ignoring principles, is sure to have trouble.''
		\begin{flushright}
		---Ralph~Waldo~Emerson
		\end{flushright}
	}
	\selectlanguage{thai}
	\ParallelRText{
		``วิธีการมีเป็นล้านและมากกว่า แต่หลักการมีไม่มาก
		บุคคลผู้ยึดในหลักการสามารถเลือกวิธีการได้อย่างดี
		บุคคลผู้ลองแต่วิธีการ ละเลยหลักการ ย่อมแน่นอนว่าจะมีปัญหา''
		\begin{flushright}
		---ราล์ฟ~วัลโด~อีเมอร์สัน
		\end{flushright}
	}
\end{Parallel}
\index{english}{words of wisdom!Ralph Waldo Emerson}
\index{english}{quote!principles}


\begin{Exercise}
	\label{ex: lin alg lin equation nxn repeat column}
	\index{english}{linear equations}
	\index{thai}{ระบบสมการเชิงเส้น}

จากระบบสมการ
\begin{eqnarray}
x + y + z &=& 6 
\label{eq: lin alg exercise singular 1} \\
2 x + 2 y + 3 z &=& 14
\label{eq: lin alg exercise singular 2} \\
x + y + 4z &=& 15
\label{eq: lin alg exercise singular 3}
\end{eqnarray}
จงวิเคราะห์และอภิปรายว่า
ระบบสมการนี้ สามารถหาคำตอบได้หรือไม่ 
หรือถ้าได้
คำตอบมีชุดเดียว
หรือคำตอบมีหลายชุด.
สังเกต
แต่ละแถว เป็นอิสระเชิงเส้นกัน
แต่สดมภ์หนึ่งและสอง (สัมประสิทธิ์ของ $x$ และ $y$)
ไม่เป็นอิสระเชิงเส้นกัน
จากมุมมองของสารสนเทศที่ได้รับ
ถ้าการไม่เป็นอิสระเชิงเส้นกันของแถว
หมายถึง สมการที่ได้ไม่ได้ให้สารสนเทศเพียงพอ
สมการหนึ่งได้มาจากการแปลงเชิงเส้นของสมการอื่น
แล้ว
การไม่เป็นอิสระเชิงเส้นกันของสดมภ์
จะหมายถึงอะไร อภิปราย

\end{Exercise}

\begin{Exercise}
	\label{ex: prob variance vs entropy}
	
	\textit{ความแปรปรวน} (variance) เป็นค่าประเมินการแจกแจงของข้อมูลจากค่าเฉลี่ย.
	\index{english}{variance}
	\index{thai}{ความแปรปรวน}
	ความแปรปรวน อาจถูกสับสนกับ\textit{เอนโทรปี}.
	\textbf{เอนโทรปีสารสนเทศ} (information entropy)
	หรือเรียกสั้น ๆ ว่า
	\textbf{เอนโทรปี} (entropy)
	\index{english}{entropy}
	\index{thai}{เอนโทรปี}
	เป็นการประมาณค่าคาดหมายของปริมาณสารสนเทศที่ได้รับ.
	กำหนดให้ตัวแปรสุ่ม $X$ แทนข้อความที่ได้รับ.
	ถ้าข้อความที่ได้รับ มีความน่าจะเป็นสูง หมายถึง ข้อมูลมีสารสนเทศน้อย.
	ถ้า $\mathrm{Pr}(X = x) = 1$ แปลว่า $x$ ไม่มีสารสนเทศอะไรอยู่เลย เป็นเรื่องที่รู้กันอยู่แล้ว.
	ถ้าข้อความที่ได้รับ มีความน่าจะเป็นต่ำ หมายถึง ข้อความมีสารสนเทศมาก เป็นเรื่องใหม่ เป็นเรื่องที่น่าแปลกใจ เป็นข่าวที่คิดไม่ถึง.
	ปริมาณสารสนเทศของแต่ละข้อความ ถูกนิยามเป็น $h(x) = -\log_2 \mathrm{Pr}(X = x)$ เมื่อ $x$ เป็นข้อความที่ได้รับ.
	\textit{ลอการิทึม} (logarithm) เป็น\textit{ฟังก์ชันทางเดียว} (monotonic function)
	และการทำลบ ช่วยให้ได้ความสัมพันธ์ที่
	$h(x)$ ค่าน้อย 
	เมื่อ $\mathrm{Pr}(X = x)$ ค่ามาก 
	และ
	$h(x)$ ค่ามาก 
	เมื่อ $\mathrm{Pr}(X = x)$ ค่าน้อย 
	นอกจากนั้น ยังช่วยให้ $h(x)$ 
	มีค่ามากกว่าหรือเท่ากับศูนย์ด้วย.
	ค่าเฉลี่ย หรือค่าคาดหมายของปริมาณสารสนเทศ
	\begin{eqnarray}
	H[X] = - \sum_x \mathrm{Pr}(X = x) \cdot \log_2 \mathrm{Pr}(X = x)
	\label{eq: Entropy}
	\end{eqnarray}
	จะเรียกว่า เอนโทรปีสารสนเทศ.
	
	จงคำนวณค่าความแปรปรวนและค่าเอนโทรปี
	ของข้อมูลต่อไปนี้.
	ข้อมูลชุดที่ 1 มีความน่าจะเป็นดังนี้
	\begin{eqnarray}
	\mathrm{Pr}(X = x) = 
	\left\{
	\begin{array}{l l}
	\frac{1}{4} 
	& \quad \mbox{เมื่อ } x = 0 \mbox{ หรือ } x = 1 \mbox{ หรือ } x = 2 \mbox{ หรือ } x = 3, \\
	0 
	& \quad \mbox{เมื่อ } x \mbox{ เป็นค่าอื่น ๆ}.
	\end{array} \right.
	\label{eq: ex prob var entropy dist 1}
	\end{eqnarray}
	
	และข้อมูลชุดที่ 2 มีความน่าจะเป็นดังนี้
	\begin{eqnarray}
	\mathrm{Pr}(X = x) = 
	\left\{
	\begin{array}{l l}
	\frac{1}{4} 
	& \quad \mbox{เมื่อ } x = 0 \mbox{ หรือ } x = 2 \mbox{ หรือ } x = 4 \mbox{ หรือ } x = 8, \\
	0 
	& \quad \mbox{เมื่อ } x \mbox{ เป็นค่าอื่น ๆ}.
	\end{array} \right.
	\label{eq: ex prob var entropy dist 2}
	\end{eqnarray}
	%	
	รูป~\ref{fig: prob var vs entropy}
	แสดง\textit{การแจกแจง}ของข้อมูลทั้งสองชุด.
	\textit{การแจกแจง} $F(x) = \mathrm{Pr}(X \leq x) = \sum_{v \leq x} \mathrm{Pr}(X = v)$.
	สังเกตผลลัพธ์ของค่าความแปรปรวนและค่าเอนโทรปีที่คำนวณได้.
	สรุปและอภิปรายค่าความแปรปรวน และค่าเอนโทรปีของข้อมูลสองชุดนี้
	พร้อมอภิปรายความต่างกันของค่าความแปรปรวน และค่าเอนโทรปี
	โดยทั่วไป
	และยกตัวอย่างลักษณะของข้อมูลที่ทำให้เห็นความต่างชัดเจนประกอบ.
	
	\begin{figure}[H]
		\begin{center}
			\begin{tabular}{cc}
				\includegraphics[width=0.5\columnwidth]{02Background/prob/var_entropy1}
				&
				\includegraphics[width=0.5\columnwidth]{02Background/prob/var_entropy2}
			\end{tabular}
			
		\end{center}
		\caption[ตัวอย่างแสดงความต่างของค่าแปรปรวนและเอนโทรปี]{ภาพ ก แสดงการแจกแจงของข้อมูลชุดที่ 1.
			ภาพ ข แสดงการแจกแจงของข้อมูลชุดที่ 2.}
		\label{fig: prob var vs entropy}
	\end{figure}
	
	\textit{คำใบ้}
	ถ้ากำหนด $X_1$ เป็นตัวแปรสุ่มของข้อมูลชุดที่ 1
	แล้ว\textit{ค่าคาดหมาย} 
	$E[X_1] = \sum_x x \cdot \mathrm{Pr}(X_1 = x) = 0 (1/4) + 1 (1/4) + 2 (1/4) + 3 (1/4) = 1.5$.
	%คำสั่ง \verb|np.log2| ช่วยคำนวณค่า\textit{ลอการิทึม}ฐานสอง.
\end{Exercise}

% LATER
%\begin{Exercise}
%	\label{ex: KL Divergence vs Loglikelihood}
% minimizing KL Divergence is equivalent to minimizing neg log likelihood (See Murphy)
% this gives MLE a nice interpretation: maximizing the likelihood of data under our estimate is equal to minimizing the difference between our estimate and the real data distribution. We can see MLE as a proxy for fitting our estimate to the real distribution, which cannot be done directly as the real distribution is unknown to us.
%
%KL Divergence หรือ Kullback Leibler Divergence: ค่าวัดว่าค่าการแจกแจงที่ทำนาย ต่างจากการแจกแจงอ้างอิงเท่าไร.
%ถ้ากำหนดให้ $f(X, \beta)$ เป็นค่า pdf หรือ pmf ที่ทำนายจากแบบจำลอง และ $g(X, \mu)$ เป็นค่า pdf หรือ pmf ของการแจกแจงอ้างอิง (หรือค่าที่วัดได้จากข้อมูล) แล้วค่า KL Divergence นิยามว่า
%\begin{equation}
%I(g, f) = \int g(X, \mu) \log \frac{g(X, \mu)}{f(X, \beta)} dX
%\end{equation}
%เมื่อ $\beta$ และ $\mu$ เป็นค่าพารามิเตอร์ต่าง ๆ ของแบบจำลอง $f$ และ $g$ ตามลำดับ.
%ปริมาณ I(g,f) ใช้วัดสารสนเทศที่สูญเสียไป เมื่อใช้แบบจำลอง $f$ แทนการแจกแจง $g$.
%
%\end{Exercise}

\begin{Exercise}
	\label{ex: opt min problem softplus sigmoid gaussian}
	จงแก้ปัญหา
	$\underset{v}{\mathrm{min}} \; g(v)
	\mbox{ s.t. } v \leq 2$
	เมื่อ 
	\begin{eqnarray}
	%	g(v) = 0.2 \log(1 + \exp(-v-3)) 
	%	+ \frac{1.5}{1 + 
	%		\exp(-v +2)}
	%	-2.5 \exp(-0.01 (v - 10)^2)
	%	%
	g(v) = 0.2 \log(1 + e^{-v-3}) 
	+ \frac{1.5}{1 + 
		e^{-v +2}}
	-2.5 e^{-0.01 (v - 10)^2}
	%	\nonumber \\
	\label{eq: ex opt const simple f}
	\end{eqnarray}
	%    p1 = 0.2 * np.log(1 + np.exp(-x-3))  
	%p2 = 1.5/(1 + np.exp(-x +2))
	%p3 = -2.5*np.exp(-0.01*(x - 10)**2)
	%
	%
	โดยใช้\textit{วิธีการลงโทษ} (penalty method)
	\index{english}{penalty method}
	\index{thai}{วิธีการลงโทษ}
	\index{english}{constrained optimization}
	พร้อมอภิปรายว่า
	(1) กำหนด\textit{ฟังก์ชันลงโทษ}เป็นอะไร
	(2) ฟังก์ชันจุดประสงค์ที่รวมการลงโทษเข้าไปแล้วเป็นอะไร
	(3) เกรเดียนต์ของฟังก์ชันจุดประสงค์
	เกรเดียนต์ของฟังก์ชันลงโทษ
	และเกรเดียนต์ของ\textit{ฟังก์ชันที่ถูกลงโทษ} (ฟังก์ชันจุดประสงค์ ที่รวมการลงโทษเข้าไปแล้ว)
	เป็นอะไรบ้าง
	และ (4) คำตอบของปัญหาคืออะไร
	และเลือกค่า\textit{ลากรานจ์พารามิเตอร์}อย่างไร ยกตัวอย่างค่าที่ทำงานได้
	ดูแบบฝึกหัด~\ref{ex: opt gd penalty} สำหรับผลจากการแก้ปัญหา ด้วยโปรแกรม.
	
	\textit{คำใบ้}
	พจน์แรกในฟังก์ชันจุดประสงค์
	ได้แก่ $0.2 \log(1 + e^{-v-3})$
	คือ \textit{ฟังก์ชันบวกอ่อน} (softplus function)
	\index{english}{softplus function}
	\index{thai}{ฟังก์ชันบวกอ่อน}
	ซึ่งมีรูปพื้นฐานคือ $\log(1 + e^x)$
	และมีอนุพันธ์คือ
	$1/(1 + e^{-x})$
	ที่เรียกว่า \textit{ฟังก์ชันซิกมอยด์} (sigmoid function).
	พจน์ที่สองได้แก่ $1.5/(1 + 
	e^{-v +2})$
	คือ \textit{ฟังก์ชันซิกมอยด์} 
	ที่พึ่งกล่าวไป 
	และ\textit{ฟังก์ชันซิกมอยด์}ในรูปพื้นฐาน $\sigma(x) = 1/(1 + e^{-x})$
	มีอนุพันธ์คือ
	$e^x / ( 1 + e^x)^2$
	หรือเท่ากับ $\sigma(x) \cdot (1 - \sigma(x))$.
	พจน์ที่สามได้แก่
	$-2.5 e^{-0.01 (v - 10)^2}$
	คือ \textit{ฟังก์ชันเกาส์เซียน} (Gaussian function)
	ซึ่งรูปพื้นฐาน $e^{-x^2}$
	มีอนุพันธ์เป็น $-2 x e^{-x^2}$.
	
	
	
	
\end{Exercise}



\begin{Exercise}
	\label{ex: opt min problem piecewise}
	จงแก้ปัญหา
	$\underset{v}{\mathrm{min}} \; g(v)
	\mbox{ s.t. } v \leq -0.5$
	เมื่อ 
	\begin{eqnarray}
	g(v) = \left\{ 
	\begin{array}{lcl}
	-(x + 1) & \mbox{ เมื่อ } & x < -1, \\
	x + 1 & \mbox{ เมื่อ } & -1 \leq x < 0, \\
	(-x + 1) & \mbox{ เมื่อ } & 0 \leq x < 1, \\
	x - 1 & \mbox{ เมื่อ } & x \geq 1.
	\end{array}
	\right.
	\label{eq: ex opt const piecewise f}
	\end{eqnarray}
	%p1 =  (x < -1) * a[0] * -(x + 1)  
	%p2 = (-1 <= x ) * (x < 0 ) * a[1] * (x + 1) 
	%p3 = (0 <= x) * (x < 1) * (a[2]*-x + a[1])
	%p4 = (x > 1) * (a[3]*(x-1) - a[2] + a[1])
	
	
	%np.cos(4*x)/(1 + x**2)
	%
	โดยใช้\textit{วิธีการลงโทษ} \index{english}{penalty method}
	\index{thai}{วิธีการลงโทษ}
	\index{english}{constrained optimization}
	พร้อมอภิปรายว่า
	(1) กำหนด\textit{ฟังก์ชันลงโทษ}เป็นอะไร
	(2) ฟังก์ชันจุดประสงค์ที่รวมการลงโทษเป็นอะไร
	(3) เกรเดียนต์ของฟังก์ชันจุดประสงค์
	เกรเดียนต์ของฟังก์ชันลงโทษ
	และเกรเดียนต์ของ\textit{ฟังก์ชันที่ถูกลงโทษ} (ฟังก์ชันจุดประสงค์ที่รวมการลงโทษเข้าไปแล้ว)
	เป็นอะไรบ้าง
	และ
	(4) คำตอบของปัญหาคืออะไร
	และเลือกค่า\textit{ลากรานจ์พารามิเตอร์}อย่างไร ยกตัวอย่างค่าที่ทำงานได้
	
	\textit{คำใบ้}
	อนุพันธ์ของ\textit{ฟังก์ชันต่อเนื่องเป็นช่วง}
	สามารถหาได้ในแต่ละช่วง.
	
	\textit{หมายเหตุ}
	ฟังก์ชัน $g$ เป็น\textit{ฟังก์ชันต่อเนื่องเป็นช่วง} (piecewise continuous function)
	ซึ่งเป็นกรณีพิเศษ ที่ ณ จุดดีที่สุด 
	ค่าเกรเดียนต์อาจจะไม่เป็นศูนย์.
	
	
\end{Exercise}

\subsection{แบบฝึกหัดการเขียนโปรแกรม}


\subsubsection{แบบฝึกหัดไพธอนแก่น}
แบบฝึกหัดต่อไปนี้
ทบทวนการเขียนโปรแกรมด้วยภาษาไพธอนพื้นฐาน
โดยยังไม่แนะนำให้เรียกใช้มอดูลอื่น ณ ตอนนี้.

\begin{Exercise}
	\label{ex: linalg addition python}
	
	จงเขียนฟังก์ชัน \verb|add_matrix| ที่รับเมทริกซ์สองตัว 
	เป็นอาร์กิวเมนต์ ซึ่งแต่ละตัวเป็นลิสต์ที่มีโครงสร้างสองลำดับมิติ (เหมือนเมทริกซ์)
	ตรวจสอบ
	ว่าขนาดของเมทริกซ์เท่ากัน
	ทำการบวกเมทริกซ์
	และรีเทิร์นผลลัพธ์ออกมาในรูปลิสต์
	ที่มีโครงสร้างแบบเดียวกัน
	
\end{Exercise}

\begin{Exercise}
	\label{ex: linalg matrix mult python}
	
	จงเขียนฟังก์ชัน \verb|mult_matrix| ที่รับเมทริกซ์สองตัว 
	เป็นอาร์กิวเมนต์ ซึ่งแต่ละตัวเป็นลิสต์ที่มีโครงสร้างสองลำดับมิติ (เหมือนเมทริกซ์)
	ตรวจสอบ
	ว่าขนาดของเมทริกซ์สามารถทำการคูณเมทริกซ์ได้
	ทำการคูณเมทริกซ์
	และรีเทิร์นผลลัพธ์ออกมาในรูปลิสต์
	ที่มีโครงสร้างลักษณะเดียวกัน
	
\end{Exercise}

%\begin{Exercise}
%	\label{ex: linalg det cofactor expansion python}
%\end{Exercise}

\begin{Exercise}
	\label{ex: linalg mat inverse}
	การหาเมทริกซ์ผกผัน ด้วย\textit{วิธีเกาส์จอร์แดน} (Gauss Jordan method) ทำได้โดยขั้นตอนต่อไปนี้.
	เมื่อต้องการหา $\bm{A}^{-1}$ ของเมทริกซ์ $\bm{A} \in \mathbb{R}^{n \times n}$
	\begin{enumerate}
		\item ขยายเมทริกซ์ $\bm{A}$ ด้วยเมทริกซ์เอกลักษณ์.
		เมทริกซ์ขยาย $\bm{A}' \in \mathbb{R}^{n \times 2n}$ จะเป็น
		\begin{eqnarray}
		\bm{A}' = \begin{bmatrix}
		a_{11} & a_{12} & \ldots & a_{1n} & 1 & 0 & \ldots & 0
		\\
		a_{21} & a_{22} & \ldots & a_{2n} & 0 & 1 & \ldots & 0
		\\
		\vdots & \vdots & \ddots & \vdots &
		\vdots & \vdots &
		\ddots & \vdots 
		\\
		a_{n1} & a_{n2} & \ldots & a_{nn} & 0 & 0 & \ldots & 1		
		\end{bmatrix}
		\label{eq: augmented matrix}
		\end{eqnarray}
		\item ดำเนินปฏิบัติการเชิงเส้นกับแถวของ $\bm{A}'$ 
		จนส่วนหน้ากลายเป็นเมทริกซ์เอกลักษณ์ ดังเช่น
		\begin{eqnarray}
		\bm{B}' = \begin{bmatrix}
		1 & 0 & \ldots & 0
		&
		b_{11} & b_{12} & \ldots & b_{1n} 
		\\
		0 & 1 & \ldots & 0
		&
		b_{21} & b_{22} & \ldots & b_{2n}
		\\
		\vdots & \vdots & \ddots & \vdots &
		\vdots & \vdots &
		\ddots & \vdots 
		\\
		0 & 0 & \ldots & 1
		&
		b_{n1} & b_{n2} & \ldots & b_{nn}		
		\end{bmatrix}
		\label{eq: linear transformed augmented matrix}
		\end{eqnarray}
		รายละเอียดการดำเนินปฎิบัติการ
		คือ 
		(1) 
		ที่แถว $i$ 
		เพื่อทำให้ส่วนประกอบแนวทะแยงมุมเป็นหนึ่ง
		ดำเนินการ $r_{ij} = a_{ij}/a_{ii}$ สำหรับ $j = 1, \ldots, 2n$
		เมื่อ $r_{ij}$ คือค่าส่วนประกอบภายหลังการคำนวณที่ตำแหน่ง $(i,j)$.
		(2)
		ที่แถวอื่น ๆ แถว $k \neq i$
		เพื่อทำให้ส่วนประกอบ ตำแหน่ง $(k,i)$ นอกแนวทะแยงมุมเป็นศูนย์
		ดำเนินการ $s_{kj} = a_{kj} - r_{ij} \cdot a_{ki}$
		สำหรับ $j = 1, \ldots, 2n$
		เมื่อ $s_{ij}$ คือค่าส่วนประกอบภายหลังการคำนวณที่ตำแหน่ง $(i,j)$.
		(3) ดำเนินการเช่นนี้ โดยทำทุกแถว จากแถว $i = 1, \ldots, n$
		แล้วผลลัพธ์จะได้ $\bm{B}'$.
		
		\item ส่วนหลังของ $\bm{B}'$ (สดมภ์ที่ $(n+1)^{th}$ จนถึงสดมภ์สุดท้าย) คือเมทริกซ์ผกผันของ $\bm{A}$.
		
	\end{enumerate}
	
	จากโปรแกรมตัวอย่างในรายการ~\ref{code: gauss-jordan inverse matrix}
	จงเขียนโปรแกรมไพธอน เพื่อหาเมตริกผกผันด้วยวิธีเกาส์จอร์แดน
	และทดสอบผลลัพธ์ที่ได้ โดยใช้การคูณเมทริกซ์ จากแบบฝึกหัด~\ref{ex: linalg matrix mult python}
	แล้วศึกษาโปรแกรม
	และอภิปรายข้อจำกัด
	และกรณีที่อาจเสี่ยงทำให้โปรแกรมรันผิดพลาด พร้อมเสนอการปรับปรุงแก้ไข.
	\textit{คำใบ้} การหารด้วยศูนย์จะทำให้โปรแกรมล่มได้.
	
	\lstinputlisting[language=Python, caption={[วิธีหาเมทริกซ์ผกผันด้วยวิธีเกาส์จอร์แดน]ตัวอย่างโปรแกรม วิธีหาเมทริกซ์ผกผันด้วยวิธีเกาส์จอร์แดน}, label={code: gauss-jordan inverse matrix}]{02Background/code/code_gauss_jordan.py}
	
\end{Exercise}

\subsubsection{แบบฝึกหัดไพธอนด้วยนัมไพ}
เนื่องจากโปรแกรมการรู้จำรูปแบบ
ใช้\textit{การคำนวณเชิงเลข} (numerical computation) อย่างมาก
ดังนั้น การใช้มอดูลการคำนวณเชิงเลขประกอบจึงมีประโยชน์มาก 
เพื่อช่วยลดภาระ 
และเพื่อจะได้ทุ่มเทไปที่\textit{ศาสตร์ของการรู้จำรูปแบบ}
และ\textit{การเรียนรู้ของเครื่อง}ได้เต็มที่มากขึ้น.
หัวข้อนี้ แนะนำมอดูลคำนวณเชิงเลข \textit{นัมไพ} (Numpy) และ\textit{แมทพล๊อตลิป} (Matplotlib) เพื่อช่วยการคำนวณเชิงเลข
และ\textit{การนำไปสร้างภาพให้เห็น} (visualization)
\index{english}{numerical programming}
\index{thai}{การเขียนโปรแกรมเชิงเลข}

นอกจากมอดูล\textit{นัมไพ}
และ\textit{แมทพล๊อตลิป}
มีมอดูลที่มีประโยชน์
และนิยมใช้
สำหรับงานรู้จำรูปแบบอีกมาก
ซึ่ง 
ตำรานี้ จะได้แนะนำมอดูลอื่น ๆ อีก ตามเนื้อหาที่เหมาะสมต่อไป

ตัวอย่างโปรแกรมในแบบฝึกหัดต่าง ๆ จากนี้ จะนำเข้ามอดูล \texttt{numpy} และ \texttt{matplotlib}
ดัวยคำสั่ง 
%\verb|import numpy as np|
%และ \verb|from matplotlib import pyplot as plt|
%\begin{Verbatim}[fontsize=\small}
%import numpy as np
%from matplotlib import pyplot as plt
%\end{Verbatim}
\begin{verbatim}
import numpy as np
from matplotlib import pyplot as plt
\end{verbatim}
ซึ่งจะนำเข้ามอดูล 
\texttt{numpy} และ 
\texttt{matplotlib.pyplot}. 
มอดูล \texttt{pyplot} เป็นมอดูลย่อย
เพื่อใช้ในการวาดกราฟ.
การนำเข้านั้น ได้ตั้งชื่อใหม่ให้กับมอดูลทั้งสองเพื่อความสะดวก เป็น \texttt{np} และ \texttt{plt}.

\begin{Exercise}
	\label{ex: numpy np.array}
	จงสร้างตัวแปร \texttt{a1} เป็น \texttt{np.array} จาก \texttt{list} เช่น \verb|[2, 4, 8, 9]|
	และเรียนรู้คำสั่งต่อไปนี้
	คำสั่ง \texttt{len(a1)}
	คำสั่ง \texttt{a1.shape}
	คำสั่ง \texttt{type(a1)}
	คำสั่ง \texttt{a1.tolist()}
	แล้วสร้าง
	\texttt{a2} เป็น \texttt{np.array} จาก \texttt{list} สองมิติ 
	เช่น \verb|[[2, 4], [8, 9]]|
	และเรียนรู้คำสั่งแบบเดียวกัน รวมทั้งทดลอง
	และอภิปรายผลของคำสั่งตัดส่วน
	(สังเกตชนิด และสัดส่วน ลอง \texttt{type} และ \texttt{shape})
	เช่น
	คำสั่ง \verb|a2[0]|
	คำสั่ง \verb|a2[0,:]|
	คำสั่ง \verb|a2[0][1]|
	และคำสั่ง \verb|a2[0,1]|.
	
\end{Exercise}

\begin{Exercise}
	\label{ex: numpy addition}
	จากคำสั่งต่อไปนี้ ทดลอง
	ดัดแปลง สังเกต และอภิปรายสิ่งที่ได้เรียนรู้.
	\begin{itemize}
		\item คำสั่ง 
		\verb|v1 = np.array([[1,2,3,4]])|
		\item คำสั่ง
		\verb|v2 = np.array([[2,4,1,-1]])|
		\item คำสั่ง
		\verb|v1 + 5|
		เปรียบเทียบกับคำสั่ง
		\verb|v1 + v2|
		และคำสั่ง
		\verb|v1 + v2.transpose()|
		\item คำสั่ง
		\verb|v1 * 5|
เปรียบเทียบกับคำสั่ง
\verb|v1 * v2|
และคำสั่ง
\verb|v1 * v2.transpose()|
		\item ทดลองแและเปรียบเทียบ
		การคูณด้วยคำสั่งต่าง ๆ 
		ได้แก่
		คำสั่ง \verb|v1*v2|
		คำสั่ง \verb|np.dot(v1,v2)|
		คำสั่ง \verb|np.multiply(v1,v2)|
		คำสั่ง	
		\verb|np.matmul(v1,v2)|
		รวมถึงทดลองเปลี่ยนสัดส่วนของ \verb|v1| และ \verb|v2| เป็นอย่างอื่น (รวมถึงเป็นเมทริกซ์ และเทนเซอร์)	
		
	\end{itemize}	
\end{Exercise}

\begin{Exercise}
	\label{ex: numpy inverse}
	จงทดลองคำสั่งการหาเมทริกซ์ผกผัน \verb|np.linalg.inv|
	และหาเมทริกซ์ผกผันต่่อไปนี้
	และเปรียบเทียบผลกับแบบฝึกหัด~\ref{ex: linalg mat inverse}.
	\begin{eqnarray}
	\bm{A}_1 &=& \begin{bmatrix}
	1 & 2 & 4 \\
	4 & 0 & 8 \\
	7 & 3 & 5
	\end{bmatrix}
	\nonumber \\
	\bm{A}_2 &=& \begin{bmatrix}
	-1 & 2 & 4 \\
	4 & 1 & -1 \\
	9 & 3 & 8
	\end{bmatrix}
	\nonumber \\
	\bm{A}_3 &=& \begin{bmatrix}
	4 & 0 & 4 \\
	1 & 2 & 3 \\
	7 & 3 & 10
	\end{bmatrix}
	\nonumber	
	\end{eqnarray}
	
	
\end{Exercise}

%\begin{Exercise}
%	\label{ex: numpy solve lin eqn}
%	
%\end{Exercise}
%
%\begin{Exercise}
%	\label{ex: numpy solve lin eqn matrix}
%	
%\end{Exercise}
%
%\begin{Exercise}
%	\label{ex: numpy determinant}
%	
%\end{Exercise}

%\begin{Exercise}
%	\label{ex: numpy norm}
%	
%\end{Exercise}

%\begin{exercise}
%	\label{ex: numpy orthogonal vector}
%	
%\end{exercise}
%
%\begin{exercise}
%	\label{ex: numpy vector rotation}
%	
%\end{exercise}


%\begin{exercise}
%	\label{ex: numpy orthogonal projection 3D}
%	
%\end{exercise}
%
%\begin{exercise}
%	\label{ex: numpy orthogonal projection 3D onto 2D}
%	
%\end{exercise}

\begin{Exercise}
	\label{ex: numpy eigenvector}
	
	จงหาค่าและเวกเตอร์ลักษณะเฉพาะของเมทริกซ์ในแบบฝึกหัด~\ref{ex: numpy inverse}.
	
	\textit{คำใบ้} ฟังก์ชัน \texttt{numpy.linalg.eig} เรียกใช้ \textit{เลแพค} (LAPACK) ซึ่งเป็นมอดูลที่ได้รับความเชื่่อถือในการคำนวณค่าและเวกเตอร์ลักษณะเฉพาะ.
	\textit{เลแพค} ใช้วิธีคำนวณด้วย\textit{การแยกตัวประกอบค่าเอกฐาน} (singular value decomposition) ที่มีประสิทธิภาพมากกว่า ตัวอย่างวิธีคำนวณที่อภิปรายในหัวข้อ~\ref{sec: Eigenvectors and Eigenvalues}.	
\end{Exercise}


\begin{Exercise}
	\label{ex: numpy matplotlib plot multiple plots color linestyle}
	
	จงเขียนโปรแกรม 
	เพื่อวาดกราฟของฟังก์ชันบวกอ่อน $f(x) = \log(1 + e^x)$
	ฟังก์ชันซิกมอยด์ $f(x) = 1/(1 + e^{-x})$ และฟังก์ชันเกาส์เซียน $f(x) = e^{-x^2}$
	โดย วาดกราฟทั้งสามให้อยู่ในภาพเดียวกัน ดังแสดงในรูป~\ref{fig: num plot softplus sigmoid gaussian}.
	\index{english}{softplus function}
	\index{english}{sigmoid function}
	\index{english}{gaussian function}
	\index{thai}{ฟังก์ชันบวกอ่อน}
	\index{thai}{ฟังก์ชันซิกมอยด์}
	\index{thai}{ฟังก์ชันเกาส์เซียนส์}
	
	\textit{คำใบ้} ดูคำสั่ง \verb|np.linspace| 
	คำสั่ง \verb|plt.plot| โดยเฉพาะอาร์กิวเมนต์ เช่น \verb|color=(1,0.5,0)| 
	และ 
	\verb|linestyle='--'|
	คำสั่ง \verb|plt.legend|
	คำสั่ง \verb|plt.title|
	โดยเฉพาะอาร์กิวเมนต์ เช่น \verb|fontsize=18|.
	
	%
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=3.0in]
			{02Background/num/code_linalg_matplot.png}
		\end{center}
		\caption[ฟังก์ชันบวกอ่อน ฟังก์ชันซิกมอยด์ และฟังก์ชันเกาส์เซียน]{กราฟแสดงพฤติกรรมของของฟังก์ชันบวกอ่อน ฟังก์ชันซิกมอยด์ และฟังก์ชันเกาส์เซียน}
		\label{fig: num plot softplus sigmoid gaussian}
	\end{figure}
	%
	
\end{Exercise}


\begin{Exercise}
	\label{ex: numpy matplotlib imshow manipulate pixels}
	
	จงเขียนโปรแกรม โดยใช้มอดูล \verb|matplotlib.pyplot| เพื่อนำเข้าภาพ (ซึ่งอาจจะเป็นไฟล์นามสกุล \verb|.png|) แล้วนำมาแสดง
	ดังตัวอย่างในรูป~\ref{fig: num imshow} (ภาพ ก).
	การดำเนินการนี้ ต้องอ่านภาพเข้ามาก่อน แล้วจึงค่อยแสดงภาพออกหน้าจอ.
	คำสั่ง เช่น
	\verb|img = plt.imread('t.png')|
	อ่านภาพจากไฟล์ชื่อ \verb|'t.png'|.
	ตรวจสอบสัดส่วนข้อมูล และลักษณะข้อมูล เช่น 
	ใช้คำสั่ง \verb|print(img.shape)|
	ใช้คำสั่ง
	\verb|print(img)|.
	สังเกต \texttt{plt.imread} อ่านภาพ 
	ออกมาเป็นข้อมูลที่มีสัดส่วน $4$ ลำดับชั้น สำหรับ ช่องสีแดง ช่องสีเขียว ช่องสีน้ำเงิน และช่อง\textit{อัลฟ่า} (alpha channel)
	และแต่ละพิกเซลมีค่าระหว่าง $0$ ถึง $1$.
	การแสดงภาพทำได้ ด้วยคำสั่ง เช่น \verb|plt.imshow(img)|.
	
	หลังจากนั้นทดลองเปลี่ยนค่าพิกเซลของภาพ แล้วสังเกตผล.
	ตัวอย่างในรูป~\ref{fig: num imshow} ภาพ ข ที่แสดงการเปลี่ยนค่าพิกเซล
	ด้วยคำสั่ง เช่น 
	\verb|img[1000:1010, 1400:1620, 1] = 1| จะเปลี่ยนค่าพิกเซลต่าง ๆ ที่ตำแหน่ง 1000 ถึง 1009 ตามแนวตั้ง
	และตำแหน่ง 1400 ถึง 1619 ตามแนวนอน  ในช่องสีที่หนึ่ง (ช่องสีเขียว) โดยเปลี่ยนค่าเป็นหนึ่ง (ค่ามากที่สุด).
	เมื่อเปลี่ยนค่าเสร็จแล้ว และนำข้อมูลมาแสดงดูใหม่ จะเห็นเส้นสีเขียวปรากฎขึ้นมา (ภาพ ข มีการเปลี่ยนค่าลักษณะนี้สี่ครั้ง สำหรับสี่เส้นที่เห็นแสดงเป็นกรอบ).
	หมายเหตุ ถ้ากำหนดค่าใหม่ให้กับพิกเซลแล้ว ภาพนั้นจะมีตำหนิ นั่นคือ เส้นสีเขียวจะไม่สามารถถูกลบออกได้ (แต่ถูกเขียนทับได้).
	หากต้องการเก็บภาพต้นฉบับไว้ ให้ทำสำเนาไว้ก่อนที่จะมีการดัดแปลงภาพ เช่น \verb|marked = img.copy()| และดำเนินการเปลี่ยนค่าพิกเซลที่สำเนาแทน.
	
	
	%
	\begin{figure}[H]
		\begin{center}
			\begin{tabular}{cc}
				\includegraphics[width=0.5\columnwidth]{02Background/num/original_image.png}
				&
				\includegraphics[width=0.5\columnwidth]{02Background/num/marked_image.png}
				\\
				ก & ข
			\end{tabular}
			
		\end{center}
		\caption[ตัวอย่างภาพและผลการแก้ค่าพิกเซล]{ภาพ ก เป็นภาพต้นฉบับ.
			ภาพ ข ดัดแปลงจาก ภาพ ก โดยกำหนดค่าความเข้มของพิกเซลใหม่}
		\label{fig: num imshow}
	\end{figure}
	%
\end{Exercise}


\begin{Exercise}
	\label{ex: opt loss 2D plot}
	
	จากค่าฟังก์ชัน $g(\bm{v}) = -e^{-53-v_1^2 -2v_2^2-v_1 v_2 + 10 v_1 + 19 v_2}$
	จงเขียนโปรแกรม 
%	โดยใช้มอดูล \verb|matplotlib.pyplot| 
	เพื่อวาดภาพคอนทัวร์
	และภาพสามทัศนมิติ ดังรูป~\ref{fig: opt 2D}.
	
	\textit{คำใบ้}
	คำสั่ง \verb|plt.contour| จะวาดภาพคอนทัวร์
	จากค่าพิกัดสามแกนมิติ 
	ดังนั้นเพื่อจากวาดภาพคอนทัวร์
	จะต้องคำนวณค่าฟังก์ชัน $g$ ที่ $v_1$ และ $v_2$ ต่าง ๆ ทั้งหมดที่ครอบคลุมบริเวณที่จะวาด.
	ตัวอย่าง เช่น หากต้องการวาดครอบคลุมบริเวณ $v_1$ มีค่า $1$ ถึง $5$ และ $v_2$ มีค่า $2$ ถึง $6$ โดยวาดให้มีความละเอียดมิติละ $40$ จุด
	จะต้องคำนวณค่า ฟังก์ชัน $g$ ที่ $v_1$ และ $v_2$ ในบริเวณนี้ออกมา $1600$ ค่า.
	คำสั่ง \verb|np.meshgrid| อาจช่วยลดภาระการจับคู่ค่า $v_1$ และ $v_2$ ได้.
	
\end{Exercise}

%\subsubsection{วิธีลงเกรเดียนต์}
%จากเนื้อหาในหัวข้อ~\ref{sec: opt grad desc}
%แบบฝึกหัดต่อไปนี้ทบทวน เสริมความเข้าใจ
%และให้ตัวอย่างสำหรับการนำไปลงมือปฏิบัติและทดลอง.

\begin{Exercise}
	\label{ex: prob monty hall simulation}
	
	จากปัญหามอนตี้ฮอล ในหัวข้อ~\ref{sec: prob cond prob examples}
	%
	จงเขียนโปรแกรมเพื่อจำลองสถานการณ์
	และแสดงให้เห็นว่า 
	โอกาสที่ผู้เข้าแข่งขันจะได้รางวัล  หากเลือกที่จะเปลี่ยนประตูเป็น $2/3$
	และโอกาสที่ผู้เข้าแข่งขันจะได้รางวัล  หากเลือกประตูเดิมเป็น $1/3$.
	
	อภิปรายโปรแกรม
	และผลการทดลอง
	พร้อมออกแบบวิธีนำเสนอผล
	ให้ประจักษ์ชัดเจน.
	รูป~\ref{fig: prob monty hall sim results}
	แสดงตัวอย่างวิธีนำเสนอผล
	ซึ่งจากรูปจะเห็นว่า
	เมื่อจำนวนซ้ำมากขึ้น
	โอกาสที่จะชนะเมื่อเลือกประตูเดิม (ภาพกลาง) จะประมาณ $0.33$ หรือ $1/3$
	ในขณะที่ ถ้าเปลี่ยนไปประตูใหม่
	โอกาสจะประมาณ $0.67$ หรือ $2/3$.
	
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=\textwidth]{02Background/prob/monty_hall_simulated_results.png}
		\end{center}
		\caption[ผลการจำลองปัญหามอนตี้ฮอล]{ผลลัพธ์จากการจำลองสถานการณ์ ปัญหามอนตี้ฮอล. ภาพซ้าย แสดงผลลัพธ์ $10$ ครั้งแรก.
			สัญลักษณ์ `o' สีแดงแทนรางวัล
			สัญลักษณ์ `x' สีน้ำเงินแทนประตูที่ผู้แข่งขันเลือก เช่น ครั้งแรกสุด (ครั้งที่ $0$) ผู้เข้าแข่งขันเลือกประตูที่สาม แต่รางวัลอยู่ประตูที่สอง.
			ประตูที่พิธีกรเปิดไม่ได้แสดงในภาพ.
			ภาพกลางแสดงอัตราส่วนสะสมของจำนวนครั้งที่ผู้เข้าแข่งขันชนะได้รางวัล เมื่อเลือกประตูเดิม.
			ภาพขวาแสดงอัตราส่วนสะสมของจำนวนครั้งที่ผู้เข้าแข่งขันชนะได้รางวัล เมื่อตัดสินใจเปลี่ยนไปประตูใหม่.}
		\label{fig: prob monty hall sim results}
	\end{figure}
	
	\textit{คำใบ้}
	คำสั่ง \verb|np.random.choice|
	ใช้สุ่มเลือกค่าจาก\textit{ลิสต์}.
	รางวัลอาจสุ่มให้อยู่ประตูไหนก็ได้.
	ประตูที่ผู้เข้าแข่งขันเลือก ก็อาจอยู่ประตูไหนก็ได้.
	แต่ประตูที่พิธีกรเลือกเปิด
	จะเป็นประตูที่มีรางวัลไม่ได้
	หรือจะเป็นประตูที่ผู้แข่งขันเลือกก็ไม่ได้.
	การเลือกประตูของพิธีกร
	ต้องทำหลังจากการเลือกประตูรางวัล
	และการเลือกประตูของผู้แข่งขัน.
	
\end{Exercise}

\begin{Exercise}
	\label{ex: prob standard error of mean}
%	Goodfellow et al 2016, pp. 124

ผลการคำนวณค่าสถิติจากข้อมูลที่จำกัด จะมีความไม่แน่นอนอยู่%
\footnote{เนื้อหาในแบบฝึกหัดนี้ ได้รับแรงบันดาลใจและอิทธิพลหลัก ๆ จาก \cite{GoodfellowEtAl2016}.}
ในแง่ที่ว่า
หากสุ่มกลุ่มข้อมูลออกมาใหม่ แล้วผลการคำนวณอาจจะเปลี่ยนไป.

หากคำนวณค่าเฉลี่ยของกลุ่มข้อมูลที่สุ่มมาจากการแจกแจงเดียวกัน
และนำค่าเฉลี่ยของแต่ละการสุ่มมาวิเคราะห์
จะพบว่า\cite{GoodfellowEtAl2016}
\textit{ค่าเบี่ยงเบนมาตราฐาน}ของ\textit{ค่าเฉลี่ย}
\begin{eqnarray}
\mathrm{SD}(\mu_N) = \sqrt{\mathrm{var}\left[ \frac{1}{N} \sum_{n=1}^N x_n \right]} = \frac{\sigma}{\sqrt{N}}
\label{eq: standard error}
\end{eqnarray}
เมื่อ $\mu_N$ คือค่าเฉลี่ยที่ของกลุ่มขนาด $N$
และ $x_n$ คือจุดข้อมูลในกลุ่มที่สุ่มขึ้นมา
และ $\sigma$ คือ ค่าเบี่ยงเบนมาตราฐานของการแจกแจง.

จากทฤษฎีข้างต้น 
ยิ่งกลุ่มข้อมูลมีขนาดใหญ่ ($N$ มีค่ามาก)
ค่าเฉลี่ยที่คำนวณได้จะยิ่งมีความแม่นยำใกล้เคียงกับค่าเฉลี่ยจริงของการแจกแจงเท่านั้น.

จงเขียนโปรแกรม เพื่อแสดงในเห็นว่า
สมการ~\ref{eq: standard error} เป็นจริง.

ตัวอย่างการนำเสนอ แสดงในรูป~\ref{fig: prob stdev of mean}.
(ไม่จำเป็นต้องทำตามตัวอย่างนี้.)
ผลที่ได้ มาจาก\textit{การจำลอง} (simulation)
โดย กำหนดการแจกแจงแบบเกาส์เซียน ที่มีค่าเฉลี่ยเป็นศูนย์ และค่าความแปรปรวน $\sigma^2$
และจำลองการสุ่มกลุ่มจำนวน $N$ ขึ้นมา.
ตัวอย่างนี้ ทดลองค่า $\sigma$ สามค่าได้แก่ $0.2$, $1.0$, และ $5.0$ แสดงด้วย ภาพซ้าย กลาง และขวา ตามลำดับ.


	\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\textwidth]{02Background/prob/standardError_Average1.png}
	\end{center}
	\caption[ความสัมพันธ์ของความคลาดเคลื่อนการคำนวณกับขนาดข้อมูล]{
ความสัมพันธ์ของความคลาดเคลื่อนการคำนวณกับขนาดข้อมูล.
แต่ละภาพ แสดง \textit{ค่าเบี่ยงเบนมาตราฐาน}ของ\textit{ค่าเฉลี่ย} ที่คำนวณจากกลุ่มข้อมูลที่สุ่มขึ้นมา
(เส้นทึบ สีน้ำเงิน) กับค่าที่คำนวณทางทฤษฎี (เส้นประ สีแดง).
แกนนอน แสดงจำนวนจุดข้อมูลในกลุ่ม.
ภาพต่าง ๆ ทางซ้าย แสดงผล เมื่อการแจกแจงของข้อมูลมี $\sigma = 0.2$ 
ภาพต่าง ๆ แนวกลาง $\sigma = 1$
และภาพต่าง ๆ ทางขวา $\sigma = 5$.
ภาพต่าง ๆ ในแถวบน แสดงผลเมื่อทำซ้ำ $10$ ครั้ง
แถวกลาง ทำซ้ำ $50$ ครั้ง
และแถวล่าง ทำซ้ำ $250$ ครั้ง.
}
	\label{fig: prob stdev of mean}
\end{figure}

จากนั้น 
คำนวณค่า $\mu_N$ ของกลุ่ม โดยทำซ้ำ 
$10$ ครั้ง (ผลแสดงในภาพต่าง ๆ แถวบน)
ทำซ้ำ $50$ ครั้ง (แถวกลาง)
และทำซ้ำ $250$ ครั้ง (แถวล่าง).
ค่าเฉลี่ยของแต่ละซ้ำจะถูกนำมาคำนวณค่าเบี่ยงเบนมาตราฐาน.
นั่นคือ $\widehat{\mathrm{SE}} = \sqrt{\frac{\sum_{r=1}^R m_r - \bar{m}}{R - 1} }$
เมื่อ
$\widehat{\mathrm{SE}}$ คือ\textit{ค่าเบี่ยงเบนมาตราฐาน}ของ\textit{ค่าเฉลี่ย} 
และ
$R$ คือ จำนวนซ้ำ.
ส่วน $m_r = \frac{1}{N} \sum_{n=1}^N x_n$ 
คือ ค่าเฉลี่ยของกลุ่มของซ้ำที่ $r^{th}$
และ $\bar{m} = \frac{1}{R} \sum_{r=1}^R m_r$.
%คือ ค่าเฉลี่ยของค่าเฉลี่ยกลุ่ม.
ค่า $\widehat{\mathrm{SE}}$
(แทนด้วย เส้นทึบสีน้ำเงิน และสัญกรณ์ \verb|stdev(mu(x))| ในภาพ)
เป็นค่าที่คำนวณจากข้อมูล
ส่วน $\sigma/N$ เป็นค่าที่คำนวณจากทฤษฎี
(แทนด้วย เส้นประสีแดง และสัญกรณ์ \verb|sigma/sqrt(N)| ในภาพ).
ในแต่ละภาพ แกนตั้ง แสดง\textit{ค่าเบี่ยงเบนมาตราฐาน}ของ\textit{ค่าเฉลี่ย}
และแกนนอน แสดงค่าขนาดของกลุ่ม $N$ ซึ่งในตัวอย่างใช้ $10$, $50$, $100$, $500$, และ $1000$.

ผลที่ได้ แสดงในเห็นว่า
(1) เมื่อ $N$ ขนาดใหญ่ขึ้น \textit{ค่าเบี่ยงเบนมาตราฐาน}ของ\textit{ค่าเฉลี่ย}มีค่าเล็กลง.
(2) ถ้า $\sigma$ ของการแจกแจง มีค่าใหญ่ 
\textit{ค่าเบี่ยงเบนมาตราฐาน}ของ\textit{ค่าเฉลี่ย} ก็จะมีค่าใหญ่ตามสัดส่วน.
(3) \textit{ค่าเบี่ยงเบนมาตราฐาน}ของ\textit{ค่าเฉลี่ย} ที่ได้จากการคำนวณกับข้อมูล เป็นไปตามทฤษฎี
และจะเห็นความสอดคล้องได้ชัดเจนมากขึ้น เมื่อจำนวนซ้ำเพิ่มขึ้น.

หมายเหตุ ในทางปฏิบัติ เราไม่รู้ค่า $\sigma$ ของการแจกแจง.
ดังนั้น การประเมินความคลาดเคลื่อนของการคำนวณ เมื่อกลุ่มข้อมูลมีขนาดจำกัด จะไม่สามารถทำได้สะดวกเช่นนี้.
ในทางปฏิบัติ เราจะสามารถประเมินความคลาดเคลื่อน ต่อขนาดข้อมูลได้อย่างไร.
หรือ ที่น่าสนใจกว่าคือคำถามว่า
ทำอย่างไร เราถึงจะสามารถประเมิน ได้ว่าภาระกิจที่กำลังทำอยู่ ต้องการจำนวนข้อมูลเท่าไร.
อภิปราย พร้อมให้เหตุผลประกอบ.


\end{Exercise}


\begin{Exercise}
	\label{ex: opt gd simple code}
	%\lstinputlisting[language=Python, caption={ฟังก์ชันคำนวณตำแหน่งเพื่อวาดลูกศร}]{02Background/opt/code_gd.py}
	
	จากตัวอย่างปัญหาค่าน้อยที่สุด $\min_x f(x)$ เมื่อ $f(x) = -e^{-(x-5)^2}$
	ในหัวข้อ~\ref{sec: opt grad desc}
	%
	เราสามารถนำวิธีลงเกรเดียนต์สามารถนำไปเขียนโปรแกรมได้ง่าย ๆ โดยเริ่มจาก
	เตรียมเกรเดียนต์ของฟังก์ชันจุดประสงค์.
	นั่นคือ $\nabla f(x) = -e^{-(x-5)^2} \cdot (-2x + 10)$
	และไพธอนฟังก์ชัน \texttt{grad} ดังแสดงในรหัสโปรแกรมข้างล่าง จะทำหน้าที่คำนวณเกรเดียนต์นี้
\begin{Verbatim}[fontsize=\small]
def grad(x):
    return -np.exp(-(x - 5)**2) * (-2*x +10)
\end{Verbatim}
	และหลังจากมีเกรเดียนต์แล้ว 
	โปรแกรมวิธีลงเกรเดียนต์ก็สามารถทำงานได้
	ดังแสดงในรายการ~\ref{code: gd simple}. 
	%
	โปรแกรมเลือกใช้ค่าขนาดก้าว  \verb|step_size| เป็น $0.5$ (ตัวแปร $\alpha$ ในสมการ~\ref{eq: opt gd})
	และใช้เงื่อนไขจบเป็นจำนวนรอบสูงสุด ซึ่งในที่นี้ใช้เป็น $8$ รอบ ที่ระบุลงไปให้ลูปเลย ด้วย \texttt{for i in range(8)}
	
	ค่าเริ่มต้นของตัวแปรตัดสินใจ เลือกกำหนดให้เป็น $6.5$ ในบรรทัดที่สอง
	และคำสั่งในบรรทัดที่สี่ %\verb|x = x - grad(x) * step_size|
	คือการคำนวณสมการ~\ref{eq: opt gd}.
	%สังเกต\textit{โปรแกรมเชิงคำสั่ง} (imperative programming)
	%ค่าตัวแปรจะเปลี่ยนตามสถานะ
	%ดังนั้นจึงสามารถกำหนดค่าคำนวณทางซ้ายมือให้กับตัวแปร \texttt{x} ทางขวามือได้เลยด้วยตัวดำเนินการกำหนดค่า \texttt{=}
	%ซึ่งต่างจากคณิตศาสตร์ที่ $=$ เป็นเครื่องหมายระบุความสัมพันธ์
	%ที่หมายถึงการเท่ากันของค่าทางซ้ายและทางขวาของเครื่องหมาย
	%
	\begin{lstlisting}[language=Python, caption={[วิธีลงเกรเดียนต์]ตัวอย่างโปรแกรม วิธีลงเกรเดียนต์อย่างง่าย ๆ},
	label={code: gd simple}]
step_size = 0.5
x = 6.5
for i in range(8):
    x = x - step_size * grad(x) 
print('x = ', x, '; grad = ', grad(x))
	\end{lstlisting}
	
	จากโปรแกรมนี้ ทดลองรัน และเปรียบผลลัพธ์ที่ได้กับตัวอย่าง
	%(อย่าลืมนำเข้า \texttt{numpy} มาเป็น \texttt{np})
	
\end{Exercise}


\begin{Exercise}
	\label{ex: opt gd termination code}
	การใช้งานวิธีลงเกรเดียนต์ในทางปฏิบัติ นิยมเพิ่ม\textit{เงื่อนไขการจบ}
	เพื่อให้สามารถเลือก\textit{จำนวนรอบสูงสุด}ไว้มาก ๆ ก่อน
	โดยไม่ต้องกังวลว่า จะเสียเวลารันโดยไม่จำเป็น (ดูแบบฝึกหัด~\ref{ex: opt gd motivation to term} ประกอบ)
	
	จากแบบฝึกหัด~\ref{ex: opt gd simple code}
	โปรแกรมวิธีลงเกรเดียนต์ง่าย ๆ ที่แสดงในรายการ~\ref{code: gd simple}
	สามารถเพิ่ม\textit{เงื่อนไขการจบ}เข้าไปได้
	ดังแสดงในรายการ~\ref{code: gd term}.
	\textit{เงื่อนไขจำนวนรอบสูงสุด} ควบคุมได้โดยผ่านตัวแปร \texttt{Nmax}.
	โปรแกรมตัวอย่างนี้ ใช้\textit{เงื่อนไขความคลาดเคลื่อนยินยอม} 
	%ที่ค่าความคลาดเคลื่อนของเกรเดียนต์
	วัดค่าผ่าน \texttt{eps}
	โดย 
	ถ้า \texttt{eps} น้อยกว่าหรือเท่ากับ\textit{ค่าที่ยินยอมได้}
	ก็จะจบการคำนวณทันที.
	\textit{ค่าที่ยินยอมได้} (tolerance)  %ที่ควบคุม\textit{เงื่อนไขความคลาดเคลื่อนยินยอม}ทั้งสามนี้ 
	กำหนดผ่าน \texttt{tol}.
	
	\begin{lstlisting}[language=Python, caption={[วิธีลงเกรเดียนต์ที่มีเงื่อนไขการจบ]ตัวอย่างโปรแกรม วิธีลงเกรเดียนต์ที่มีเงื่อนไขการจบด้วยความคลาดเคลื่อนที่ยินยอมได้},
	label={code: gd term}]
step_size = 0.5
Nmax = 500
tol = 0.00001
x = 6.5
for i in range(Nmax):
    x = x - step_size * grad(x)    
    print(i, ': x = ', x, '; grad = ', grad(x))
	
    eps = np.abs(grad(x))
    if eps <= tol:
        print('Reach termination criteria.')
        break
	\end{lstlisting}
	
	%สังเกตว่า
	%โปรแกรมในรายการ~\ref{code: gd term} มีการเรียกใช้ \texttt{f(x)} ซึ่งคือฟังก์ชันคำนวณค่า\textit{ฟังก์ชันจุดประสงค์}
	%และในตัวอย่างนี้ที่\textit{ฟังก์ชันจุดประสงค์}
	%$f(x) = -e^{-(x-5)^2}$
	%สามารถนำมาเขียนโปรแกรมได้ดังนี้
	%\begin{verbatim}
	%def f(x):
	%    return -np.exp(-(x - 5)**2)
	%\end{verbatim}
	
	%หมายเหตุ
	%โปรแกรมในรายการ~\ref{code: gd term}
	%ใช้ \texttt{gradx} แทนค่าเกรเดียนต์ปัจจุบัน (เกรเดียนต์ก่อนปรับค่า \texttt{x})
	%และใช้ \texttt{grad(x)}
	%แทนเกรเดียนต์ใหม่ (เกรเดียนต์หลังปรับค่า \texttt{x}).
	
	สังเกตว่า
	โปรแกรมนี้
	มีการคำนวณที่ซ้ำซ้อนมาก ในแต่ละรอบ  เช่น \texttt{grad(x)} มีการคำนวณค่าเดียวกันถึงสามครั้ง.
	ความซ้ำซ้อนนี้สามารถลดลงได้ โดยการเก็บค่าไว้ในตัวแปร เช่น
	\begin{Verbatim}[fontsize=\small]
...
x = 6.5
gradx = grad(x)
for i in range(Nmax):
    x = x - step_size * gradx
    gradx = grad(x)
    print(i, ': x = ', x, '; grad = ', gradx)
    eps = np.abs(gradx)
    if eps <= tol:
        print('Reach termination criteria.')
        break
	\end{Verbatim}
	โดย \texttt{...} แทนโค้ดต่าง ๆ ที่ละไว้ ไม่ได้หมายถึงการพิมพ์จุดสามครั้งเข้าไปในโปรแกรม.
	ตัวแปร \texttt{gradx} ใช้เก็บค่าเกรเดียนต์ที่คำนวณไว้แล้ว
	และค่าเกรเดียนต์ที่คำสั่งปรับค่า \verb|x = x -step_size * gradx| จะเป็นคนละค่ากับที่คำสั่ง \texttt{print} และที่กำหนดค่า \texttt{eps}
	ดังนั้นตำแหน่งของ \texttt{gradx = grad(x)} จึงต้องอยู่หลังการปรับค่า \texttt{x}
	และเพื่อให้รอบคำนวณแรกสามารถทำได้ จึงต้องมีคำสั่ง
	\texttt{gradx = grad(x)} อยู่ก่อนเข้าลูปด้วย.
	
	จากโปรแกรมในรายการ~\ref{code: gd term}
	จงทดลองรัน และเปรียบเทียบผล
	แล้วทดลองเปลี่ยนค่า \texttt{tol} เป็นค่าอื่น ๆ เช่น \texttt{0}, \verb|1e-5|, \verb|1e-3|.
	
	คำถามเพิ่มเติม. 
	ทำไม\textit{เงื่อนไขความคลาดเคลื่อน}
	นั่นคือ \texttt{eps <= tol}
	ถึงเขียนด้วยการเปรียบเทียบน้อยกว่าหรือเท่ากับ 
	ทดลองเปลี่ยนเป็นการเปรียบเทียบน้อยกว่า ได้แก่ \texttt{eps < tol} และทดลองค่า \texttt{tol} ต่าง ๆ อีกครั้ง 
	สังเกตและอภิปรายผล
	
\end{Exercise}

\begin{Exercise}
	\label{ex: opt gd motivation to term}
	จากแบบฝึกหัด~\ref{ex: opt gd simple code}
	จงทดลองเปลี่ยนจุดเริ่มต้น (บรรทัดที่สอง) เป็นค่าต่าง ๆ เช่น $4$, $5$, $6$, $7$, $8$. ทดลองเพิ่มหรือลดจำนวนรอบสูงสุดถ้าจำเป็น 
	ลองรันโปรแกรมในรายการ~\ref{code: gd simple} ใหม่
	แล้วสังเกตผลที่ได้ ว่าที่ค่าเริ่มต้นต่าง ๆ ต้องคำนวณกี่รอบ ถึงจะได้คำตอบ เช่น จากตัวอย่าง ถ้าใช้ \texttt{x = 6.5} จะได้คำตอบที่รอบที่เจ็ด
	(ให้ใช้ค่า\textit{ขนาดก้าว}เท่ากันหมดเป็น $0.5$ ก่อน)
	
	อภิปรายถึงประเด็นปัญหาที่จะเกิด เมื่อนำโปรแกรมนี้ไปรันในทางปฏิบัติ
	แล้วทำการทดลองใหม่ โดยรันโปรแกรมในรายการ~\ref{code: gd term} และอภิปรายข้อดีของการใช้เงื่อนไขการจบ ที่มีในโปรแกรม~\ref{code: gd term}.
	
\end{Exercise}

\begin{Exercise}
	\textit{เงื่อนไขความคลาดเคลื่อนยินยอม}
	จะกำหนดค่าความคลาดเคลื่อนที่ยอมรับได้ ซึ่งอาจทำได้หลายวิธี เช่น
	ใช้ค่าความคลาดเคลื่อนของตัวแปร $\epsilon_{\bm{v}} = \|\bm{v}^{(k+1)} - \bm{v}^{(k)}\|$
	ใช้ค่าความคลาดเคลื่อนของเกรเดียนต์
	$\epsilon_{\nabla} = \|\nabla g(\bm{v}^{(k+1)}) - \nabla g(\bm{v}^{(k)})\|$
	หรือใช้ค่าความคลาดเคลื่อนของฟังก์ชันจุดประสงค์
	$\epsilon_g = | g(\bm{v}^{(k+1)}) -  g(\bm{v}^{(k)})|$
	หรือใช้ค่าความคลาดเคลื่อนข้างต้นผสมกัน.
	อภิปราย\textit{เงื่อนไขความคลาดเคลื่อนยินยอม}แต่ละแบบ
	\textit{คำใบ้} พิจารณาสมการ~\ref{eq: opt gd} และความหมายของเกรเดียนต์.
	
\end{Exercise}


\begin{Exercise}
	\label{ex: opt gd vec code}
	จากตัวอย่าง ปัญหาค่าน้อยที่สุด เมื่อตัวแปรตัดสินใจเป็นเวกเตอร์
	$\min_{\bm{v}} \; g$ เมื่อ
	$\bm{v} =[v_1, v_2]^T$
	และ
	$g(\bm{v}) = -e^{-53-v_1^2 -2v_2^2-v_1 v_2 + 10 v_1 + 19 v_2}$.
	%	
	คล้ายกับแบบฝึกหัด~\ref{ex: opt gd simple code} 
	วิธีลงเกรเดียนต์ต้องการฟังก์ชันคำนวณค่าเกรเดียนต์ ซึ่งอาจทำได้โดย 
	\begin{Verbatim}[fontsize=\small]
def grad(u):
    assert type(u) == type(np.array([]))
    assert u.shape == (2,1)
	
    gu = g(u)
    gradu = gu * np.array([[-2*u[0,0] - u[1,0] + 10],
           [-4*u[1,0] - u[0,0] + 19]])
    return gradu
	\end{Verbatim}
	ฟังก์ชัน \texttt{grad} นี้ใช้คำสั่ง \texttt{assert} เพื่อจำกัดชนิดของอินพุต \texttt{u}  เพื่อป้องกันปัญหาจากชนิดข้อมูล.
	ตัวแปร \texttt{u}
	แทนเวกเตอร์ $\bm{u} = [u_1, u_2]^T$.
	ค่าส่วนประกอบ $u_1$ และ $u_2$
	เข้าถึงได้โดย \texttt{u[0,0]} และ \texttt{u[1,0]} ตามลำดับ.
	นอกจากนี้ ฟังก์ชัน \texttt{grad} ยังเรียกใช้ฟังก์ชันจุดประสงค์ ซึ่งเขียนได้ดังนี้
	\begin{Verbatim}[fontsize=\small]
def g(u):
    assert type(u) == type(np.array([]))
    assert u.shape == (2, 1)
	
    loss = -np.exp(-53 - u[0,0] ** 2 - 2 * u[1,0] ** 2 - u[0,0] * u[1,0] 
          + 10 * u[0,0] + 19 * u[1,0])
    return loss
	\end{Verbatim}
	
	รายการ~\ref{code: gd vec} แสดงตัวอย่างโปรแกรม วิธีลงเกรเดียนต์ เมื่อตัวแปรเป็นเวกเตอร์.
	%\begin{lstlisting}[language=Python, caption={ตัวอย่างโปรแกรม วิธีลงเกรเดียนต์ เมื่อตัวแปรเป็นเวกเตอร์},
	%label={code: gd vec}]{code_gd_vec.py}
	%\end{lstlisting}
	
	\lstinputlisting[language=Python, caption={[วิธีลงเกรเดียนต์ เมื่อตัวแปรเป็นเวกเตอร์]ตัวอย่างโปรแกรม วิธีลงเกรเดียนต์ เมื่อตัวแปรเป็นเวกเตอร์},
	label={code: gd vec}]{02Background/code/code_gd_vec.py}
	
	สังเกตว่า โปรแกรมบันทึกค่าฟังก์ชันจุดประสงค์ หรือเรียกว่าย่อ ๆ ว่า \textbf{ค่าสูญเสีย} (loss) 
	ของทุกรอบการคำนวณไว้ใน \texttt{losses}.
	\textit{ค่าสูญเสีย}ต่อรอบคำนวณ
	สามารถนำมาใช้ เพื่อตรวจสอบการทำงานแก้ปัญหาค่าน้อยที่สุดได้
	ดังแสดงในภาพขวาบนของรูป~\ref{fig: opt gd 2D}.
	ภาพอื่น ๆ ในรูป~\ref{fig: opt gd 2D} ก็จะสามารถทำได้ในแบบเดียวกัน เพียงแต่ต้องบันทึกค่านั้น ๆ ขณะรันด้วย ซึ่งในที่นี้ ขอละไว้เพื่อไม่ให้โปรแกรมดูซับซ้อนเกินไป.
	
	ลองเปรียบเทียบฟังก์ชัน \texttt{grad} กับการคำนวณหาค่าเกรเดียนต์ด้วยมือ
	และเปรียบเทียบโปรแกรมในรายการ~\ref{code: gd vec} เปรียบเทียบกับรายการ~\ref{code: gd term}
	และอภิปรายจุดแตกต่าง
	
	ทดลองรันโปรแกรมในรายการ~\ref{code: gd vec}
	แล้วแก้ไขค่า \verb|step_size| รัน และตรวจสอบผลที่ได้ กับการคำนวณของตัวอย่างในหัวข้อ~\ref{sec: opt contrained opt}.
	
	
\end{Exercise}

% LATER
%\begin{exercise}
%	\label{ex: opt numerical grad test}
%	%\lstinputlisting[language=Python, caption={ฟังก์ชันคำนวณตำแหน่งเพื่อวาดลูกศร}]{02Background/opt/code_gd_vec.py}
%	
%\end{exercise}


\begin{Exercise}
	\label{ex: opt gd step size}
	%\lstinputlisting[language=Python, caption={ฟังก์ชันคำนวณตำแหน่งเพื่อวาดลูกศร}]{02Background/opt/code_gd_vec.py}
	
	จากปัญหาในแบบฝึกหัด~\ref{ex: opt gd vec code}
	ทดลอง เปลี่ยนค่าขนาดก้าว (ตัวแปร \verb|step_size|) ต่าง ๆ เช่น $0.1$, $0.2$, $0.4$, $0.8$
	แล้วสังเกตผลและอภิปราย และเตรียมหลักฐานเพื่อประกอบการอภิปราย เช่น รูป~\ref{fig: ex opt gd step sizes}
	รูป~\ref{fig: ex opt gd step sizes zoomin}
	และรูป~\ref{fig: ex opt gd step sizes final answers}.
	ทดลองค่าอภิมานพารามิเตอร์อื่น ๆ เพื่อยืนยันข้อสรุปที่ได้อภิปราย.
	
	รูป~\ref{fig: ex opt gd step sizes}
	แสดงความก้าวหน้าของการแก้ปัญหา (\textit{ค่าสูญเสีย}ต่อรอบคำนวณ)
	เมื่อใช้ค่าขนาดก้าวต่าง ๆ 
%	\verb|step_size| ต่าง ๆ 
	(ตามระบุเหนือภาพ) โดย\textit{ค่าอภิมานพารามิเตอร์}อื่น ๆ 
	คือ ใช้\textit{จำนวนรอบสูงสุด} $1000$ รอบ
	ใช้ค่าตัวแปรตัดสินใจเริ่มต้นเป็น $[2.5,3.5]^T$
	และใช้ค่า\textit{ความคลาดเคลื่อนยินยอม} เป็น $10^{-6}$.

	%
\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\textwidth]
		{02Background/opt/losses_step_sizes.png}
	\end{center}
	\caption[ผลการทำงานวิธีลงเกรเดียนต์ ที่ค่าขนาดก้าวต่าง ๆ]{ตัวอย่างแสดงผลการทำงานวิธีลงเกรเดียนต์ เมื่อใช้ค่าขนาดก้าวต่าง ๆ.}
	\label{fig: ex opt gd step sizes}
\end{figure}
%
	
รูป~\ref{fig: ex opt gd step sizes zoomin} 
แสดงความก้าวหน้าของการแก้ปัญหา เมื่อใช้ค่าขนาดก้าวต่าง ๆ
ในภาพเดียวกัน 
โดยค่าขนาดก้าวที่ใช้ระบุด้วยสัญลักษณ์
ดังแสดงใน\textit{กรอบคำอธิบายสัญลักษณ์} (legend).
ภาพซ้ายแสดงในช่วง $80$ รอบคำนวณแรก 
(เมื่อใช้ขนาดก้าวบางค่า การคำนวณจบก่อน $80$ รอบ).
ภาพขวาแสดงในช่วง $10$ รอบคำนวณแรก
เพื่อให้เห็นชัดเจนว่าที่ค่าขนาดก้าวเท่าใดลู่เข้าสู่คำตอบได้เร็วที่สุด
(ค่าสูญเสียลดลงต่ำสุด ในรอบคำนวณที่น้อยที่สุด หมายถึงการลู่เข้าสู่คำตอบได้เร็วที่สุด).
ตัวอย่างนี้ จะเห็นว่าขนาดก้าว $0.4$ 
ช่วยให้วิธีลงเกรเดียนต์ลู่เข้าเร็วที่สุด
และขนาดก้าวที่น้อยลง มีผลให้ลู่เข้าช้าลง.
แต่หากใช้ขนาดก้าวที่ใหญ่เกินไป (เช่น $0.8$ ในตัวอย่างนี้)
อาจทำให้วิธีลงเกรเดียนต์ไม่สามารถลู่เข้าสู่คำตอบได้.
รูป~\ref{fig: ex opt gd step sizes final answers}
แสดงค่าของตัวแปรตัดสินใจ $v_1$ และ $v_2$
สังเกตว่า เมื่อใช้ขนาดก้าว $0.1, 0.2, 0.4$ ค่าของตัวแปรตัดสินใจลู่เข้าสู่ค่า $3$ และ $4$ ตามลำดับ
โดย เมื่อใช้ขนาดก้าว $0.4$ ค่าของ
$v_1$ และ $v_2$ มีการส่ายอยู่บ้างก่อนส่ายน้อยลงจนลู่เข้าสู่คำตอบ.
แต่เมื่อใช้ขนาดก้าว $0.8$ ค่าของ
$v_1$ และ $v_2$ แสดงการส่ายต่อเนื่องไปจนครบ $1000$ รอบฝึกโดยไม่มีแนวโน้มจะลู่เข้า
ขนาดก้าว $0.8$ เป็นขนาดก้าวที่ใหญ่เกินไปอย่างชัดเจน.
อภิปราย พฤติกรรมนี้ พร้อมวาด เสนทางการหาคาทำใหนอยที่สุด (เช่นรูป~\ref{fig: opt gd 2D trajectory}) เพื่อประกอบการอภิปราย.

	%
\begin{figure}[H]
	\begin{center}
		\includegraphics[width=0.8\textwidth]
		{02Background/opt/losses_step_sizes_zoomin.png}
	\end{center}
	\caption[ผลการทำงานวิธีลงเกรเดียนต์ ที่ค่าขนาดก้าวต่าง ๆ ในรอบคำนวณต้น ๆ]{ผลการทำงานวิธีลงเกรเดียนต์
		ในรอบคำนวณต้น ๆ เมื่อใช้ค่าขนาดก้าวต่าง ๆ เมื่อวาดรวมกัน.}
	\label{fig: ex opt gd step sizes zoomin}
\end{figure}
%
	
	%
\begin{figure}[H]
	\begin{center}
		\includegraphics[width=\textwidth]
		{02Background/opt/vs_step_sizes.png}
	\end{center}
	\caption[ผลลัพธ์จากวิธีลงเกรเดียนต์ ที่ใช้ค่าขนาดก้าวต่าง ๆ]{ผลลัพธ์จากวิธีลงเกรเดียนต์ เมื่อใช้ค่าขนาดก้าวต่าง ๆ.}
	\label{fig: ex opt gd step sizes final answers}
\end{figure}
%	
	
หมายเหตุ 
อย่างไรก็ตาม
ค่าขนาดก้าวนี้ไม่จำเป็นต้องใช้เป็นค่าเดียวกันตลอดทุกรอบการคำนวณ
อาจเปลี่ยนขนาดได้ตามความเหมาะสม เช่น อาจปรับให้ขนาดเล็กลง เมื่อจำนวนรอบคำนวณมาก ๆ ได้
หรืออาจใช้กลไกการปรับที่ซับซ้อนขึ้นได้ เช่น \textit{วิธีลงเกรเดียนต์ชันที่สุด} (steepest gradient descent method ดู \cite{ChongZak2ndEd} เพิ่มเติม สำหรับผู้ที่สนใจ).
\end{Exercise}

\begin{Exercise}
	\label{ex: opt gd init}
	
	จงแก้ปัญหา $\min_u \cos(2 \pi u - \frac{\pi}{4}) \cdot \exp \left( -\frac{u^2}{\pi}\right)$	 
	ด้วยวิธีลงเกรเดียนต์.
	
	ทดลองค่าเริ่มต้นต่าง ๆ เช่น
	$-2, -1, -0.7, 0, 0.12301636938191951, 0.5, 1, 1.5$.
	เลือกค่าอภิมานพารามิเตอร์อื่น ๆ ให้เหมาะสม รันวิธีลงเกรเดียนต์จนสำเร็จ
	และสังเกตผลลัพธ์ที่ได้จากการใช้ค่าเริ่มต้นต่าง ๆ. 
	อภิปรายความสัมพันธ์ระหว่างค่าเริ่มต้นต่าง ๆ กับผลลัพธ์ที่ได้.
	เมื่อใช้ค่าเริ่มต้นเป็น $0.12301636938191951$ ผลลัพธ์เป็นอย่างไร ทำไมถึงเป็นเช่นนั้น?
	
	รูป~\ref{fig: ex opt gd multimodal} แสดงค่าฟังก์ชันจุดประสงค์ $g(u)$.
	อภิปรายการใช้งานวิธีลงเกรเดียนต์กับปัญหาลักษณะนี้ 
	โดยเฉพาะในทางปฏิบัติ
	ที่มักไม่สามารถวาดกราฟของฟังก์ชันจุดประสงค์ได้.
	

	
\begin{figure}[H]
	\begin{center}
		\includegraphics[width=0.3\textwidth]
		{02Background/opt/multimodal.png}
	\end{center}
	\caption[ฟังก์ชันจุดประสงค์ของปัญหาหลายภาวะ]{ฟังก์ชันจุดประสงค์ $g(u) =\cos(2 \pi u - \frac{\pi}{4}) \cdot \exp \left( -\frac{u^2}{\pi}\right)$.}
	\label{fig: ex opt gd multimodal}
\end{figure}
%	
	
หมายเหตุ ปัญหาในแบบฝึกหัดนี้ จะเรียกว่า
\textit{ปัญหาหลายภาวะ} (multi-modal problem)
ซึ่งคือ ปัญหาค่าน้อยที่สุดที่มีค่าทำน้อยที่สุดท้องถิ่นหลายที่
และวิธีลงเกรเดียนต์จะพบคำตอบที่ใกล้ที่สุด
ที่ทิศทางเกรเดียนต์ของจุดเริ่มต้นชี้ไป เมื่อใช้ขนาดก้าวเล็กพอ.
	
\end{Exercise}

\begin{Exercise}
	\label{ex: opt gd random.norm init}

จงแก้ปัญหาของแบบฝึกหัด~\ref{ex: opt gd init}
โดยใช้การกำหนดค่าเริ่มต้นด้วยวิธีการสุ่ม
แล้วทดลอง 
%วิธีลงเกรเดียนต์ด้วยค่าสุ่ม
เพิ่มจำนวนทำซ้ำให้มากขึ้นเท่าตัว.
สังเกตผลลัพธ์ที่ได้
อภิปรายว่า
การกำหนดค่าเริ่มต้นด้วยวิธีการสุ่ม
จะช่วยบรรเทาปัญหาของการติดอยู่ใน\textit{สถานการณ์ที่ดีที่สุดท้องถิ่น}ได้อย่างไร

\textit{คำใบ้} ลองคำสั่งการสุ่มค่า เช่น คำสั่ง \verb|np.random.uniform|,
คำสั่ง\verb|np.random.normal|,
หรือคำสั่ง \verb|np.random.randn|.

\end{Exercise}





\begin{Exercise}
	\label{ex: opt gd penalty}
	จากแบบฝึกหัด~\ref{ex: opt min problem softplus sigmoid gaussian}
	จงเขียนโปรแกรม เพื่อแก้ปัญหาแบบมีีข้อจำกัด
	และเปรียบเทียบผลที่ได้
	กับผลที่แสดงในรูป~\ref{fig: ex opt gd penalty}.
	ผลที่แสดงในรูป~\ref{fig: ex opt gd penalty}
	ได้จากการคำนวณวิธีลงเกรเดียนต์ โดยใช้ \textit{รอบคำนวณสูงสุด} เป็น $5000$ และใช้ค่า\textit{ขนาดก้าว}เป็น
	$0.02$.
	
	%
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=0.8\textwidth]
			{02Background/opt/constraint_penalty.png}
		\end{center}
		\caption[ตัวอย่างแสดงผลการแก้ปัญหาค่าน้อยที่สุดแบบมีข้อจำกัด เมื่อใช้วิธีการลงโทษ]{ตัวอย่างแสดงผลทำงานวิธีลงเกรเดียนต์ ของแบบฝึกหัด~\ref{ex: opt gd penalty}.
			แต่ละแถวแสดงผล เมื่อเลือก $\lambda$ เป็น $0.01, 0.1, 0.2$ ตามลำดับ.
			ภาพในสดมภ์แรก แสดงความก้าวหน้า (ค่าฟังก์ชันจุดประสงค์ต่อรอบฝึก) โดยเส้นบางสีเขียว แสดงความก้าวหน้า เมื่อค่าเริ่มต้นเป็น $-5$
			และเส้นหนาสีน้ำเงินเขียว แสดงความก้าวหน้า เมื่อค่าเริ่มต้นเป็น $5$.
			กราฟทั้งหมดลู่เข้าดี ยกเว้นที่ $\lambda = 0.1$ และค่าเริ่มต้นเป็น $5$ (กราฟกลางเส้นหนาสีน้ำเงินเขียว) ที่ดูเหมือนกำลังลดลง แต่อาจต้องการรอบคำนวณเพิ่ม.
			ภาพในสดมภ์ที่สองและที่สาม
			แสดง ค่าฟังก์ชันจุดประสงค์ดั่งเดิม (เส้นบางสีฟ้า)
			ค่าฟังก์ชันจุดประสงค์ที่ถูกลงโทษ (เส้นหนาสีส้ม)
			ค่าเริ่มต้นของตัวแปรตัดสินใจ (กากบาทสีดำ)
			และค่าสุดท้ายของการคำนวณ
			(จุดกลมสีแดง)
			พื้นที่สีเทาแสดงบริเวณที่ละเมิดข้อจำกัด
			คำตอบใดที่อยู่ในบริเวณนี้ถือว่าใช้ไม่ได้
			โดยภาพในสดมภ์ที่สอง 
			แสดงผลเมื่อค่าเริ่มต้นเป็น $-5$
			และภาพในสดมภ์ที่สาม
			แสดงผลเมื่อค่าเริ่มต้นเป็น $5$.
		}
		\label{fig: ex opt gd penalty}
	\end{figure}
	%
	
	รูป~\ref{fig: ex opt gd penalty} แสดงให้เห็นว่า
	เมื่อเลือกใช้ค่า $\lambda$ ขนาดใหญ่มากพอ
	ไม่ว่าจะเลือกใช้ค่าเริ่มต้นที่ไหน
	คำตอบที่ได้จะเป็นค่าที่\textit{ใช้ได้} (feasible) 
	ดังที่เห็นในแถวล่างสุด ภาพกลางและขวา.
	
\end{Exercise}


\begin{Exercise}
	\label{ex: opt kkt}
\index{english}{Karush-Kuhn-Tucker theorem}
\index{thai}{ทฤษฎีบทคารูชคุนทักเกอร์}	
\index{english}{KKT}
	
\textbf{ทฤษฎีบทคารูชคุนทักเกอร์} (Karush-Kuhn-Tucker theorem คำย่อ KKT)%
\footnote{%
เนื้อหาในส่วนนี้ เรียบเรียงจาก \cite{ChongZak2ndEd}.
}
กล่าวถึงเงื่อนไขสำหรับ\textit{ค่าทำให้น้อยที่สุด}ของปัญหา
\begin{eqnarray}
\mathrm{minimize} &  f(\bm{x}) &
\nonumber \\
\mbox{subject to} & \bm{h}(\bm{x}) & = \bm{0},
\nonumber \\
                  & \bm{g}(\bm{x}) & \leq \bm{0}.
\nonumber                  
\end{eqnarray}
เมื่อตัวแปร $\bm{x} \in \mathbb{R}^n$.
ฟังก์ชันจุดประสงค์ $f: \mathbb{R}^n \mapsto \mathbb{R}$.
ฟังก์ชันข้อจำกัด $\bm{h}: \mathbb{R}^n \mapsto \mathbb{R}^m$, $\bm{h} = [h_1, \ldots, h_m]^T$.
และฟังก์ชันข้อจำกัด $\bm{g}: \mathbb{R}^n \mapsto \mathbb{R}^p$, $\bm{g} = [g_1, \ldots, g_p]^T$.

\textit{ทฤษฎีบทคารูชคุนทักเกอร์}
กล่าวว่า
หากกำหนดให้ฟังก์ชัน $f$, $\bm{h}$, และ $\bm{g}$ เป็นฟังก์ชัน\textit{ที่สามารถหาอนุพันธ์ได้อย่างต่อเนื่อง} (continuously differentiable) ซึ่งระบุด้วยสัญกรณ์ $f, \bm{h}, \bm{g} \in \mathcal{C}^1$
และกำหนดให้ $\bm{x}^\ast$ เป็น\textit{จุดปรกติ} และเป็น\textit{ค่าทำให้น้อยที่สุด}ท้องถิ่นของปัญหา
$\min f(\bm{x})$ $\mbox{ s.t. }$ $\bm{h}(\bm{x}) = \bm{0},$ $\bm{g}(\bm{x}) \leq \bm{0}$
แล้วจะต้องมี $\bm{\alpha} \in \mathbb{R}^m$ และ $\bm{\beta} \in \mathbb{R}^p$ โดยที่
\\
%\begin{center}
\begin{tabular}{ll}
(หนึ่ง) & $\bm{\beta} \geq \bm{0}$, \\
(สอง) & $\nabla f(\bm{x}^\ast) + \bm{\alpha}^{T} \nabla \bm{h}(\bm{x}^\ast) + \bm{\beta}^{T} \nabla \bm{g}(\bm{x}^\ast) = \bm{0}^T$, และ \\
(สาม) & $\bm{\beta}^{T} \bm{g}(\bm{x}^\ast) = 0$.
\end{tabular} 
%\end{center}

การประยุกต์ใช้\textit{ทฤษฎีบทคารูชคุนทักเกอร์} จะใช้เงื่อนไขทั้งสามนี้ ประกอบกับอีกสองเงื่อนไขข้อจำกัดเดิม ได้แก่ $\bm{h}(\bm{x}^\ast) = \bm{0}$ และ $\bm{g}(\bm{x}^\ast) \leq \bm{0}$
เพื่อค้นค่า $\bm{x}$'s ต่าง ๆ ที่มีโอกาสเป็น\textit{ค่าทำให้น้อยที่สุด} $\bm{x}^\ast$.

 %
%\footnote{
%%สำหรับปัญหาการหาค่าดีที่สุด $\min f(\bm{x}) \mbox{ s.t. } \bm{h}(\bm{x}) = \bm{0}$
%%เมื่อตัวแปร $\bm{x} \in \mathbb{R}^n$,
%%ฟังก์ชันจุดประสงค์ $f: \mathbb{R}^n \mapsto \mathbb{R}$
%%และฟังก์ชันเงื่อนไข $\bm{h}: \mathbb{R}^n \mapsto \mathbb{R}^m$, $\bm{h} = [h_1, \ldots, h_m]^T$ 
%%และ $m \leq n$ โดย $\bm{h} \in \mathcal{C}^1$ 
%%แล้ว
%จุดข้อมูล $\bm{x}^\ast$ ที่สอดคล้องกับเงื่อนไข $h_1(\bm{x}^\ast) = 0$, $\ldots$, $h_m(\bm{x}^\ast) = 0$
%จะเรียกว่าเป็น \textit{จุดปรกติ} (regular point) ของเงื่อนไข ถ้าเกรเดียนต์เวกเตอร์ $\nabla h_1(\bm{x}^\ast), \ldots, \nabla h_m(\bm{x}^\ast)$ เป็น\textit{อิสระเชิงเส้น}ต่อกัน.
%\index{regular point}
%\index{จุดปรกติ}
%}

หมายเหตุ
\textit{จุดปรกติ} (regular point) หมายถึง 
ค่า $\bm{x}^\ast$ ที่สอดคล้องกับข้อจำกัดทั้งหมด 
และมีเกรเดียนต์ของข้อจำกัด\textit{ที่ทำงาน}เป็นอิสระเชิงเส้นกัน.
นั่นคือ
ค่า $\bm{x}^\ast$ จะเป็น\textit{จุดปรกติ} เมื่อ
เงื่อนไขดั้งเดิม
$h_1(\bm{x}^\ast) = 0$, $\ldots$, $h_m(\bm{x}^\ast) = 0$
และเงื่อนไขดั้งเดิม
%$\bm{g}(\bm{x}^\ast) \leq \bm{0}$ (นั่นคือ 
$g_1(\bm{x}^\ast) \leq 0$, $\ldots$, $g_p(\bm{x}^\ast) \leq 0$
และเกรเดียนต์เวกเตอร์
$\nabla h_i(\bm{x}^\ast)$, $\nabla g_j(\bm{x}^\ast)$ สำหรับ $i=1, \ldots, m$ และ $j \in J(\bm{x}^\ast)$
เป็น\textit{อิสระเชิงเส้นต่อกัน}
โดย 
%$J(\bm{x}^\ast)$ เป็นเซตของดัชนีเงื่อนไขอสมการ\textit{ที่ทำงาน}.
เซตของดัชนีข้อจำกัดที่ทำงาน $J(\bm{x}^\ast) \equiv \{j : g_j(\bm{x}^\ast) = 0 \}$.

ข้อจำกัดแบบภาวะไม่เท่ากัน $g_j(\bm{x}) \leq 0$ จะเรียกว่า \textit{ทำงาน} (active) ที่ $\bm{x}^\ast$
ถ้า $g_j(\bm{x}^\ast) = 0$
และข้อจำกัด จะเรียกว่า \textit{ไม่ทำงาน} (inactive) ที่ $\bm{x}^\ast$
ถ้า $g_j(\bm{x}^\ast) < 0$.
\index{thai}{เงื่อนไข!ทำงาน}
\index{thai}{เงื่อนไข!ไม่ทำงาน}
\index{english}{constraint!active}
\index{english}{constraint!inactive}

ความหมายของ\textit{ทฤษฎีบทคารูชคุนทักเกอร์} คือ
ด้วยเงื่อนไข $\beta_j \geq 0$ และข้อจำกัด $g_j(\bm{x}^\ast) \leq 0$
ทำให้เงื่อนไข $\bm{\beta}^T \bm{g}(\bm{x}^\ast) = \beta_1 g_1(\bm{x}^\ast) + \ldots + \beta_p g_p(\bm{x}^\ast)$
สามารถอนุมานได้ว่า
ถ้า $g_j(\bm{x}^\ast) < 0$ แล้ว $\beta_j = 0$ 
แต่ถ้า $g_j(\bm{x}^\ast) = 0$ แล้ว $\beta_j$ อาจจะมีค่าเป็นบวกก็ได้ หรือเป็นศูนย์ก็ได้. 
%(เพราะแต่ละพจน์น้อยกว่าหรือเท่ากับศูนย์ แต่บวกกันทั้งหมดเป็นศูนย์ 
%ดังนั้นแต่ละพจน์ต้องเป็นศูนย์)

จงวิเคราะห์ค่า $\bm{x}^\ast$ ด้วยเงื่อนไขจาก\textit{ทฤษฎีบทคารูชคุนทักเกอร์} สำหรับปัญหา
$\min f(\bm{x})$
s.t.
$\bm{g}(\bm{x}) \leq 0$ 
โดย $g_1(\bm{x})= (x_1 - 1.5)^2 + x_2 - 5.5$
และ
$g_2(\bm{x}) = 0.2 x_1^2 - x_2 + 2.5 \leq 0$
และ
$f(\bm{x}) = 1.5 (x_1 + c_1)^2 + 1.5 (x_2 + c_2)^2$
เมื่อ
\begin{itemize}
	\item (สถานการณ์ ก) $c_1 = 3.27$ และ $c_2 = 4.8$. % และ $\bm{x}^\ast = [2.52242385, 4.45464947]^T$.
	\item (สถานการณ์ ข) $c_1 = 3.27$ และ $c_2 = 3.98950997289$. % และ $\bm{x}^\ast = [2.72901995, 3.98950997]^T$.
	\item (สถานการณ์ ค) $c_1 = 2$ และ $c_2 = 4$. % และ $\bm{x}^\ast = [2, 4]^T$.	
\end{itemize}
พร้อมเขียนโปรแกรม เพื่อแสดงผลเช่นรูป~\ref{fig: ex opt KKT}. % แสดงสถานการณ์ทั้งสามกรณี.

ตัวอย่างการตรวจสอบเงื่อนไขคารูชคุนทักเกอร์ 
%พิจารณาจุด $\bm{x}_a = [2.52242385, 4.45464947]^T$
พิจารณาสถานการณ์ ก เมื่อ $f(\bm{x}) = 1.5 (x_1 + 3.27)^2 + 1.5 (x_2 + 4.8)^2$.
%
%ก่อนอื่นตรวจสอบข้อจำกัด $g_1(\bm{x}_a) = (2.52242385 - 1.5)^2 + 4.45464947 - 5.5 = 0$
%และทำนองเดียวกัน $g_2(\bm{x}_a) = -0.682 < 0$.
%จุด $\bm{x}_a$ ผ่านข้อจำกัด โดยเนื่องจาก $g_2 < 0$ ทำให้ $\beta_2 = 0$.
%ดังนั้นจากเงื่อนไข 
%$\nabla f(\bm{x}_a) + \beta_1 \nabla g_1(\bm{x}_a) + \beta_2 \nabla g_2(\bm{x}_a) = 0$
%ทำให้ได้ว่า
%\[
%\begin{bmatrix}
%3(x_1 - 3.27) + 2 \beta_1 (x_1 - 1.5) + 0.4 \beta_2 x_1 \\
%3(x_2 - 4.8) + \beta_1 - \beta_2 
%\end{bmatrix}
%= 0
%\]
%ซึ่งเมื่อแทนค่า $x_1$, $x_2$, และ $\beta_2$ แล้วจะได้ $\beta_1 > 0$ ซึ่งสอดคล้องกับเงื่อนไขแรกของทฤษฎีบทคารูชคุนทักเกอร์.
จากเงื่อนไขที่หนึ่ง $\beta_1 \leq 0$ และ $\beta_2 \leq 0$.
เงื่อนไขที่สอง $\nabla f(\bm{x}) + \beta_1 \nabla g_1(\bm{x}) + \beta_2 \nabla g_2(\bm{x}) = 0$.
นั่นคือ
\[
\begin{bmatrix}
3(x_1 - 3.27) + 2 \beta_1 (x_1 - 1.5) + 0.4 \beta_2 x_1 \\
3(x_2 - 4.8) + \beta_1 - \beta_2 
\end{bmatrix}
= 
\begin{bmatrix}
0 \\
0
\end{bmatrix}
\]
และเงื่อนไขที่สาม $\beta_1 g_1(\bm{x}) + \beta_2 g_2(\bm{x}) = 0$.
นั่นคือ
$\beta_1 (x_2 + (x_1 - 1.5)^2 - 5.5) + \beta_2 (-x_2 + 0.2 x_1^2 + 2.5) = 0$.

กรณีแรก (a) ถ้า $\beta_1 = \beta_2 =0$.
เมื่อแทนค่า $\beta_1$ และ $\beta_2$ เข้าไปในเงื่อนไขที่สองแล้วจะได้ว่า
$\bm{x}_a = [3.27, 4.8]^T$
แต่เมื่อตรวจสอบเงื่อนข้อจำกัด $g_1(\bm{x}_a) = 2.4329$ ซึ่งละเมิดข้อจำกัด $g_1(\bm{x}) \leq 0$.
ดังนั้น $\bm{x}_a$ ไม่ใช่คำตอบ.

กรณีที่สอง (b) ถ้า $\beta_1 = 0$.
เมื่อแทนค่า $\beta_1$ เข้าไปในเงื่อนไขที่สองและเงื่อนไขที่สาม จะได้สามสมการ ซึ่งสามารถแก้สมการเพื่อหาค่า $x_1, x_2, \beta_2$ ออกมาได้
หลังจากแก้สมการแล้ว จะได้
$\bm{x}_b = [3.348, 4.742]^T$ และ $\beta_2 = -0.175$
%
%beta2: -0.174662928770235, x1: 3.34796880491982, x2: 4.74177902374325
ซึ่งค่า $\beta_2 < 0$ ละเมิดเงื่อนไขแรก.
ดังนั้น $\bm{x}_b$ ไม่ใช่คำตอบ.

กรณีที่สาม (c) ถ้า $\beta_2 = 0$.
เมื่อแทนค่า $\beta_2$ เข้าไปในเงื่อนไขที่สองและเงื่อนไขที่สาม จะได้สามสมการ ซึ่งสามารถแก้สมการเพื่อหาค่า $x_1, x_2, \beta_2$ ออกมาได้
หลังจากแก้สมการแล้ว จะได้
$\bm{x}_c = [2.529, 4.440]^T$ และ $\beta_1 = 1.079$
%
%beta1: 1.07912060381198, x1: 2.52942064674132, x2: 4.44029313206267
ซึ่งค่า $\beta_1 > 0$ สอดคล้องกับเงื่อนไขแรก
และเมื่อตรวจสอบ $g_1(\bm{x}_c) = 0$ และ $g_2(\bm{x}_c) = -0.661$ ซึ่งก็สอดคล้องกับข้อจำกัด $\bm{g}(\bm{x}) \leq \bm{0}$.
ดังนั้น $\bm{x}_c$ สามารถเป็นคำตอบได้.

	%
\begin{figure}[H]
	\begin{center}
\begin{tabular}{ccc}
		\includegraphics[width=0.3\textwidth]{02Background/opt/KKT1.png}
		&
		\includegraphics[width=0.3\textwidth]{02Background/opt/KKT2.png}
		&
		\includegraphics[width=0.3\textwidth]{02Background/opt/KKT3.png}
\end{tabular} 		
	\end{center}
	\caption[ตัวอย่างปัญหาค่าน้อยที่สุดแบบมีข้อจำกัด และเงื่อนไขคารูชคุนทักเกอร์]{
		ตัวอย่างปัญหาค่าน้อยที่สุดแบบมีข้อจำกัดกรณีต่าง ๆ.
		ภาพซ้าย แสดงสถานการณ์ ก ที่\textit{ค่าทำให้น้อยที่สุด}อยู่ตำแหน่งที่ทำให้ข้อจำกัด $g_1 = 0$ แต่ $g_2 < 0$.
		ภาพกลาง แสดงสถานการณ์ ข ที่ทำให้ข้อจำกัดทั้ง $g_1 = g_2 = 0$.
		ภาพขวา แสดงสถานการณ์ ค ที่ทำให้ข้อจำกัดทั้ง $g_1 < 0$ และ $g_2 < 0$.
		ตัวแปร $\bm{x} \in \mathbb{R}^2$ แสดงด้วยแกนนอนแทน $x_1$ และแกนตั้งแทน $x_2$.
สำหรับ แต่ละภาพ
ค่าฟังก์ชันจุดประสงค์ $f$ แสดงด้วยวาดภาพคอนทัวร์ (เส้นระดับสีเทา).
เส้นสีน้ำเงิน แสดงขอบเขตของข้อจำกัด $g_1$ (เส้นแทน $g_1(\bm{x}) = 0$).
บริเวณค่าที่สอดคล้องกับข้อจำกัด $g_1$ อยู่ด้านล่างของเส้นสีน้ำเงิน.
เส้นสีเขียว แสดงขอบเขตของข้อจำกัด $g_2$  (เส้นแทน $g_2(\bm{x}) = 0$).
บริเวณค่าที่สอดคล้องกับข้อจำกัด $g_2$ อยู่ด้านบนของเส้นสีเขียว.
พื้้นที่แรเงาสีเหลือง แสดงบริเวณค่าที่ยอมรับได้ (ผ่านข้อจำกัดของ $g_1$ และ $g_2$).
จุดสีแดงคือ $\bm{x}^\ast$ ที่ถูกต้องสำหรับแต่ละกรณี.
	}
	\label{fig: ex opt KKT}
\end{figure}
%

\textit{หมายเหตุ}
การแก้สมการด้วยมือ เป็นการฝึกทักษะที่ดี.
แต่อย่างไรก็ตาม ไพธอนมีเครื่องมือที่สะดวกในการช่วยแก้สมการลักษณะแบบนี้.
คำสั่งข้างล่างนี้ แสดงตัวอย่างการใช้ \verb|sympy| เพื่อช่วยในการแก้สมการ (สถานการณ์ ก กรณี a)
%
\begin{Verbatim}[fontsize=\small]
from sympy.solvers import solve
from sympy import Symbol
x1, x2, beta2 = Symbol('x1'), Symbol('x2'), Symbol('beta2')
solve([3*(x1 - 3.27) + 0.4*beta2*x1, 
       3*(x2-4.8) - beta2, 
       beta2*(-x2 + 0.2*x1**2 + 2.5)])
\end{Verbatim}

ในทางปฏิบัติ การแก้ปัญหาแบบมีีข้อจำกัด อาจจะสะดวกกว่าที่จะเลือกใช้\textit{วิธีการลงโทษ}
แต่ทฤษฎีบทคารูชคุนทักเกอร์ ช่วยให้ความเข้าใจเกี่ยวกับคำตอบของปัญหา 
ซึ่งในหลาย ๆ กรณี ได้นำไปสู่วิธีการแก้ปัญหาที่มีประสิทธิภาพมาก. 
(หัวข้อ~\ref{sec: SVM} อธิบายแบบจำลองจำแนกค่าทวิภาค ที่การพัฒนาใช้ประโยชน์จากทฤษฎีบทคารูชคุนทักเกอร์)

\end{Exercise}

\begin{Exercise}
	\label{ex: opt penalty inequality}

จงเขียนโปรแกรม เพื่อแก้ปัญหาในแบบฝึกหัด~\ref{ex: opt kkt} โดยใช้\textit{วิธีการลงโทษ}.

\textit{คำใบ้} วิธีการลงโทษต้องการ\textit{ฟังก์ชันลงโทษ}.
ตัวอย่างเช่น \textit{ฟังก์ชันลงโทษ} $P_1(\bm{x})$ สำหรับข้อจำกัด $g_1(\bm{x}) \leq 0$
อาจกำหนดเป็น 
$P_1(\bm{x}) = \delta(g_1(\bm{x})) \cdot g_1(\bm{x})$
%และจะมีเกรเดียนต์เป็น $(1 - \delta(-a))$ สำหรับ $(-\infty, 0]$
%$\nabla P_1(\bm{x}) = \delta(g_1(\bm{x})) \cdot [2 (x_1-1.5), \; 1]^T$
เมื่อ $\delta$ เป็น\textit{ฟังก์ชันขั้นบันไดหนึ่งหน่วย} (unit step function).
\index{thai}{ฟังก์ชันขั้นบันไดหนึ่งหน่วย}
\index{english}{unit step function}
นั่นคือ
\[
\delta(a) = 
\left\{
\begin{array}{l l}
0 & \quad \mbox{เมื่อ} \quad a < 0, \\
1 & \quad \mbox{เมื่อ} \quad a \geq 0.
\end{array} \right.
\]

%\[
%P_1(\bm{x}) = 
%\left\{
%\begin{array}{l l}
%0 & \quad \mbox{เมื่อ} \quad g_1(\bm{x}) \leq 0 \\
%g_1(\bm{x}) & \quad \mbox{เมื่อ} g_1(\bm{x}) > 0
%\end{array} \right.
%\] 
%ดังนั้นเกรเดียนต์ $\nabla P_1(\bm{x}) = $ จะเป็น
%\[
%\nabla P_1(\bm{x}) = \delta(g_1(\bm{x})) \begin{bmatrix}
%2 (x_1-1.5) \\
%\end{bmatrix}
%\]

คำสั่งข้างล่าง แสดงตัวอย่างโปรแกรมเกรเดียนต์ $\nabla P_1(\bm{x})$ ของฟังก์ชันลงโทษ $P_1(\bm{x})$.
\begin{Verbatim}[fontsize=\small]
def dPenalized_g1(x):
    g1 = x[1,0] + (x[0,0] - 1.5)**2 - 5.5
    dP = (g1 > 0) * np.array([[2*(x[0,0]-1.5)],[1]])
return dP
\end{Verbatim}
สังเกต การเขียนโปรแกรมข้างต้นใช้กลไก \verb|(g1 > 0)| ซึ่งเทีียบเท่า $(1 - \delta(-g_1))$.
การใช้กลไกลักษณะนี้จะให้ค่าเป็นหนึ่ง (ลงโทษ) เมื่อ \verb|g1| มากกว่าศูนย์
และให้ค่าเป็นศูนย์ (ไม่มีการลงโทษ) เมื่อ \verb|g1| น้อยกว่าหรือเท่ากับศูนย์.
เงื่อนไขที่ขอบ (ที่ \verb|g1| เท่ากับศูนย์) จะไม่มีเกรเดียนต์.
เมื่อเปรียบเทียบกับ \verb|(g1 >= 0)| ซึ่งเทีียบเท่า $\delta(g_1)$
ผลลัพธ์อาจต่างกันเพียงเล็กน้อย แต่การรวมเงื่อนไขขอบที่ถูกต้องอาจช่วยให้การทำงานของวิธีลงเกรเดียนต์มีเสถียรภาพมากขึ้น.

หมายเหตุ ปัญหาในแบบฝึกหัด~\ref{ex: opt kkt} มีสองข้อจำกัด แต่ที่นี้แสดงตัวอย่างแค่สำหรับ $g_1(\bm{x}) \leq 0$.
	
	
\end{Exercise}


\begin{Exercise}
	\label{ex: opt duality}
\index{english}{optimization!duality}
\index{thai}{การหาค่าดีที่สุด!ภาวะคู่กัน}
	
หลาย ๆ สถานการณ์พบว่า 
ปัญหาการหาค่าดีที่สุดแบบมีเงื่อนไข จะมีคู่ปัญหาของมัน.
และในกรณีนั้น
ปัญหาการหาค่าดีที่สุดแบบมีเงื่อนไขดั้งเดิม จะเรียกว่า \textbf{ปัญหาปฐม} (primal problem)
ส่วนปัญหาที่เป็นคู่ของ\textit{ปัญหาปฐม} จะเรียกว่า \textbf{ปัญหาคู่} (dual problem).
\index{english}{primal problem}
\index{english}{dual problem}
\index{english}{optimization!duality!primal problem}
\index{english}{optimization!duality!dual problem}

สำหรับตัวอย่างของ\textbf{ภาวะคู่กัน} (duality) 
พิจารณาปัญหาเชิงเส้นที่เขียนในรูป
%\begin{tabular}{ll}
%ปัญหาปฐม              & ปัญหาคู่ 
%\\
\begin{eqnarray}
\underset{\bm{x}}{\mathrm{minimize}} & \bm{c}^T \bm{x} & 
\nonumber \\
\mbox{subject to} & \bm{A} \bm{x} & \geq \bm{b}, 
\nonumber \\
& \bm{x}        & \geq \bm{0}.
\nonumber
\end{eqnarray}
%&
%\begin{eqnarray}
%\underset{\bm{\lambda}}{\mathrm{maximize}} & \bm{c}^T \bm{x} & 
%\nonumber \\
%\mbox{subject to} & \bm{A} \bm{x} & \geq \bm{b} 
%\nonumber \\
%& \bm{x}        & \bm{0}
%\nonumber
%\end{eqnarray}
%\end{tabular} 
ฟังก์ชันจุดประสงค์ $f(\bm{x}) = \bm{c}^T \bm{x}$ เป็นฟังก์ชันเชิงเส้น
และข้อจำกัดต่าง ๆ ก็เป็นฟังก์ชันเชิงเส้น.
การหาค่าดีที่สุดแบบมีเงื่อนไข สำหรับปัญหาเชิงเส้น มักถูกอ้างถึงด้วยชื่อ \textbf{การโปรแกรมเชิงเส้น} (linear programming).
\textit{การโปรแกรมเชิงเส้น} เป็นการศึกษาถึงขั้นตอนวิธีต่าง ๆ ที่มีประสิทธิภาพ สำหรับการหาค่าดีที่สุดแบบมีเงื่อนไข เพื่อใช้กับปัญหาเชิงเส้น.
รายละเอียดของ\textit{การโปรแกรมเชิงเส้น} สามารถศึกษาเพิ่มเติมได้จาก \cite{ChongZak2ndEd} หรือ \cite{NashSofer1996}.

จาก\textit{วิธีลากรานจ์} (Lagrange method ศึกษาได้จาก \cite{ChongZak2ndEd})
ปัญหาเชิงเส้นแบบมีข้อจำกัดข้างต้น สามารถเขียนในรูปปัญหาที่ไม่มีข้อจำกัดได้เป็น
\[
\underset{\bm{x}}{\mathrm{min}} \quad \bm{c}^T \bm{x} 
- \bm{\lambda}_1^T (\bm{A} \bm{x} - \bm{b})
- \bm{\lambda}_2^T \bm{x}
\]
เมื่อ $\bm{\lambda}_1 \geq \bm{0}$, $\bm{\lambda}_1 \geq \bm{0}$, 
และทั้ง $\bm{\lambda}_1$ กับ $\bm{\lambda}_2$ มีค่าใหญ่มากพอ. 
สังเกตว่า หากมีการละเมิดข้อจำกัด เช่น $\bm{A} \bm{x} < \bm{b}$ จะทำให้พจน์ $- \bm{\lambda}_1^T (\bm{A} \bm{x} - \bm{b})$ มีค่าเป็นบวก 
และเมื่อประกอบกับกลไกของ\textit{ลากรานจ์พารามิเตอร์} $\bm{\lambda}_1 \geq \bm{0}$ ที่หาก $\bm{\lambda}_1$ มีขนาดใหญ่มากพอ
จะทำให้ ค่าจุดประสงค์รวมมากขึ้น และส่งผลต่อเนื่องทำให้การค้นหาค่า $\bm{x}$ จะต้องปรับค่า $\bm{x}$ 
และส่งผลเป็นการแก้ไขการละเมิดดังกล่าว.

วิธีของ\textit{วิธีลากรานจ์} จะต้องเลือก\textit{ลากรานจ์พารามิเตอร์}ให้เหมาะสม
นั่นคือมีค่าใหญ่มากพอที่ข้อจำกัดจะไม่ถูกละเมิด.
แต่การเลือก\textit{ลากรานจ์พารามิเตอร์}ที่มีค่าใหญ่มากเกินไป จะไปขัดขวางการค้นหาค่าที่ดีที่สุด (ผลลัพธ์ที่ได้ จะไม่ละเมิดข้อจำกัด แต่จะไม่ใช่ค่าที่ดีที่สุดที่เป็นไปได้%
\footnote{%
\textit{วิธีลากรานจ์} จะต่างจากวิธีการลงโทษ
โดยวิธีลากรานจ์ ใช้\textit{ลากรานจ์พารามิเตอร์}และต้องเลือกค่าให้เหมาะสม.
แต่วิธีการลงโทษ ใช้ฟังก์ชันการลงโทษ ซึ่งจะลงโทษเฉพาะตอนที่ละเมิดข้อจำกัด
ดังนั้นการเลือกค่าน้ำหนักในการลงโทษจึงผ่อนคลายกว่า.
นั่นคือ สำหรับวิธีการลงโทษ 
เพียงเลือกค่าน้ำหนักให้มีค่าใหญ่มากพอเท่านั้น ไม่ต้องห่วงว่ามากเกินไปจะไปรบกวนฟังก์ชันจุดประสงค์หลัก.
แต่ความสะดวกนี้ ก็จะแลกมาด้วยการเลือกใช้ฟังก์ชันลงโทษให้เหมาะสม และประสิทธิภาพการทำงาน.
}%
).
ดังนั้น 
การเลือกขนาดของ\textit{ลากรานจ์พารามิเตอร์}เอง ก็สามารถถูกมองเป็นปัญหาการหาค่าดีที่สุดได้.
นั่นคือ เลือกขนาดของ\textit{ลากรานจ์พารามิเตอร์}ที่ใหญ่ที่สุด ที่จะไม่ทำร้ายจุดประสงค์เดิมของ\textit{ปัญหาปฐม}.

%\textit{ปัญหาคู่}ของ\textit{ปัญหาปฐม}ที่พิจารณาได้.

%จากทฤษฎีบทคารูชคุนทักเกอร์
%โดยเฉพาะเงื่อนไขที่สอง

เพื่อความสะดวก กำหนดให้ฟังก์ชันจุดประสงค์รวม 
\[
L \equiv \bm{c}^T \bm{x} 
- \bm{\lambda}_1^T (\bm{A} \bm{x} - \bm{b})
- \bm{\lambda}_2^T \bm{x}
\]
โดย $\bm{\lambda}_1 \geq \bm{0}$ และ $\bm{\lambda}_2 \geq \bm{0}$.

ดังนั้นเกรเดียนต์ 
\[
\nabla_{\bm{x}} L = \bm{c}^T - \bm{\lambda}_1^T \bm{A} - \bm{\lambda}_2^T
\]
และเมื่อพิจารณา ณ จุดดีที่สุด%
\footnote{%
การวิเคราะห์นี้เทียบเท่าทฤษฎีบทคารูชคุนทักเกอร์ โดยเฉพาะเงื่อนไขที่สอง.
}
%
นั่นคือ ที่ $\nabla_{\bm{x}} L = 0$ และแก้สมการจะได้ $\bm{\lambda}_2^T = \bm{c}^T - \bm{\lambda}_1^T \bm{A}$.
%นี่หมายความว่า ณ ที่จุดดีที่สุดค่า $\bm{\lambda}_2^T = bm{c}^T - \bm{\lambda}_1^T \bm{A}$.
ดังนั้น 
ค่าฟังก์ชันจุดประสงค์รวม ณ จุดดีที่สุด (เมื่อแทนค่า $\bm{\lambda}_2$ เข้าไป) จะเป็น
\[
L' = \bm{\lambda}_1^T \bm{b}
\]
โดย $\bm{\lambda}_1 \geq \bm{0}$ 
และ $\bm{\lambda}_2 \geq \bm{0}$.
และ ณ จุดดีที่สุด เงื่อนไข $\bm{\lambda}_2 \geq \bm{0}$
%$\equiv \bm{c}^T - \bm{\lambda}_1^T \bm{A} \geq \bm{0}$ 
$\equiv \bm{\lambda}_1^T \bm{A} \leq \bm{c}^T$.
สังเกตว่า
(1) $L$ เป็นค่าฟังก์ชันจุดประสงค์รวม ที่ค่าขึ้นกับ $\bm{x}$
แต่ $L'$  เป็นค่าฟังก์ชันจุดประสงค์รวม ที่ได้เลือก $\bm{x}$ ให้ดีที่สุดแล้ว
และ (2)
$L'$ ไม่ใช่ฟังก์ชันของ $\bm{x}$ แต่เป็นฟังก์ชันของ $\bm{\lambda}_1$.
%เพราะว่า ณ จุดที่ดีที่สุด หมายความว่า ได้ปรับค่า $\bm{x}$ ให้ดีที่สุดแล้ว.
การมองจากปัญหาจากมุมมองของ $\bm{\lambda}_1$
จะทำให้ได้\textit{ปัญหาคู่} ซึ่งเขียนได้เป็น
%พิจารณาบทบาทของ $\bm{\lambda}_1$ ใน $L$ ซึ่ง
\begin{eqnarray}
\underset{\bm{\lambda}_1}{\mathrm{maximize}} & \bm{\lambda}_1^T \bm{b} & 
\nonumber \\
\mbox{subject to} & \bm{\lambda}_1        & \geq \bm{0},
\nonumber \\
& \bm{\lambda}_1^T \bm{A}        & \leq \bm{c}^T.
\nonumber
\end{eqnarray}
สังเกต 
ข้อจำกัด $\bm{\lambda}_1^T \bm{A} \leq \bm{c}^T$
เปรียบเสมือน เงื่อนไขที่ควบคุมไม่ให้ $\bm{\lambda}_1$ มีค่าใหญ่เกินไปจนไปรบกวนจุุดประสงค์ดั้งเดิมในปัญหาปฐม.
% $\min \bm{c}^T \bm{x}$.
%เปรียบเทียบกับสองพจน์แรกใน $L$ จะพบว่า

หากเปรียบเทียบ 
ปัญหาปฐมเป็นเสมือนการหาค่า $\bm{x}$ ที่ทำให้จุดประสงค์เดิมเล็กที่สุด 
แต่การดำเนินการให้จุดประสงค์เดิม $f$ มีขนาดเล็ก ถูกควบคุมด้วยข้อจำกัดดั้งเดิมต่าง ๆ.
ดังนั้น จุดประสงค์เดิมจะเล็กได้เท่าที่ข้อจำกัดเดิมอนุญาต.
ในขณะที่ปัญหาคู่ มองจากอีกด้านของมุม
มองจากจุดที่ปรับ $\bm{x}$ ได้ดีที่สุดแล้ว แต่ต้องการคุมไม่ให้ละเมิดข้อจำกัด.
ปัญหาคู่ จึงเสมือนการหาค่า $\bm{\lambda}_1$ ที่ทำให้จุดประสงค์รวม $L'$ (ซึ่งรวมข้อจำกัดเดิม และปรับ $\bm{x}$ ดีที่สุดแล้ว) 
มีค่ามากที่สุด เพื่อรักษาข้อจำกัดเดิมต่าง ๆ ไว้
แต่การดำเนินการให้ $L'$ ใหญ่ ถูกควบคุมไม่ให้มากเกินไปจนรบกวนจุุดประสงค์ดั้งเดิม.

เมื่อแก้ปัญหาคู่เสร็จ คำตอบจะได้ $\bm{\lambda}_1^\ast$ และทำให้สามารถคำนวณ $\bm{\lambda}_2^\ast = \bm{c} - \bm{A}^T \bm{\lambda}_1^\ast$.
ด้วยความเชื่อมโยงและทฤษฎีบทคารูชคุนทักเกอร์ คำตอบของปัญหาปฐม สามารถพิจารณาได้ดังนี้.
ตรวจดูส่วนประกอบต่าง ๆ นั่นคือ $\bm{\lambda}_1^\ast = [\lambda_{11}, \ldots, \lambda_{1m}]^T$
และ $\bm{\lambda}_2^\ast = [\lambda_{21}, \ldots, \lambda_{2n}]^T$.
ถ้า $\lambda_{1i} > 0$ แปลว่า เงื่อนไขที่ตำแหน่ง $i^{th}$ ทำงาน นั่นคือ $\bm{A}_{i,:} \cdot \bm{x} = b_i$.
ถ้า $\lambda_{2i} > 0$ แปลว่า $x_i = 0$.
ค่าของ $\bm{x}^\ast$ สามารถวิเคราะห์ได้จากสมการที่ได้เหล่านี้.

ตัวอย่างปัญหาเชิงเส้นข้างล่าง
\begin{eqnarray}
\underset{x_1, x_2}{\mathrm{minimize}} & 2 x_2 - x_1 & 
\nonumber \\
\mbox{subject to} & -4 x_1 - x_2 & \geq -2, 
\nonumber \\
& x_1        & \geq 0,
\nonumber \\
& x_2        & \geq 0.
\nonumber
\end{eqnarray}
ซึ่งอยู่ใน\textit{ปฐมรูป} (primal form).
เปรียบเทียบกับแก้ปัญหา
\begin{eqnarray}
\underset{\lambda_1}{\mathrm{maximize}} & -2 \lambda_1 & 
\nonumber \\
\mbox{subject to} & \lambda_1 & \geq 0, 
\nonumber \\
& -4 \lambda_1        & \leq -1,
\nonumber \\
& -\lambda_1        & \leq 2.
\nonumber
\end{eqnarray}
ซึ่งเป็น\textit{รูปคู่} (dual form) ของปัญหาข้างต้น.

เมื่อแก้ปัญหาคู่เสร็จ ผลลัพธ์คือ $\lambda_1^\ast = 0.25$.
ดังนั้น $\bm{\lambda}_2^\ast = [-1, 2]^T - [-4, -1]^T \cdot 0.25$
$= [0, 2.25]^T$. 
เนื่องจาก $\lambda_{22} > 0$ ดังนั้น $x_2 = 0$.
และเนื่องจาก $\lambda_1 > 0$ ดังนั้น $-4 x_1 - x_2 = -2$.
เมื่อวิเคราะห์ผลทั้งหมดรวมกันจะได้ว่า $\bm{x}^\ast = [0.5, 0]^T$.
รูป~\ref{fig: ex opt duality}
แสดงภาพของภาวะคู่กันในตัวอย่างนี้.

\begin{figure}[H]
	\begin{center}
		\begin{tabular}{cc}
			\includegraphics[width=0.45\columnwidth]{02Background/opt/primal.png}
			&
			\includegraphics[width=0.45\columnwidth]{02Background/opt/dual.png}
		\end{tabular} 		
	\end{center}
	\caption[ตัวอย่างภาวะคู่กัน]{
		ตัวอย่างภาวะคู่กัน.
		ภาพซ้าย แสดงปัญหาปฐม (ปัญหาค่าน้อยที่สุด) ด้วยค่าฟังก์ชันจุดประสงค์ในปริภูมิของตัวแปร $\bm{x}$.
		ค่าฟังก์ชันจุดประสงค์ $f(\bm{x}) = 2 x_2 - x_1$ แสดงด้วยวาดภาพคอนทัวร์.
		เส้นสีน้ำเงิน แสดงขอบเขตของข้อจำกัด $-4 x_1 - x_2 \geq -2$ (เส้นแทน $-4 x_1 - x_2 = -2$).
		เส้นสีเขียว แสดงขอบเขตของข้อจำกัด $x_2 \geq 0$  (เส้นแทน $x_2 = 0$).
		เส้นสีฟ้าเขียว แสดงขอบเขตของข้อจำกัด $x_1 \geq 0$  (เส้นแทน $x_1 = 0$).
		พื้้นที่แรเงาสีเหลือง แสดงบริเวณค่าที่ยอมรับได้ (ผ่านข้อจำกัดทั้งสาม).
		จุดสีแดงคือ $\bm{x}^\ast$.
		ภาพขวา แสดงปัญหาคู่ (ปัญหาค่ามากที่สุด) ด้วยแกนตั้งเป็นค่าฟังก์ชันจุดประสงค์ของปัญหาคู่ และแกนนอนแสดงค่า $\lambda$.
		เส้นสีดำทึบ คือ ค่าฟังก์ชันจุดประสงค์ของปัญหาคู่ $L'(\lambda_1) = -2\lambda_1$.
		เส้นประ แสดงขอบเขตของข้อจำกัด $\lambda_1 \geq 0$ (เส้นสีเขียว)
		และข้อจำกัด $-4 \lambda_1 \leq -1 \equiv \lambda_1 \geq 0.25$ 
		และ $-\lambda_1 \leq 2 \equiv \lambda_1 \geq -2$ (ทั้งคู่แสดงด้วยเส้นสีฟ้าเขียว).
		พื้นที่แรเงาสีเหลือง แสดงบริเวณค่าที่ยอมรับได้ (ผ่านข้อจำกัดทั้งสาม).
		จุดสีแดง (ในทั้งสองภาพ) แทนคำตอบที่ถูกต้อง.
		นั่นคือ ปัญหาปฐม $x_1^\ast = 0.5,\; x_2^\ast = 0$
		และปัญหาคู่ $\lambda_1^\ast = 0.25$.
	}
	\label{fig: ex opt duality}
\end{figure}

จากปัญหาเชิงเส้นข้างล่าง 
จงแปลงเป็นรูปคู่ แก้ปัญหาทั้งในรูปปฐม และรูปคู่ และตรวจสอบคำตอบ.
\begin{eqnarray}
\underset{x_1, x_2}{\mathrm{minimize}} & 2 x_2 + 2 x_1 & 
\nonumber \\
\mbox{subject to} & -4 x_1 - x_2 & \geq -2, 
\nonumber \\
& x_1        & \geq 0,
\nonumber \\
& x_2        & \geq 0.
\nonumber
\end{eqnarray}

\textit{หมายเหตุ}
วิธีลงเกรเดียนต์ และวิธีลงโทษสามารถใช้ช่วยหาคำตอบได้
%(สังเกตผลและพฤติกรรมการทำงาน รวมถึงความยากง่ายในการปรับแต่ง เพื่อให้ได้คำตอบที่ถูกต้อง)
แต่ปัญหาเชิงเส้น เป็นกลุ่มปัญหาที่ได้รับการศึกษาอย่างกว้างขวาง
และมีขั้นตอนวิธีต่าง ๆ ที่ได้พัฒนาขึ้นเฉพาะ ซึ่งมีประสิทธิภาพมากกว่าวิธีลงเกรเดียนต์มาก 
เช่น วิธีซิมเพล็กซ์ (simplex method) 
และวิธีจุดภายใน (interior-point method).
เนื้อหาของปัญหาการหาค่าดีที่สุดสำหรับปัญหาเชิงเส้น เกินขอบเขตของหนังสือเล่มนี้
ผู้อ่านที่สนใจสามารถศึกษาเพิ่มเติมได้จาก \cite{NashSofer1996}.

\end{Exercise}

%\subsubsection{ความน่าจะเป็น}
%จากเนื้อหาในหัวข้อ~\ref{sec: probability} แบบฝึกหัดต่อไปนี้
%เป็นตัวอย่างสำหรับการนำทฤษฎีความน่าจะเป็นไปเขียนโปรแกรม.

\subsubsection{การคำนวณเชิงเลข}
การเขียนโปรแกรมคำนวณเชิงเลข
มีปัจจัยด้านข้อจำกัดที่ต้องคำนึงถึง.
แบบฝึกหัดต่อไปนี้ แนะนำบางประเด็นที่ควรคำนึงถึง
เวลานำทฤษฎีทางคณิตศาสตร์มาเขียนโปรแกรม.

\begin{Exercise}
	\label{ex: num sampling effect}
	
	โปรแกรมข้างล่างนี้ใช้วาดรูป~\ref{fig: num sampling effect}.
	\begin{Verbatim}[fontsize=\small]
	x = np.linspace(0, 100, 5)
	plt.plot(x, np.sin(x))
	\end{Verbatim}
	จงวิเคราะห์และอธิบายว่า
	ทำไมรูปที่ได้ไม่เห็นเป็นรูปโค้งขึ้นลง เช่น รูปของค่าพังชั่นไซน์ที่คุ้นเคย
	
	%
	\begin{figure}[H]
		\begin{center}
			\includegraphics[width=3.0in]
			{02Background/num/code_num_sampling.png}
		\end{center}
		\caption[ผลการวาดกราฟฟังก์ชันไซน์ ที่ดูต่างจากความคาดหวัง]{ผลจากคำสั่ง \texttt{plt.plot(x, np.sin(x))} จากแบบฝึกหัด~\ref{ex: num sampling effect}.}
		\label{fig: num sampling effect}
	\end{figure}
	%
	
\end{Exercise}


\begin{Exercise}
	\label{ex: num round off}
	จากโปรแกรมและผลการรันดังแสดงข้างล่างนี้
	จงอภิปรายว่าทำไมมี $x$ บางตัวไม่เท่ากับ $7 \cdot y$ ทั้ง ๆ ที่ $y = x/7$.
	โปรแกรมคำนวณ
	\begin{Verbatim}[fontsize=\small]
x = np.linspace(1,10, 20)
y = x/7
print(x == 7*y)
	\end{Verbatim}
	และผลลัพธ์ที่ได้คือ
	\begin{Verbatim}[fontsize=\small]
[ True  True  True  True  True  True  True  True  True  True  True  True
True False False  True  True  True  True  True]
	\end{Verbatim}
ทำไม จึงมีผลบางค่าที่เป็น \verb|False| ทั้ง ๆ ที่ $\frac{x}{7} \cdot 7$ มีค่าเท่ากับ $x$ ?	
จงวิเคราะห์และอธิบายผลของ \verb|x == 7*(x/7)| กับ \verb|x == 7*x/7| ประกอบ
พร้อมอภิปรายประเด็นที่ได้เรียนรู้นี้
กับสถานการณ์ที่อาจจะเกิดขึ้น.
\end{Exercise}

\begin{Exercise}
\label{ex: num plot Inf}
จากคณิตศาสตร์ $\log(\exp(x)) = x$
โปรแกรมข้างล่างนี้
\begin{Verbatim}[fontsize=\small]
xs = np.linspace(100, 800)
plt.plot(xs, xs/xs, 'r', linewidth=4)
plt.plot(xs, xs/np.log(np.exp(xs)), 'b', linewidth=1.5)
\end{Verbatim}
วาดกราฟของ $x/x$ เปรียบเทียบกับ $x/\log(\exp(x))$ 
โดย $x$ มีค่าตั้งแต่ $100$ ถึง $799$
ซึ่ง ทั้ง $x/x$ และ $x/\log(\exp(x))$ ก็มีค่าเท่ากับ $1$ เมื่อ $x > 0$.
ดังนั้น ผลลัพธ์น่าจะเห็นเส้นตรงแนวนอนที่ค่าหนึ่ง เท่าเดิมคงที่ตลอดช่วง.
แต่ผลที่ได้เป็นดังแสดงในรูป~\ref{fig: num infty effect}.
จงสืบกรณีนี้
อธิบายสิ่งที่เกิดขึ้น
และอภิปรายผลที่อาจเกิดขึ้นในทางปฏิบัติ
จากประเด็นที่ได้เรียนรู้.

\textit{คำใบ้}
ตรวจดูค่า \verb|np.exp(x)|
ที่ค่า \verb|x| ต่าง ๆ
และลองสืบค้นข้อมูลเรื่อง IEEE754 จากอินเตอร์เนต.

	%
\begin{figure}[H]
	\begin{center}
		\includegraphics[width=2.0in]
		{02Background/num/infty.png}
	\end{center}
	\caption[ผลจากการวาดกราฟ ซึ่งกราฟที่ได้ดูแปลกจากที่คาด]{ผลจากการวาดกราฟ $x/x$ (เส้นสีแดงหนา) และกราฟ $x/\log(\exp(x))$ 
	(เส้นสีน้ำเงินบาง) โดย $x$ มีค่าตั้งแต่ $100$ ถึง $799$. เส้นกราฟ อาจดูต่างจากที่คาด. แบบฝึกหัด~\ref{ex: num plot Inf}.}
	\label{fig: num infty effect}
\end{figure}
%

\end{Exercise}

\begin{Exercise}
	\label{ex: num nan}
	
	\textbf{ฟังก์ชันซอฟต์แมกซ์} (softmax function)
	\index{english}{softmax}
	\index{english}{function!softmax}
	\index{thai}{ฟังก์ชันซอฟต์แมกซ์}
	\index{thai}{ฟังก์ชัน!ซอฟต์แมกซ์}
	\index{thai}{ซอฟต์แมกซ์}
	ซึ่งมักใช้สัญลักษณ์ $\mathrm{softmax}: \mathbb{R}^n \mapsto \mathbb{R}^n$ นิยามว่า
	เมื่อ อินพุตของ\textit{ซอฟต์แมกซ์} $\bm{v} = [v_1, \ldots, v_n]^T$
	แล้วผลลัพธ์ $\bm{u} = \mathrm{softmax}(\bm{v})$ โดย
	\begin{eqnarray}
	u_i
	= \frac{\exp(v_i)}{\sum_{j=1}^n \exp(v_j)}
	\nonumber 
	\end{eqnarray}
	สำหรับ $i = 1, \ldots, n$ เมื่อ $u_i$ เป็นส่วนประกอบของ $\bm{u}$.
ฟังก์ชันซอฟต์แมกซ์นิยมใช้อย่างมาก ในงานรู้จำรูปแบบ.
โปรแกรมข้างล่างนี้ เขียนการคำนวณฟังก์ชันซอฟต์แมกซ์แบบง่าย ๆ
\begin{Verbatim}[fontsize=\small]
def softmax(v):
    ev = np.exp(v)
    return ev/np.sum(ev)
\end{Verbatim}

จงทดสอบฟังก์ชันนี้ ด้วยค่า \verb|v| ต่าง ๆ
เช่น \verb|softmax(np.array([1, 2, 5]))|
%
%\verb|softmax(np.array([-1, -2, -5]))|
%\verb|softmax(np.array([1, 0, -5]))|
%\verb|softmax(np.array([-1, 0, -5]))|
(ลองผสมค่าหลาย ๆ แบบ ทั้งค่าบวก ค่าลบ และศูนย์)
อภิปรายการพฤติกรรมของฟังก์ชันซอฟต์แมกซ์.
%
แล้วลองทดสอบอีกครั้งด้วยค่าขนาดใหญ่ เช่น
\verb|softmax(np.array([1000, 2000, 5000]))|
สังเกตผลลัพธ์ที่ได้
อภิปรายถึงปัญหาและสาเหตุ พร้อมเสนอวิธีแก้ปัญหา.

\textit{คำใบ้}
ปัญหาอยู่ที่ไหน 
วิธีแก้อาจใช้คณิตศาสตร์ไปช่วยบรรเทาสาเหตุ.
(หัวข้อ~\ref{sec: ann exercises}
อภิปรายวิธีเขียนโปรแกรม
ฟังก์ชันซอฟต์แมกซ์ที่\textit{ทนทาน} (robust)
สำหรับใช้งานในทางปฏิบัติ.)

\end{Exercise}

%LATER
%\begin{Exercise}
%	\label{ex: num underflow}
	
%	\textit{ความน่าจะเป็น}เป็นทฤษฎีที่ใช้งานได้อย่างกว้างขวาง
%	แต่ค่า\textit{ความน่าจะเป็น}จะอยู่ระหว่างศูนย์ถึงหนึ่ง
%	และผลรวมของ\textit{ความน่าจะเป็น}ของทุกเหตุการณ์จะเป็นหนึ่ง.
%	ดังนั้นสำหรับ เรื่องที่มีผลลัพธ์ได้หลายรูปแบบมาก
%	แต่ละรูปแบบของผลลัพธ์อาจจะมีค่า\textit{ความน่าจะเป็น}ที่ต่ำมาก ๆ.
	
	
%\end{Exercise}

