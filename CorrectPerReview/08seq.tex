\chapter{แบบจำลองสำหรับข้อมูลเชิงลำดับ}
\label{chapter: RNN}

\begin{Parallel}[c]{0.45\textwidth}{0.43\textwidth}
%\selectlanguage{english}
\ParallelLText{
``Failure comes only when we forget our ideals and objectives and principles.''
\begin{flushright}
---Jawaharlal Nehru
\end{flushright}
}
%\selectlanguage{thai}
\ParallelRText{
		``ความล้มเหลวมาก็แต่เฉพาะตอนที่เราลืมอุดมการณ์ เป้าหมาย และหลักการของเรา.''
\begin{flushright}
		---ชวาหะร์ลาล เนห์รู
\end{flushright}
}
\end{Parallel}
\index{english}{words of wisdom!Jawaharlal Nehru}
\index{english}{quote!principles}

รูปแบบของข้อมูลในเนื้อหาที่ผ่าน ๆ มา เป็นลักษณะที่เป็นอิสระในตัวเอง 
นั่นคือ แต่ละจุดข้อมูลมีความหมายสมบูรณ์แบบในตัวเอง
หรือหากเจาะจงลงไป อาจกล่าวว่า 
ที่ผ่านมา แต่ละจุดข้อมูลเป็นอิสระต่อกันและมีการแจกแจงเหมือนกัน ที่เรียกว่า \textit{ไอ.ไอ.ดี.} (independent and identically distributed คำย่อ i.i.d.).
\index{english}{i.i.d.}\index{thai}{ไอ.ไอ.ดี.}\index{english}{independent and identically distributed}
อย่างไรก็ตาม มีข้อมูลหลายประเภทที่จุดข้อมูลต่าง ๆ มีความสัมพันธ์ระหว่างกัน.
เนื้อหาในบทนี้อภิปรายแนวทางและแบบจำลอง
ที่ออกแบบมาสำหรับการทำงานอย่างมีประสิทธิภาพกับข้อมูลเชิงลำดับ.

\section{ข้อมูลเชิงลำดับ}
\label{sec: seq data}
ข้อมูลประเภทที่จุดข้อมูลมีความสัมพันธ์เชิงลำดับระหว่างกัน จะเรียกว่า \textbf{ข้อมูลเชิงลำดับ} (sequential data).
\index{thai}{ข้อมูลเชิงลำดับ}\index{english}{sequential data}
นั่นคือ แม้ว่าจุดข้อมูลจะมีค่าเหมือนกัน แต่หากลำดับที่ปรากฏต่างกัน ก็อาจทำให้ความหมายต่างกัน
หรือแม้จุดข้อมูลหนึ่งจะมีค่าเท่าเดิมและปรากฏที่ตำแหน่งเดิม แต่หากจุดข้อมูลอื่น ๆ ในลำดับเปลี่ยนค่า ก็อาจจะทำให้ความหมายนั้นเปลี่ยนไปได้.

ข้อมูลหลากหลายชนิด เป็นข้อมูลเชิงลำดับ
และงานการรู้จำรูปแบบกับข้อมูลเชิงลำดับ ก็มีหลากหลายประเภท
เช่น 
%การทำนายปริมาณน้ำฝนต่อวัน (precipitation forecast) ที่การรู้ปริมาณน้ำฝนของวันก่อนหน้าจะช่วยอย่างมากในทำนาย,
การทำนายข้อมูลทางการเงิน (financial data prediction) 
ซึ่งอาจรับอินพุตเป็นลำดับของราคาปิดของหุ้นในวันก่อน ๆ และทำนายราคาปิดของวันถัดไป,
การรู้จำเสียงพูด (speech recognition)
ที่รับอินพุตเป็นสัญญาณเสียง (ลำดับค่าแอมพลิจูดต่อเวลา) และให้เอาต์พุตเป็นลำดับของคำ,
%ที่ความหมายของข้อมูล การที่จะบอกว่าสัญญาณคลื่นไฟฟ้าหัวปกติ หรือผิดปกติอย่างไร 
%ขึ้นกับค่าของจุดข้อมูลแต่ละจุด และลำดับเวลาที่มันปรากฎด้วย.
%หากนำค่าระดับสัญญาณไฟฟ้าที่วัดได้ แล้วสลับลำดับเวลา จะทำให้ความหมายผิดเพี้ยนไป.
%ข้อมูลเสียงพูด ก็เป็นข้อมูลเชิงลำดับ
%รูปแบบของเสียงที่รับรู้ จะขึ้นกับทั้งระดับเสียงหรือแอมพลิจูดของแต่ละจุดข้อมูล และลำดับเวลาของมัน.
%การรู้จำคอร์ดดนตรี (chord progression recognition)
%ที่อาจรับอินพุตเป็นสัญญาณเสียงของเพลง และให้เอาต์พุตเป็นลำดับของคอร์ดดนตรี,
%
%chord progression recognition
ระบบแต่งเพลงอัตโนมัติ (music generation)
ที่อาจรับอินพุตเป็นประเภทของเพลง และให้เอาต์พุตเป็นลำดับของโน๊ตดนตรี,
การรู้จำรูปแบบสัญญาณคลื่นไฟฟ้าหัวใจ (ECG pattern recognition)
ที่รับอินพุตเป็นสัญญาณคลื่นไฟฟ้าหัวใจ (ลำดับแอมพลิจูดหลาย ๆ ช่องสัญญาณต่อเวลา) และอาจจะให้เอาต์พุตเป็นค่าระบุว่า 
ปกติหรือผิดปกติ หรืออาจระบุตำแหน่งและชนิดที่ผิดปกติออกมาด้วย,
ระบบวิเคราะห์ลำดับดีเอ็นเอ (DNA sequence analysis)
ที่รับอินพุตเป็นลำดับของชนิดฐานนิวคลีโอไทด์ และอาจจะให้เอาต์พุตเป็นตำแหน่งต่าง ๆ ในลำดับที่สัมพันธ์กับโปรตีนที่สนใจ,
การรู้จำกิจกรรมจากวีดีโอ (video activity recognition)
ที่รับอินพุตเป็นข้อมูลวีดีโอ (ลำดับของภาพต่าง ๆ ตามเวลา) และให้เอาต์พุตเป็นฉลากของกิจกรรม,
การจำแนกอารมณ์ (sentiment classification)
ที่อาจรับอินพุตเป็นข้อความ (ลำดับของคำต่าง ๆ) และให้เอาต์พุตเป็นคะแนนประเมินความพอใจ,
การแปลภาษาอัตโนมัติ (machine translation) 
ที่รับอินพุตเป็นข้อความในภาษาหนึ่ง (ลำดับของคำในภาษาต้นทาง) และให้เอาต์พุตเป็นข้อความในอีกภาษาหนึ่ง (ลำดับของคำในภาษาเป้าหมาย).
%
%name entity recognition
%
%part-of-speech tagging 
%
%question answering 
สำหรับข้อมูลเชิงลำดับบางชนิด ตัวลำดับอาจเป็นตัวแทนของเวลา เช่น สัญญาณเสียง
หรืออาจเป็นเพียงลำดับที่ไม่ได้เกี่ยวกับเวลาก็ได้ เช่น ลำดับของคำต่าง ๆ ในข้อความ.
อย่างไรก็ตาม เพื่อความสะดวก เนื้อหาในบทนี้อาจใช้คำว่า เวลา ในการอ้างถึงลำดับ.
รูป~\ref{fig: seq sequential pattern recognition tasks} แสดงตัวอย่างข้อมูลเชิงลำดับ และตัวอย่างภาระกิจการรู้จำรูปแบบที่เกี่ยวข้อง.

หากจำแนกภาระกิจออกตามลักษณะอินพุตและเอาต์พุต การรู้จำรูปแบบเชิงลำดับ อาจจำแนกได้ดังนี้.
(1)
ประเภทแรกคือ ภาระกิจที่อินพุตเป็นข้อมูลลำดับ $\{\bm{x}_n\}_{n=1,\ldots, N}$ เมื่อ $N$ คือจำนวนจุดข้อมูลทั้งหมดในลำดับ 
แต่เอาต์พุตไม่ได้เป็นข้อมูลลำดับ $y \in \mathbb{R}^K$ เมื่อ $K$ คือจำนวนมิติของเอาต์พุต.
ในรูป~\ref{fig: seq sequential pattern recognition tasks} 
ตัวอย่างในกลุ่มนี้คือ การทำนายข้อมูลทางการเงิน, การรู้จำรูปแบบสัญญาณคลื่นไฟฟ้าหัวใจ, การรู้จำกิจกรรมจากวีดีโอ และการจำแนกอารมณ์.
ระบบวิเคราะห์ลำดับดีเอ็นเอ ก็อาจจัดอยู่ในกลุ่มนี้ หากให้เอาต์พุตออกมาเป็นค่าดัชนีของจุดเริ่มต้นและจุดจบของส่วนลำดับที่สนใจ.
(2) ประเภทสองคือ
ภาระกิจที่อินพุตเป็นข้อมูลลำดับ $\{\bm{x}_n\}_{n=1,\ldots, N}$  
และเอาต์พุตก็เป็นข้อมูลลำดับ $\{\bm{y}_n\}_{n=1,\ldots, N}$ โดยทั้งสองลำดับมีจำนวนจุดข้อมูลในลำดับเท่ากัน.
รูป~\ref{fig: seq sequential pattern recognition tasks} ไม่ได้แสดงตัวอย่างของภาระกิจในกลุ่มนี้.
ตัวอย่างภาระกิจในกลุ่มนี้ ได้แก่ การระบุหมวดคำ (Part-Of-Speech Tagging) 
ที่วิเคราะห์ข้อความแล้วระบุหมวดคำของคำทุกคำในข้อความ ว่าอยู่ในหมวดคำใดในกลุ่ม (ซึ่งมักประกอบด้วย 
คำนาม, คำกริยา, คำคุณศัพท์, คำกริยาวิเศษณ์, คำบุพบท, คำสันธาน, คำสรรพนาม, คำอุทาน และคำนำหน้านาม 
%noun, verb, article, adjective, preposition, pronoun, adverb, conjunction และ interjection 
สำหรับภาระกิจการระบุหมวดคำในภาษาอังกฤษ)
\index{english}{Part-Of-Speech Tagging}
\index{thai}{การระบุหมวดคำ}
%
และการรู้จำชื่อเฉพาะ (Named-Entity Recognition) 
ที่ต้องการระบุว่าคำไหนบ้างในข้อความที่เป็นชื่อเฉพาะ และเป็นชื่อเฉพาะของสิ่งประเภทใด (ซึ่งมักกำหนดประเภทที่สนใจไว้ เช่น ชื่อคน, ชื่อองค์กร หน่วยงาน หรือบริษัท, ชื่อตราสินค้า, ชื่อสถานที่, เวลา, ปริมาณหรือจำนวน)
เป็นต้น.
\index{english}{Named-Entity Recognition}
(3)
ประเภทสามคือ
ภาระกิจที่อินพุตเป็นข้อมูลลำดับ $\{\bm{x}_n\}_{n=1,\ldots, N}$  
และเอาต์พุตก็เป็นข้อมูลลำดับ $\{\bm{y}_n\}_{n=1,\ldots, M}$ เมื่อ $M$ เป็นจำนวนจุดข้อมูลในลำดับของเอาต์พุต แต่ลำดับทั้งสองอาจมีจำนวนจุดข้อมูลในลำดับไม่เท่ากัน.
ตัวอย่างที่แสดงในรูป~\ref{fig: seq sequential pattern recognition tasks}
คือ การแปลภาษาอัตโนมัติ ที่ข้อความของภาษาต้นทาง อาจมีจำนวนคำต่างจากข้อความของภาษาปลายทาง.
(4)
ประเภทสี่คือ
ภาระกิจที่อินพุตไม่ใช่ข้อมูลลำดับ แต่เอาต์พุตเป็นข้อมูลลำดับ.
ตัวอย่างที่แสดงในรูป~\ref{fig: seq sequential pattern recognition tasks}
คือ ระบบแต่งเพลงอัตโนมัติ ที่อินพุตอาจจะเป็นเวกเตอร์ หรืออาจจะเป็นค่าสเกล่าร์ 
แต่ให้เอาต์พุตออกมาเป็นลำดับของ\atom{โน๊ต}ดนตรี.
สุดท้าย หากภาระกิจที่ทั้งอินพุตและเอาต์พุตไม่ใช่ข้อมูลลำดับ ภาระกิจนี้ไม่จัดอยู่ในการรู้จำรูปแบบเชิงลำดับ 
และโดยทั่วไป ภาระกิจประเภทนี้จะสามารถดำเนินการได้ โดยวิธีการต่าง ๆ ที่ได้อภิปรายไปในบทก่อน ๆ.

%
\begin{figure}
	\begin{center}
	\includegraphics[width=0.9\textwidth]{08seq/sequential_data1.png}	
	\caption[ตัวอย่างภาระกิจการรู้จำรูปแบบเชิงลำดับ]{ตัวอย่างภาระกิจการรู้จำรูปแบบเชิงลำดับ.
ภาระกิจ (จากแถวบนลงล่าง) ได้แก่ การทำนายทางการเงิน อินพุตเป็นราคาปิดต่อวัน, 
การรู้จำเสียงพูด อินพุตเป็นสัญญาณเสียง ที่เป็นข้อมูลแอมพลิจูดต่อเวลา, 
ระบบแต่งเพลงอัตโนมัติ เอาต์พุตเป็นลำดับของโน๊ตดนตรี (โดยอินพุตอาจเป็นค่าสเกล่าร์หรือเวกเตอร์ ที่เป็นตัวแทนระบุลักษณะของเพลง), 
%ซึ่งแม้จะเป็นเวกเตอร์ แต่ไม่ใช่ข้อมูลลำดับ ดูหัวข้อ~\ref{sec: convapp GAN} ประกอบ สำหรับแบบจำลองก่อกำเนิด),
การรู้จำรูปแบบสัญญาณคลื่นไฟฟ้าหัวใจ
อินพุตเป็นลำดับแอมพลิจูดหลาย ๆ ช่องสัญญาณต่อเวลา,
การวิเคราะห์ลำดับดีเอ็นเอ อินพุตเป็นลำดับของชนิดฐานนิวคลีโอไทด์,
การรู้จำกิจกรรมจากวีดีโอ อินพุตเป็นภาพต่อเวลา,
การจำแนกอารมณ์ อินพุตเป็นลำดับคำ
และการแปลงภาษาอัตโนมัติ ที่ทั้งอินพุตและเอาต์พุตต่างก็เป็นข้อมูลลำดับของคำ.
สังเกตภาระกิจอาจเกี่ยวข้องกับข้อมูลเชิงลำดับ โดยรับอินพุตเป็นข้อมูลเชิงลำดับ หรือให้เอาต์พุตออกมาเป็นข้อมูลเชิงลำดับ หรือทั้งสองอย่าง.
ข้อมูลเชิงลำดับ อาจมีลำดับที่มีความหมายตามลำดับเวลาจริง ๆ เช่น ลำดับราคาปิดต่อวัน, ลำดับแอมพลิจูดต่อเวลา, ลำดับโน๊ตดนตรีต่อเวลา
และลำดับภาพต่อเวลา
หรืออาจมีลำดับที่ไม่ได้มีความหมายกับเวลา เช่น ลำดับของชนิดฐานนิวคลีโอไทด์ และลำดับของคำในข้อความ. 
}
	\label{fig: seq sequential pattern recognition tasks}
	\end{center}
\end{figure}
%

ข้อมูลเชิงลำดับ อาจแบ่งออกได้เป็นสองประเภท คือ ข้อมูลเชิงลำดับแบบคงที่  กับ 
ข้อมูลเชิงลำดับแบบไม่คงที่.
ข้อมูลเชิงลำดับแบบคงที่ (stationary sequential data)
\index{english}{sequential data!stationary}
\index{english}{stationary sequential data}
\index{thai}{ข้อมูลเชิงลำดับแบบคงที่}
ที่แม้ค่าต่าง ๆ ของจุดข้อมูลอาจผันแปรไปตามเวลา แต่การแจกแจงเบื้องหลังลำดับข้อมูลนั้นคงที่ ไม่ได้มีการเปลี่ยนแปลงตามเวลา.
ส่วนกรณีของข้อมูลเชิงลำดับแบบไม่คงที่ (nonstationary sequential data) การแจกแจงเบื้องหลังลำดับข้อมูลนั้นมีการเปลี่ยนแปลงตามเวลาด้วย.
หากอธิบายง่าย ๆ อาจเปรียบเทียบจาก 
ตัวอย่างของข้อมูลปริมาณน้ำฝนในแต่ละวัน ตลอดหลาย ๆ ปี โดยที่ระยะเวลาเหล่านั้นฟ้าฝนตกต้องตามฤดูกาล
เป็นตัวอย่างของข้อมูลเชิงลำดับแบบคงที่.
ส่วนตัวอย่างของข้อมูลปริมาณน้ำฝนในแต่ละวัน ในหลาย ๆ ปีให้หลังมานี้ 
ซึ่งสังเกตได้ชัดว่าฟ้าฝนตกผิดเพี้ยนจากฤดูกาลที่คุ้นเคย.
การเปลี่ยนแปลงเกิดที่ตัวของฤดูกาลเองอย่างมาก
ที่อาจจะเกิดจากหลาย ๆ สาเหตุรวมถึงภาวะโลกร้อนสภาพภูมิอากาศเปลี่ยนแปลง.
กรณีหลังนี้ เป็นตัวอย่างของข้อมูลเชิงลำดับแบบไม่คงที่
ซึ่งการเปลี่ยนแปลงตามเวลาของข้อมูล
เกิดจากกระบวนการเบื้องหลังที่มีการเปลี่ยนแปลงตัวกระบวนการไปตามเวลาด้วย.
%หรือในกรณีของภาษา 
%ข้อมูลเชิงลำดับแบบคงที่ คล้ายการวิเคราะห์ข้อความในภาษาไทย
%ส่วนข้อมูลเชิงลำดับแบบไม่คงที่ คล้ายการวิเคราะห์ข้อความในภาษาไทย 
%โดยคำนึงถึงวิวัฒนาการของภาษาและการเปลี่ยนแปลงของสังคม 
%ซึ่งมีผลต่อคำต่าง ๆ ที่เลือกใช้. 
%
เนื้อหาในบทนี้ใช้สมมติฐานของกรณีข้อมูลเชิงลำดับแบบคงที่เป็นหลัก ยกเว้นแต่จะระบุเป็นอื่น.

การสร้างแบบจำลองสำหรับข้อมูลเชิงลำดับ สามารถทำได้หลายแนวทาง.
หัวข้อ~\ref{sec: Markov model} และ~\ref{sec: HMM} อภิปรายแนวทางการใช้ความน่าจะเป็นด้วยแบบจำลองมาร์คอฟ
และแบบจำลองมาร์คอฟซ่อนเร้น. 
แนวทางของโครงข่ายประสาทเวียนกลับ จะถูกอภิปรายในหัวข้อ~\ref{sec: RNN}.

\section{แบบจำลองมาร์คอฟ}
\label{sec: Markov model}
\index{english}{Markov model}
\index{thai}{แบบจำลองมาร์คอฟ}	

การสร้างแบบจำลองสำหรับข้อมูลเชิงลำดับ
โดยรองรับความสัมพันธ์เชิงลำดับระหว่างลำดับต่าง ๆ อย่างสมบูรณ์
อาจทำให้การคำนวณทำได้ยาก.
ตัวอย่างเช่น 
สำหรับภารกิจการทำนายค่าในอนาคต
นั่นคือ การทำนายจุดข้อมูลลำดับต่อไป $\bm{x}_{T+1}$ ของข้อมูลชุดลำดับ $\{\bm{x}_t\}_{t=1,\ldots, T}$.
การใช้แบบจำลองความน่าจะเป็น%
\footnote{หรือความหนาแน่นความน่าจะเป็น กรณี\textit{ตัวแปรสุ่มต่อเนื่อง}}
ด้วย
$p(\bm{x}_1, \bm{x}_2, \ldots, \bm{x}_T)$ 
อาจอาศัยทฤษฎีของเบส์ (หัวข้อ~\ref{sec: cond prob}) 
เพื่อประมาณค่าในอนาคตด้วย
$p(\bm{x}_{T+1}|\bm{x}_1, \bm{x}_2,$ $\ldots, \bm{x}_T) = p(\bm{x}_1, \bm{x}_2, \ldots, \bm{x}_T, \bm{x}_{T+1})/p(\bm{x}_1, \bm{x}_2, \ldots, \bm{x}_T)$.
ค่า $p(\bm{x}_1, \bm{x}_2, \ldots, \bm{x}_T)$ เอง ก็ประมาณได้ยากในทางปฏิบัติ
และถึงแม้จะรู้ แต่ค่าของ $p(\bm{x}_1, \bm{x}_2, \ldots$ $,\bm{x}_T, \bm{x}_{T+1})$ ยิ่งยากกว่าที่จะประมาณ
หากยังใช้แบบจำลองที่รองรับความสัมพันธ์เชิงลำดับระหว่างลำดับต่าง ๆ อย่างสมบูรณ์.

แนวทางการแก้ปัญหาเชิงคำนวณหลาย ๆ ครั้ง
ที่\textit{การคำนวณค่าอย่างแม่นตรง} (exact calculation) ไม่สามารถทำได้หรือทำได้ยาก
การประมาณหรือการเพิ่มเงื่อนไขที่สมเหตุสมผล มักถูกนำมาใช้.
\index{english}{Approaches to exact calculation issues!approximation}
\index{english}{Approaches to exact calculation issues!constraining}
วิธีหนึ่งคือ เลือกการประมาณที่สุดขอบ เช่น การประมาณโดยไม่สนใจความสัมพันธ์เชิงลำดับเลย (ใช้สมมติฐาน \textit{ไอ.ไอ.ดี.})
\index{english}{i.i.d.}\index{thai}{ไอ.ไอ.ดี.}
ซึ่งวิธีนี้ทำให้เราสามารถเลือกแบบจำลองต่าง ๆ ที่ไม่มีความสามารถเชิงลำดับ เช่น โครงข่ายประสาทเทียม (บทที่~\ref{chapter: ANN}) มาใช้ก็ได้.
แต่การประมาณที่สุดขอบเช่นนี้ เท่ากับเราทิ้งสารสนเทศความสัมพันธ์เชิงลำดับไปทั้งหมดเลย.
เราไม่สามารถใช้ประโยชน์จากสารสนเทศเชิงลำดับได้เลย.

ยืดหยุ่นขึ้นมาบ้าง \textbf{แบบจำลองมาร์คอฟ} (Markov models หรืออาจเรียก Markov chain)
ประมาณความสัมพันธ์เชิงลำดับโดยจำกัดเฉพาะลำดับที่ผ่านมาไม่กี่ลำดับ.
จุดสำคัญ คือ (1) แบบจำลองมาร์คอฟ จำกัดความสัมพันธ์เชิงลำดับ โดยจำกัดให้ค่าของจุดข้อมูลมีความสัมพันธ์เฉพาะกับค่าของจุดข้อมูลลำดับก่อนหน้า.
จุดข้อมูลลำดับหลังไม่จำเป็น.
นั่นคือ $p(\bm{x}_t| \bm{x}_1, \bm{x}_2, \ldots, \bm{x}_{t-1}, \bm{x}_{t+1}, \ldots, \bm{x}_T)$
$=p(\bm{x}_t| \bm{x}_1, \bm{x}_2, \ldots,$ $\bm{x}_{t-1})$.
(2) แบบจำลองมาร์คอฟ จำกัดความสัมพันธ์เชิงลำดับกลับไปเพียงจำนวนลำดับที่กำหนดเท่านั้น.
ไม่ได้ย้อนกลับไปจนถึงจุดข้อมูลที่ลำดับแรกสุดทุกครั้ง.
นั่นคือ แบบจำลองมาร์คอฟประมาณ 
$p(\bm{x}_{T+1}|\bm{x}_1, \bm{x}_2,$ $\ldots, \bm{x}_T) 
=
p(\bm{x}_{T+1}|\bm{x}_{T+1-\tau}, \ldots, \bm{x}_T)$
เมื่อ $\tau$ เป็นจำนวนจุดข้อมูลในลำดับก่อนหน้าที่แบบจำลองมาร์คอฟถือว่ามีความสัมพันธ์.
อภิมานพารามิเตอร์ $\tau$ ที่นิยมเลือกใช้คือ $\tau = 1$
ซึ่งแบบจำลองมาร์คอฟที่ใช้ $\tau = 1$ จะเรียกว่า \textit{แบบจำลองมาร์คอฟอันดับหนึ่ง} (first-order Markov model).
นั่นคือ 
\begin{eqnarray}
p(\bm{x}_{T+1}|\bm{x}_1, \bm{x}_2, \ldots, \bm{x}_T) 
&=&
p(\bm{x}_{T+1}|\bm{x}_T)
\label{eq: seq first-order markov criteria} 
\end{eqnarray}
เมื่อลำดับ $\{\bm{x}_t\}$ มีความสัมพันธ์เชิงลำดับตามเงื่อนไขของมาร์คอฟ.
รูป~\ref{fig: seq relation models} แสดงเงื่อนไขมาร์คอฟ เปรียบเทียบกับสมมติฐานอื่น ๆ.
เนื่องจากแบบจำลองมาร์คอฟอันดับหนึ่งเป็นที่นิยมเป็นอย่างมาก 
ทำให้หลาย ๆ ครั้งการอ้างถึงแบบจำลองมาร์คอฟ หมายถึงแบบจำลองมาร์คอฟอันดับหนึ่ง.
เพื่อความกระชับ 
เนื้อหาต่อไปนี้ก็จะอ้างถึงแบบจำลองมาร์คอฟอันดับหนึ่งว่า แบบจำลองมาร์คอฟ ยกเว้นแต่จะระบุเป็นอื่น.

%
\begin{figure}
	\begin{center}
		\includegraphics[width=0.6\textwidth]{08seq/HMM/relation_models.png}	
		\caption[ตัวอย่างสมมติฐานแบบต่าง ๆ ของความสัมพันธ์ระหว่างจุดข้อมูล]{ตัวอย่างสมมติฐานแบบต่าง ๆ ของความสัมพันธ์ระหว่างจุดข้อมูล. 
		แต่ละภาพ แสดงจุดข้อมูลสี่จุด.
		วงกลมทึบสีแดง แทนจุดข้อมูล และตัวแปร $\bm{x}_i$ สำหรับ $i = 1,\ldots,4$ แทนค่าของจุดข้อมูล.		
		ภาพบนสุด แสดงสมมติฐาน\textit{ไอ.ไอ.ดี.} ที่ถือว่า ค่าของจุดข้อมูลไม่มีความสัมพันธ์ระหว่างกันเลย (แต่ค่าของจุดข้อมูลทุกจุดมาจากการแจกแจงเดียวกัน).
		ภาพที่สองจากบน แสดงสมมติฐานว่า ทุกจุดข้อมูลมีความสัมพันธ์ร่วมกัน (เกี่ยวพันกันหมด ไม่ว่ากับจุดข้อมูลลำดับก่อนหน้า หรือกับจุดข้อมูลลำดับหลัง).
		เส้นเชื่อมไม่มีหัวลูกศร แสดงความสัมพันธ์สองทาง.
		ภาพที่สามจากบน แสดงสมมติฐานมาร์คอฟ(อันดับหนึ่ง).
		เส้นเชื่อมมีหัวลูกศร แสดงความสัมพันธ์ทางเดียว นั่นคือ ค่าของจุดข้อมูลต้นทางของเส้นเชื่อม ส่งผลต่อค่าของจุดข้อมูลปลายทาง (ที่หัวลูกศรชี้).
		ภาพที่สี่จากบน แสดงสมมติฐานมาร์คอฟอันดับสอง.
		ภาพล่างสุด แสดงสมมติฐานมาร์คอฟซ่อนเร้น ที่ว่า ค่าของจุดข้อมูล $\bm{x}_i$ ขึ้นอยู่กับค่าของสถานะ $\bm{z}_i$
		และค่าของสถานะ $\bm{z}_i$ ได้รับอิทธิพลมาจากค่าของสถานะก่อนหน้า $\bm{z}_{i-1}$.
		ค่าของสถานะ $\bm{z}_i$ อาจสามารถสังเกตได้โดยตรง อาจมีความหมายชัดเจน หรืออาจจะไม่สามารถสังเกตได้โดยตรง หรืออาจเป็นสถานะที่สมมติขึ้นมาก็ได้.
		}
		\label{fig: seq relation models}
	\end{center}
\end{figure}
%

ด้วยแบบจำลองมาร์คอฟ การแจกแจงร่วมของลำดับข้อมูลสามารถวิเคราะห์ได้จาก
\begin{eqnarray}
p(\bm{x}_1, \ldots, \bm{x}_T) &=& p(\bm{x}_1) \cdot \prod_{t=2}^T p(\bm{x}_t|\bm{x}_{t-1})
\label{eq: seq markov chain} .
\end{eqnarray}

การแจกแจงแบบมีเงื่อนไข $p(\bm{x}_t|\bm{x}_{t-1})$ สามารถถูกกำหนดให้มีค่าเท่ากันทุก ๆ ดัชนีลำดับ $t$ ตามสมมติฐาน\textit{ข้อมูลเชิงลำดับแบบคงที่}.
การกำหนดเช่นนี้ ช่วยให้เราสามารถใช้ค่าพารามิเตอร์ร่วมกันได้%
\footnote{%
การใช้ค่าพารามิเตอร์ร่วมกัน (parameter sharing)
เป็นปัจจัยที่สำคัญที่ช่วยให้แบบจำลองหลาย ๆ ชนิดสามารถทำงานได้ดี.
ตัวอย่างเช่น โครงข่ายคอนโวลูชั่น (บทที่~\ref{chapter: Convolution})
มีการใช้ชั้นคำนวณคอนโวลูชั่น ซึ่งอาศัยการเชื่อมต่อท้องถิ่น ที่ใช้ค่าพารามิเตอร์ร่วมกัน.
เนื่องจากสมมติฐานของการซ้ำรูปแบบเชิงพื้นที่สมเหตุสมผลกับข้อมูลรูปภาพ 
โครงข่ายคอนโวลูชั่น จึงสามารถทำงานได้ดีกับภาระกิจคอมพิวเตอร์วิทัศน์ต่าง ๆ.
}%
\index{english}{parameter sharing}
ซึ่งมีผลช่วยลดความซับซ้อนของการคำนวณ และช่วยลดปริมาณข้อมูลที่ต้องการสำหรับการฝึกแบบจำลองด้วย.
%
แบบจำลองมาร์คอฟ
ช่วยให้การประมาณการแจกแจงร่วมของข้อมูลลำดับคำนวณได้สะดวกขึ้น.

แต่อย่างไรก็ตาม เงื่อนไขการขึ้นอยู่กับค่าจุดข้อมูลก่อนหนึ่งเพียงหนึ่งลำดับ ก็เป็นปัจจัยจำกัดความสามารถของแบบจำลองมาร์คอฟลงด้วย.
เราอาจจะเพิ่มอันดับ (เพิ่มค่า $\tau$) ของแบบจำลองมาร์คอฟขึ้น ซึ่งก็จะอาจจะช่วยบรรเทาข้อจำกัดลงได้บ้าง ในเรื่องความสามารถที่จะเชื่อมโยงความสัมพันธ์เชิงลำดับระยะที่ยาวขึ้น.
แต่แนวทางนี้ กลับส่งผลลบต่อประสิทธิภาพการคำนวณเป็นอย่างมาก (ศึกษารายละเอียดเพิ่มเติมจาก \cite[\textsection 13.1]{Bishop2006a}).

เพื่อแบบจำลองจะไม่ถูกจำกัดจำนวนลำดับย้อนหลังที่สัมพันธ์กันจากเงื่อนไขของมาร์คอฟ และก็ยังสามารถคำนวณได้อย่างมีประสิทธิภาพ
เราสามารถดัดแปลงแบบจำลองได้โดยกำหนดให้ จุดข้อมูล $\bm{x}_t$ สัมพันธ์กับสถานะ $\bm{z}_t$
และสถานะ $\bm{z}_t$ เป็นไปตามเงื่อนไขของมาร์คอฟ.
เงื่อนไขเช่นนี้ ช่วยให้แบบจำลองมีความยืดหยุ่น สามารถรองรับความสัมพันธ์ของจุดข้อมูลย้อนหลังกี่ลำดับก็ได้ โดยผ่านกลไกของตัวแปรสถานะ
และยังคงรักษาการคำนวณที่มีประสิทธิภาพไว้ได้.

ค่าของสถานะ $\bm{z}_t$ อาจมีความหมายชัดเจนหรือไม่ก็ได้
และอาจสามารถสังเกตได้โดยตรงหรือไม่ก็ได้.
ดังนั้น สถานะ $\bm{z}_t$ จึงถูกเรียกว่า \textbf{สถานะซ่อนเร้น} (latent state) หรือ\textbf{ตัวแปรซ่อนเร้น} (latent variable) และเงื่อนไขนี้ เรียกว่า \textit{เงื่อนไขมาร์คอฟซ่อนเร้น} (hidden Markov criteria).
\index{english}{latent state}
\index{english}{latent variable}
\index{english}{latent state!HMM}
\index{english}{latent variabl!HMM}
บางครั้ง เพื่อลดความสับสน ตัวแปรจุดข้อมูล $\bm{x}_t$ อาจถูกเรียกว่า \textbf{ตัวแปรที่ถูกสังเกต} (observed variable).
\index{thai}{ตัวแปรที่ถูกสังเกต}\index{english}{observed variable}
รูป~\ref{fig: seq relation models} แสดงเงื่อนไขมาร์คอฟซ่อนเร้น (ภาพสุดท้าย)
เปรียบเทียบกับสมมติฐานอื่น ๆ.

ค่าของสถานะซ่อนเร้น $\bm{z}_t$ อาจจะเป็นค่าชนิดเดียวกับค่าของจุดข้อมูล $\bm{x}_t$ ก็ได้ หรืออาจจะต่างกันก็ได้
เช่น ค่าของสถานะอาจเป็นค่าวิยุตที่มีจำนวนจำกัด 
แต่ค่าของจุดข้อมูล $\bm{x}_t$ อาจจะเป็นค่าวิยุตที่มีจำนวนจำกัด หรือค่าวิยุตที่มีจำนวนไม่จำกัด หรือค่าต่อเนื่องก็ได้.
จำนวนมิติของสถานะซ่อนเร้น อาจจะเท่ากับ หรืออาจจะต่างจากจำนวนมิติของตัวแปรจุดข้อมูลก็ได้.
เงื่อนไขมาร์คอฟซ่อนเร้น เพียงระบุว่า ความเป็นอิสระต่อกันแบบมีเงื่อนไข นั่นคือ 
$\bm{z}_t \perp \!\!\! \perp \bm{z}_{t-2} | \bm{z}_{t-1}$
และ $\bm{x}_t \perp \!\!\! \perp \bm{x}_{t-1} | \bm{z}_t$.

ด้วยเงื่อนไขมาร์คอฟซ่อนเร้น การแจกแจงร่วมของลำดับชุดข้อมูลและชุดสถานะ สามารถเขียนได้
\begin{eqnarray}
p(\bm{x}_1, \ldots, \bm{x}_T, \bm{z}_1, \ldots, \bm{z}_T)
&=& p(\bm{z}_1) \cdot \left( \prod_{t=2}^T p(\bm{z}_t|\bm{z}_{t-1}) \right) \cdot \prod_{t=1}^T p(\bm{x}_t|\bm{z}_t)
\label{eq: seq state space model} .
\end{eqnarray}
แบบจำลองตามเงื่อนไขมาร์คอฟซ่อนเร้น เรียกว่า \textit{แบบจำลองปริภูมิสถานะ} (state space model).
\index{english}{state space model}
\index{thai}{แบบจำลองปริภูมิสถานะ}
แบบจำลองปริภูมิสถานะ
มีแบบจำลองที่เฉพาะเจาะจงลงไปอีก
ที่สำคัญได้แก่
\textit{แบบจำลองมาร์คอฟซ่อนเร้น} ที่เจาะจงสำหรับกรณี\textit{สถานะซ่อนเร้น}เป็นตัวแปรวิยุต
และ\textit{แบบจำลองพลวัตเชิงเส้น} (linear dynamic model หรือ linear dynamic system)
ที่เจาะจงสำหรับกรณีที่ทั้ง\textit{สถานะซ่อนเร้น}และ\textit{ตัวแปรที่ถูกสังเกต}เป็นตัวแปรต่อเนื่องที่มีการแจกแจงเกาส์เซียน.

\section{แบบจำลองมาร์คอฟซ่อนเร้น}
\label{sec: HMM}
\index{english}{Hidden Markov model}
\index{thai}{แบบจำลองมาร์คอฟซ่อนเร้น}	

\textbf{แบบจำลองมาร์คอฟซ่อนเร้น}%
\footnote{%
เนื้อหาในส่วนของแบบจำลองมาร์คอฟซ่อนเร้น ได้รับอิทธิพลหลัก ๆ จาก \cite{Bishop2006a}.
}%
(hidden Markov model)
เป็นแบบจำลองสำหรับข้อมูลเชิงลำดับ ที่ใช้เงื่อนไขมาร์คอฟซ่อนเร้น สำหรับกรณีที่\textit{สถานะซ่อนเร้น}เป็นตัวแปรวิยุต ที่ค่าวิยุตมีจำนวนจำกัด.
เมื่อพิจารณาสมการ~\ref{eq: seq state space model} ด้วยสมมติฐานสถานะซ่อนเร้นวิยุต 
เราจะเห็นว่า
สำหรับ ระบบที่มีค่าของสถานะซ่อนเร้นได้ $K$ สถานะแล้ว
ความน่าจะเป็น $p(\bm{z}_1)$ ที่อาจเรียกว่า \textbf{ค่าความน่าจะเป็นเริ่มต้น} (initial probabilities)
\index{english}{initial probabilities}
\index{english}{initial probabilities!HMM}
\index{thai}{ค่าความน่าจะเป็นเริ่มต้น}
\index{thai}{ค่าความน่าจะเป็นเริ่มต้น!แบบจำลองมาร์คอฟซ่อนเร้น}
สามารถแทนด้วยตารางความน่าจะเป็น
โดยแต่ละรายการของตารางระบุค่าความน่าจะเป็น $p(\bm{z}_1 =k) = \pi_k$ สำหรับ $k = 1, \ldots, K$
เมื่อ $\pi_k$ เป็นความน่าจะเป็นที่ระบบจะเริ่มต้นด้วยสถานะ $k$.
ค่าของ $\pi_k$ ต่าง ๆ เป็นพารามิเตอร์ของแบบจำลอง (กระบวนการหาค่าพารามิเตอร์เหล่านี้ จะอภิปรายในหัวข้อ~\ref{sec: seq HMM train}.)

ความน่าจะเป็น $p(\bm{z}_t|\bm{z}_{t-1})$ ที่เรียกว่า \textbf{ความน่าจะเป็นของการเปลี่ยนสถานะ} (transition probabilities)
\index{english}{transition probabilities}
\index{thai}{ความน่าจะเป็นของการเปลี่ยนสถานะ}
\index{english}{transition probabilities!HMM}
\index{thai}{ความน่าจะเป็นของการเปลี่ยนสถานะ!แบบจำลองมาร์คอฟซ่อนเร้น}
สามารถแทนด้วยเมทริกซ์ $\bm{A}$ ที่ส่วนประกอบ $A_{ij}$ แทนความน่าจะเป็นของการเปลี่ยนสถานะจากสถานะ $i$ ไปเป็นสถานะ $j$.
%นั่นคือ $A_{ij} = p(\bm{z}_t=j|\bm{z}_{t-1}=i)$.
เมทริกซ์ $\bm{A}$ อาจถูกเรียกว่า \textbf{เมทริกซ์การเปลี่ยนสถานะ} (transition matrix).
\index{english}{transition matrix}
\index{thai}{เมทริกซ์การเปลี่ยนสถานะ}
\index{english}{transition matrix!HMM}
\index{thai}{เมทริกซ์การเปลี่ยนสถานะ!แบบจำลองมาร์คอฟซ่อนเร้น}

เพื่อความสะดวก สถานะซ่อนเร้นได้ $K$ สถานะ สามารถแสดงด้วย\textit{รหัสหนึ่งร้อน} (one-hot coding ดูหัวข้อ~\ref{sec: ann classification}) ซึ่งคือ สถานะซ่อนเร้น $\bm{z}_t = [z_{t,1}, \ldots, z_{t,K}]^T \in \{0,1\}^K$ และ $\sum_{k=1}^K z_{t,k} = 1$. 
ดังนั้น
$\pi_k \equiv p(z_{1,k} = 1)$
และ
$A_{ij} \equiv p(z_{t,j}=1|z_{t-1,i}=1)$.
หมายเหตุ ด้วยสมมติฐาน\textit{ข้อมูลเชิงลำดับแบบคงที่}
ความน่าจะเป็นของการเปลี่ยนสถานะ $p(\bm{z}_t|\bm{z}_{t-1})$
จะถูกแทนด้วยเมทริกซ์การเปลี่ยนสถานะ $\bm{A}$ เหมือนกันสำหรับทุก ๆ ค่าของลำดับ $t$.
นอกจากนั้น ด้วยคุณสมบัติความน่าจะเป็น
ทำให้รู้ว่า $0 \leq \pi_k, A_{ij} \leq 1$
สำหรับทุก ๆ ค่าของ $i, j, k$
กับ 
$\sum_{k=1}^K \pi_k = 1$ 
และ $\sum_{j=1}^K A_{ij} = 1$.

เช่นเดียวกับพารามิเตอร์ $\bm{\pi} = [\pi_1, \ldots, \pi_K]^T$
เมทริกซ์ $\bm{A}$ ก็เป็นพารามิเตอร์ของแบบจำลอง.
เราสามารถเขียนฟังก์ชันการแจกแจงเริ่มต้น และฟังก์ชันการแจกแจงการเปลี่ยนสถานะ โดยเน้นพารามิเตอร์เหล่านี้ได้%
\footnote{%
วิธีการเขียนเช่นนี้ เป็นการเขียนจากมุมมองคณิตศาสตร์เพื่อให้คำนิยามต่าง ๆ สมบูรณ์.
การนำพจน์ต่าง ๆ เหล่านี้ไปเขียนโปรแกรม อาจดำเนินการต่างไป เพื่อให้คอมพิวเตอร์สามารถคำนวณได้อย่างมีประสิทธิภาพ.
}
\begin{eqnarray}
p(\bm{z}_1|\bm{\pi}) &=& \prod_{k=1}^K \pi_k^{z_{1k}}
\label{eq: seq HMM p(z|pi)} . \\
p(\bm{z}_t|\bm{z}_{t-1}, \bm{A}) &=& \prod _{j=1}^K \prod_{i=1}^K A_{ij}^{z_{t-1,i} \cdot z_{t,j}} 
\label{eq: seq HMM p(z|z,A)} .
\end{eqnarray}
ตัวอย่างเช่น สำหรับระบบที่มีสามสถานะซ่อนเร้น
การคำนวณฟังก์ชันการแจกแจงเริ่มต้น สำหรับสถานะที่หนึ่ง ($\bm{z}_1 = [1,0,0]^T$)
ทำโดย
$p(\bm{z}_1 = [1,0,0]^T|\bm{\pi}) = \pi_1^1 \cdot \pi_2^0 \cdot \pi_3^0 = \pi_1$.

สุดท้ายฟังก์ชันการแจกแจงแบบมีเงื่อนไข สำหรับ\textit{ตัวแปรที่ถูกสังเกต}
$p(\bm{x}_t|\bm{z}_t)$ มักถูกเรียกว่า \textbf{ความน่าจะเป็นของการปล่อย} (emission  probabilities).
\index{thai}{ความน่าจะเป็นของการปล่อย}
\index{english}{emission  probabilities}
\index{thai}{ความน่าจะเป็นของการปล่อย!แบบจำลองมาร์คอฟซ่อนเร้น}
\index{english}{emission  probabilities!HMM}
เช่นเดียวกัน ด้วยสมมติฐาน\textit{ข้อมูลเชิงลำดับแบบคงที่}
\textit{ความน่าจะเป็นของการปล่อย} ไม่ขึ้นกับดัชนีลำดับ $t$.
เราอาจเขียน\textit{ความน่าจะเป็นของการปล่อย}ด้วย $p(\bm{x}|\bm{z})$ โดยละดัชนีลำดับออกได้.

\textit{ความน่าจะเป็นของการปล่อย}
อาจถูกนิยามด้วยการแจกแจงที่เหมาะสมกับลักษณะของ\textit{ตัวแปรที่ถูกสังเกต}
เช่น 
หาก\textit{ตัวแปรที่ถูกสังเกต}เป็นค่าวิยุต 
เราอาจประมาณ\textit{ความน่าจะเป็นของการปล่อย} ด้วยเมทริกซ์แจกแจง $\bm{\Phi}$ ที่ส่วนประกอบ $\phi_{kd}$ 
ระบุค่าความน่าจะเป็นที่\textit{ตัวแปรที่ถูกสังเกต}จะเป็นชนิดที่ $d^{th}$ เมื่อสถานะซ่อนเร้นเป็นสถานะที่ $k^{th}$.
นั่นคือ $p(\bm{x}|\bm{z}, \bm{\Phi}) = \prod_d \prod_k \phi_{kd}^{z_k \cdot x_d}$
เมื่อ
$\phi_{kd} \equiv p(x_d = 1|z_k =1)$
และทั้ง $\bm{x}$ และ $\bm{z}$ แสดงด้วยรหัสหนึ่งร้อน.
%สำหรับจำลอง\textit{ความน่าจะเป็นของการปล่อย}.
%
หาก\textit{ตัวแปรที่ถูกสังเกต}เป็นค่าต่อเนื่อง 
เราอาจเลือก\textit{การแจกแจงเกาส์เซียน} 
สำหรับประมาณ\textit{ความน่าจะเป็นของการปล่อย}.
นั่นคือ 
$p(\bm{x}|\bm{z}, \{\bm{\mu}_i, \bm{\Sigma}_i\}_{i=1,\ldots,K}) = \prod_{k=1}^K \left(\mathcal{N}(\bm{x}|\bm{\mu}_k, \bm{\Sigma}_k)\right)^{z_k}$
เมื่อ $\mathcal{N}(\bm{x}|\bm{\mu}_k, \bm{\Sigma}_k) = \frac{1}{ \sqrt{ (2\pi)^D | \bm{\Sigma}_k |} } \exp \left( -\frac{1}{2}  (\bm{x} -\bm{\mu}_k)^T \bm{\Sigma}_k^{-1} (\bm{x} -\bm{\mu}_k) \right)$
โดย $D$ เป็นจำนวนมิติของเวกเตอร์ $\bm{x}$
และ $\{\bm{\mu}_i, \bm{\Sigma}_i\}_{i=1,\ldots,K}$ เป็นพารามิเตอร์ของแบบจำลอง.
หมายเหตุ ค่า $\pi$ ในที่นี้หมายถึง ค่าคงที่ไพ ($\pi \approx 3.1416$) ซึ่งต่างจาก $\pi_k$ (เช่นในสมการ~\ref{eq: seq HMM p(z|pi)}) ที่เป็นพารามิเตอร์ของแบบจำลอง.
สังเกตว่า ถึงแม้แบบจำลองมาร์คอฟซ่อนเร้น จะกำหนดให้สถานะซ่อนเร้น $\bm{z}$ เป็นตัวแปรค่าวิยุต
แต่ตัวแปรที่ถูกสังเกต $\bm{x}$ อาจจะเป็นค่าวิยุต หรือเป็นค่าต่อเนื่องก็ได้.

เพื่อความสะดวก ต่อจากนี้ พารามิเตอร์ของฟังก์ชันประมาณความน่าจะเป็นของการปล่อย จะถูกอ้างถึงโดยรวมด้วยสัญกรณ์ $\bm{\phi}$ ไม่ว่าจะเลือกใช้การแจกแจงแบบใด และ $\bm{\phi}_k$ จะหมายถึงชุดพารามิเตอร์ของการแจกแจง ของสถานะซ่อนเร้น $k^{th}$
เช่น กรณีเมทริกซ์แจกแจง $\bm{\phi}_k \equiv \prod_d \phi_{kd}^{x_d}$
หรือกรณีเกาส์เซีียน $\bm{\phi}_k \equiv \mathcal{N}(\bm{x}|\bm{\mu}_k, \bm{\Sigma}_k)$.
นั่นคือ ฟังก์ชันประมาณความน่าจะเป็นของการปล่อย หรือเรียกย่อ ๆ ว่า \textit{ฟังก์ชันการปล่อย} (emission function)
จะใช้สัญกรณ์ $p(\bm{x}|\bm{z}, \bm{\phi})$ โดย $\bm{\phi}$ หมายถึงพารามิเตอร์ของแบบจำลองที่ใช้ (อาจจะหมายถึง เมทริกซ์ $\bm{\Phi}$ หรือเซต $\{\bm{\mu}_i, \bm{\Sigma}_i\}_{i=1,\ldots,K}$ หรือชุดพารามิเตอร์อื่น ๆ ตามการแจกแจงที่เลือก).
\textit{ฟังก์ชันการปล่อย} อาจเขียนได้ โดยทั่วไปเป็น
\begin{eqnarray}
p(\bm{x}_t|\bm{z}_t, \bm{\phi}) &=& \prod_{k=1}^K \left( p(\bm{x}_t| \bm{\phi}_k ) \right)^{z_{t,k}}
\label{eq: seq HMM emission} .
\end{eqnarray}
 
การแจกแจงร่วมของข้อมูลหนึ่งลำดับชุด สามารถเขียนได้เป็น
\begin{eqnarray}
p(\bm{X}, \bm{Z}| \bm{\theta})
&=&
p(\bm{z}_1|\bm{\pi}) \cdot \left( \prod_{t=2}^T p(\bm{z}_t|\bm{z}_{t-1}, \bm{A}) \right)
\cdot \prod_{\tau=1}^T p(\bm{x}_\tau|\bm{z}_\tau, \bm{\phi})
\label{eq: seq HMM 1 sequence joint prob}
\end{eqnarray}
เมื่อ $\bm{X} = \{\bm{x}_1, \ldots, \bm{x}_T\}$,
$\bm{Z} = \{\bm{z}_1, \ldots, \bm{z}_T\}$
และ $\bm{\theta} = \{ \bm{\pi}, \bm{A}, \bm{\phi}  \}$ เป็นชุดพารามิเตอร์ทั้งหมดของแบบจำลอง.

จากแบบจำลองในสมการ~\ref{eq: seq HMM 1 sequence joint prob}
เป็น\textit{แบบจำลองสร้างกำเนิด} (generative model)
ซึ่งด้วยทฤษฎีความน่าจะเป็น โดยเฉพาะทฤษฎีของเบส์ (หัวข้อ~\ref{sec: cond prob})
เราสามารถทำการอนุมานต่าง ๆ ได้หากรู้ค่าของชุดพารามิเตอร์ $\bm{\theta}$
เช่น 
กรณีการทำนายข้อมูลการเงิน การทายค่าลำดับต่อไป $\hat{\bm{x}}_{T+1}$ ก็สามารถอนุมานจาก%
\footnote{%
ตัวอย่างนี้ ต้องการแสดงในเห็นคร่าว ๆ เท่านั้นว่า การแจกแจงร่วมสามารถนำไปใช้ในการอนุมานต่าง ๆ ได้อย่างไร อย่างน้อยในทางทฤษฎี.
การอนุมานในทางปฎิบัติ อาจต้องการขั้นตอนวิธีคำนวณที่มีประสิทธิภาพมากกว่าการประยุกต์ใช้ทฤษฎีความน่าจะเป็นตรง ๆ ดังที่แสดงในตัวอย่างนี้.
}
$\hat{\bm{x}}_{T+1} \approx E[\bm{x}_{T+1}|\bm{X}, \bm{\theta}]$
$=\sum_d \sum_k \sum_j \bm{x}_{T+1,d} \cdot p(\bm{x}_{T+1,d}|\bm{z}_{T+1, k}, \bm{\phi}) \cdot p(\bm{z}_{T+1, k}|\bm{z}_{T,j}, \bm{A}) \cdot  p((\bm{z}_{T,j}|\bm{X}, \bm{\theta})$
และ
$p((\bm{z}_T|\bm{X}, \bm{\theta}) = \sum_{\{\bm{z}_1, \ldots,  \bm{z}_{T-1}\}} p(\bm{Z}|\bm{X}, \bm{\theta})$
โดย
$p(\bm{Z}|\bm{X}, \bm{\theta}) = \frac{p(\bm{X}, \bm{Z}|\bm{\theta})}{\sum_{\bm{Z}} p(\bm{X},\bm{Z}|\bm{\theta})}$.
%และ $p(\bm{X}|\bm{\theta}) = \sum_{\bm{Z}} p(\bm{X},\bm{Z})$
%กรณีการรู้จำเสียงพูด Z
% music gen --> prob
% ECG --> Z --> classify
% DNA seq --> Z
% VDO -->Z --> classify
% sentiment --> Z --> classify
% Translation --> Z -(another seq prob of the target lang)-> Y

\subsection{การฝึกแบบจำลองมาร์คอฟซ่อนเร้น}
\label{sec: seq HMM train}

การฝึกแบบจำลองมาร์คอฟซ่อนเร้น หรือการหาค่าชุดพารามิเตอร์ $\bm{\theta}$ 
สามารถทำได้ด้วย\textbf{วิธีค่าฟังก์ชันควรจะเป็นสูงสุด} (maximum likelihood ดูแบบฝึกหัด~\ref{ex: ann predicts dists}).
แนวคิดของ\textit{วิธีค่าฟังก์ชันควรจะเป็นสูงสุด} 
คือ การหาค่าของชุดพารามิเตอร์ ที่ทำให้ค่า\textit{ความน่าจะเป็นภายหลัง} (posterior) มีค่ามากกว่าที่สุด
โดย\textit{ความน่าจะเป็นภายหลัง} คือค่า\textit{ความน่าจะเป็น}ที่คำนวณด้วยค่าต่าง ๆ ของชุดข้อมูลที่มีอยู่.
\index{thai}{วิธีค่าฟังก์ชันควรจะเป็นสูงสุด}
\index{english}{maximum likelihood}
\index{thai}{วิธีค่าฟังก์ชันควรจะเป็นสูงสุด!แบบจำลองมาร์คอฟซ่อนเร้น}
\index{english}{maximum likelihood!HMM}

นั่นคือ 
ด้วยข้อมูลชุดลำดับ $\bm{X} = \{\bm{x}_1, \ldots, \bm{x}_T\}$ ที่สังเกตได้
ค่าค่าของชุดพารามิเตอร์ $\bm{\theta}$ ของแบบจำลองมาร์คอฟซ่อนเร้น สามารถหาได้จาก
$\bm{\theta}^\ast = \arg\max_{\bm{\theta}} p(\bm{X}|\bm{\theta})$
โดย $p(\bm{X}|\bm{\theta})$ อาจหาได้โดย\textit{การสลายปัจจัย} (marginalization)
\index{thai}{การสลายปัจจัย}
\index{english}{marginalization}
\begin{eqnarray}
p(\bm{X}|\bm{\theta}) &=& \sum_{\bm{Z}} p(\bm{X}, \bm{Z}|\bm{\theta})
\label{eq: seq HMM marginal dist}.
\end{eqnarray}

ในทางปฏิบัติ การคำนวณสมการ~\ref{eq: seq HMM marginal dist} โดยตรง
ทำได้ยาก
เพราะว่า \textit{การสลายปัจจัย} อาศัยการบวกทุกค่าที่เป็นไปได้ของชุดลำดับสถานะซ่อนเร้น $\bm{Z} = \{\bm{z}_1, \ldots, \bm{z}_T\}$
และ ที่แต่ละลำดับ สถานะซ่อนเร้นก็มีโอกาสเป็นไปได้หลายค่า.
ในที่นี้ กำหนดให้ ค่าของสถานะซ่อนเร้นที่เป็นไปได้ มีจำนวนเป็น $K$ ค่า.
ด้วยความยาวของลำดับเป็น $T$ ทำให้มีชุดค่าของลำดับสถานะซ่อนเร้นที่เป็นไปได้เท่ากับ $K^T$ ชุด.
จำนวนพจน์ที่ต้องทำการบวก จะเพิ่มขึ้นแบบชี้กำลังตามความยาวของชุดลำดับ.
%\textit{การสลายปัจจัย} โดยการบวกตรง ๆ เช่นนี้ จะส่งผมต่อประสิทธิภาพการคำนวณอย่างมาก โดยเฉพาะสำหรับชุดลำดับยาว ๆ ที่แต่ละสถานะมีจำนวนค่าที่เป็นไปได้หลายค่า.

แนวทางหนึ่งสามารถนำมาใช้คำนวณหาค่าพารามิเตอร์ที่เหมาะสมได้
คือ \textbf{ขั้นตอนวิธีอีเอ็ม} (expectation-maximization algorithm คำย่อ EM algorithm)
ซึ่งเป็นขั้นตอนวิธีทั่ว ๆ ไปสำหรับการหาค่าพารามิเตอร์ของแบบจำลอง โดยมีนัยของ\textit{ความน่าจะเป็น}ประกอบ.
\index{thai}{ขั้นตอนวิธีอีเอ็ม}
\index{english}{expectation-maximization algorithm}
\index{thai}{ขั้นตอนวิธีอีเอ็ม!แบบจำลองมาร์คอฟซ่อนเร้น}
\index{english}{expectation-maximization algorithm!HMM}
กล่าวโดยคร่าว ๆ 
ขั้นตอนวิธีอีเอ็ม อาศัยการทำงานเป็นสองขั้นตอนหลัก ๆ คือ \textit{ขั้นตอนการหาค่าคาดหมาย} (expectation phase)
และ\textit{ขั้นตอนการหาค่าตัวทำมากที่สุด} (maximization phase).
ขั้นตอนวิธีอีเอ็ม เริ่มด้วยค่าเริ่มต้นของพารามิเตอร์ $\bm{\theta}_0$ 
แล้วคำนวณ\textit{ความน่าจะเป็นภายหลัง} $p(\bm{Z}|\bm{X}, \bm{\theta}_0)$.
จากนั้น
ใช้ค่า\textit{ความน่าจะเป็นภายหลัง}ที่ได้ 
เพื่อประเมินค่าคาดหมายของลอการิทึมของค่า\textit{ฟังก์ชันควรจะเป็น}ของข้อมูล
%
\begin{eqnarray}
\varepsilon (\bm{\theta}, \bm{\theta}_0)
&=&
\sum_{\bm{Z}} p(\bm{Z}|\bm{X}, \bm{\theta}_0) \cdot
\ln p(\bm{X},\bm{Z}|\bm{\theta})
\label{eq: seq HMM likelihood function}
\end{eqnarray}
เมื่อ $\bm{\theta}_0$ เป็นค่าพารามิเตอร์ ณ ปัจจุบัน
ส่วน $\bm{\theta}$ เป็นตัวแปรของค่าพารามิเตอร์ (ที่ต้องการจะปรับปรุงใหม่).
การประเมิน\textit{ฟังก์ชันควรจะเป็น} $\varepsilon (\bm{\theta}, \bm{\theta}_0)$ จะใช้ในกระบวนการหาค่าพารามิเตอร์ที่ดีที่สุด.
%นั่นคือ $\bm{\theta}^\ast = \arg\max_{\bm{\theta}} \varepsilon (\bm{\theta}, \bm{\theta}_0)$.
หลังจากได้ค่าพารามิเตอร์ชุดใหม่แล้ว 
%($\bm{\theta}_0 \gets \bm{\theta}^\ast$)
จึงวนซ้ำคำนวณในลักษณะเช่นนี้ต่อไป 
จนค่าต่าง ๆ ลู่เข้า หรือจนกว่าจะเป็นไปตามเงื่อนไขการจบการคำนวณ.

\paragraph{ขั้นตอนวิธีอีเอ็ม.}
กล่าวโดยละเอียดแล้ว 
ด้วยค่าพารามิเตอร์ $\bm{\theta}_0$
ขั้นตอนวิธีอีเอ็ม เริ่มที่\textit{ขั้นตอนการหาค่าคาดหมาย}ใช้ค่าพารามิเตอร์นี้ในการคำนวณค่าคาดหมายของสถานะซ่อนเร้น.

เพื่อความสะดวก นิยาม\textit{ความน่าจะเป็นภายหลัง}ของสถานะซ่อนเร้นด้วย $\bm{q}_t$ และนิยาม\textit{ความน่าจะเป็นภายหลังร่วม}ด้วย $\bm{R}^{(t-1,t)}$.
นั่นคือ 
\begin{eqnarray}
%q(\bm{z}_t) &\equiv& p(\bm{z}_t|\bm{X}, \bm{\theta}_0)
\bm{q}_t &\equiv& p(\bm{z}_t|\bm{X}, \bm{\theta}_0)
\label{eq: seq HMM q}  \\
%r(\bm{z}_{t-1}, \bm{z}_t) &\equiv& p(\bm{z}_{t-1}, \bm{z}_t|\bm{X}, \bm{\theta}_0)
\bm{R}^{(t-1, t)} &\equiv& p(\bm{z}_{t-1}, \bm{z}_t|\bm{X}, \bm{\theta}_0)
\label{eq: seq HMM r} 
\end{eqnarray}
โดย สำหรับแต่ละดัชนีลำดับ $t$
เวกเตอร์ $\bm{q}_t \in [0,1]^K$ 
ซึ่งส่วนประกอบ $q_{tk} \equiv p(z_{tk} = 1|\bm{X}, \bm{\theta}_0)$
และ เมทริกซ์ $\bm{R}^{(t-1,t)} \in [0,1]^{K \times K}$
ซึ่งส่วนประกอบ $R^{(t-1,t)}_{j,k} \equiv p(z_{t-1,j} = 1, z_{t,k}=1|\bm{X}, \bm{\theta}_0)$.
	
หมายเหตุ 
เนื่องจาก $z_{tk}$ เป็นตัวแปรค่าทวิภาค 
นั่นทำให้ ค่าคาดหมายของสถานะซ่อนเร้น
$E[z_{tk}] = p(z_{tk}=1|\bm{X}, \bm{\theta}_0) \cdot 1 + p(z_{tk}=0|\bm{X}, \bm{\theta}_0) \cdot 0$ $= p(z_{tk}=1|\bm{X}, \bm{\theta}_0)$ $=q_{tk}$.
ในทำนองเดียวกัน 
$E[z_{t-1,j} \cdot z_{tk}]$
$=p(z_{t-1,j} = 1, z_{t,k}=1|\bm{X}, \bm{\theta}_0) \cdot 1 \cdot 1 + 0 + 0 + 0$
$=R^{(t-1,t)}_{j,k}$.
ดังนั้น การประมาณค่าความน่าจะเป็นภายหลัง $\bm{q}_t$ และความน่าจะเป็นภายหลังร่วม $\bm{R}^{(t-1,t)}$ จึงเทียบเท่ากับการหาค่าคาดหมาย.
การคำนวณในขั้นตอนนี้ จึงถูกเรียกว่าเป็น \textit{ขั้นตอนการหาค่าคาดหมาย}.

ด้วยความน่าจะเป็นภายหลังทั้ง $\bm{q}_t$ และ $\bm{R}^{(t-1,t)}$
และนำแบบจำลอง\atom{มาร์คอฟ}ซ่อนเร้น ในสมการ~\ref{eq: seq HMM 1 sequence joint prob} มาประกอบ
เราจะได้ฟังก์ชันควรจะเป็น (สมการ~\ref{eq: seq HMM likelihood function}) ว่า
\begin{eqnarray}
\varepsilon (\bm{\theta}, \bm{\theta}_0)
&=&
\sum_{\bm{Z}} p(\bm{Z}|\bm{X}, \bm{\theta}_0) \cdot
\ln \left\{p(\bm{z}_1|\bm{\pi}) \cdot \left( \prod_{t=2}^T p(\bm{z}_t|\bm{z}_{t-1}, \bm{A}) \right)
\cdot \prod_{\tau=1}^T p(\bm{x}_\tau|\bm{z}_\tau, \bm{\phi}) \right\}
\nonumber \\
%&=&
%\sum_{\bm{Z}} p(\bm{Z}|\bm{X}, \bm{\theta}_0) \cdot
%\left\{
%\ln p(\bm{z}_1|\bm{\pi}) + \ln \left( \prod_{t=2}^T p(\bm{z}_t|\bm{z}_{t-1}, \bm{A}) \right)
%+ \ln \prod_{\tau=1}^T p(\bm{x}_\tau|\bm{z}_\tau, \bm{\phi})
%\right\}
%\nonumber \\
%&=&
%\sum_{\bm{Z}} p(\bm{Z}|\bm{X}, \bm{\theta}_0) \cdot
%\left\{
%\ln p(\bm{z}_1|\bm{\pi}) +  \sum_{t=2}^T \ln p(\bm{z}_t|\bm{z}_{t-1}, \bm{A})
%+  \sum_{\tau=1}^T \ln p(\bm{x}_\tau|\bm{z}_\tau, \bm{\phi})
%\right\}
%\nonumber \\
&=&
\sum_{k=1}^K q_{1k} \cdot \ln p(\bm{z}_1|\bm{\pi}) +  \sum_{j=1}^K \sum_{k=1}^K \sum_{t=2}^T R^{(t-1,t)}_{j,k} \cdot \ln p(\bm{z}_t|\bm{z}_{t-1}, \bm{A})
\nonumber\\
&\;&
+  \sum_{k=1}^K \sum_{\tau=1}^T q_{\tau k} \cdot \ln p(\bm{x}_\tau|\bm{z}_\tau, \bm{\phi})
\nonumber \\
&=&
\sum_{k=1}^K q_{1k} \cdot \ln \pi_k +  \sum_{j=1}^K \sum_{k=1}^K \sum_{t=2}^T R^{(t-1,t)}_{j,k} \cdot \ln A_{jk}
+  \sum_{k=1}^K \sum_{\tau=1}^T q_{\tau k} \cdot \ln p(\bm{x}_\tau|\bm{\phi}_k)
\nonumber \\
\label{eq: seq HMM likelihood function M step}
\end{eqnarray}
โดย $\bm{\pi}$ และ % = [\pi_1, \ldots, \pi_K]^T$,
$\bm{A}$ % = [A_{11}, \ldots, A_{1K}] 
เป็น\textit{ค่าความน่าจะเป็นเริ่มต้น}
และ\textit{ความน่าจะเป็นของการเปลี่ยนสถานะ} ตามลำดับ.
ส่วน $p(\bm{x}_\tau|\bm{\phi}_k)$ คือ\textit{ความน่าจะเป็นของการปล่อย}ของสถานะที่ $k^{th}$.

\textit{ขั้นตอนการหาค่าตัวทำมากที่สุด} 
หาค่าของพารามิเตอร์ $\bm{\theta} =\{\bm{\pi}, \bm{A}, \bm{\phi} \}$ จากค่าที่ทำให้ฟังก์ชันควรจะเป็น (สมการ~\ref{eq: seq HMM likelihood function M step})
มีค่ามากที่สุด (โดยค่า $\bm{q}_t$ และ $\bm{R}^{(t-1,t)}$ จะใช้ค่าที่ได้จาก\textit{ขั้นตอนการหาค่าคาดหมาย} และคิดเสมือนเป็นค่าคงที่).
ค่าพารามิเตอร์ $\bm{\pi}$ และ $\bm{A}$ หาได้จากค่าทำมากที่สุดของ\textit{ฟังก์ชันควรจะเป็น} ประกอบกับเงื่อนไขของพารามิเตอร์
ได้แก่ $\sum_k \pi_k = 1$ และ $\sum_k A_{jk} = 1$ และได้ผลลัพธ์ (ดูแบบฝึกหัด~\ref{ex: seq HMM M step derivatives}) คือ
%
\begin{eqnarray}
\pi_k &=& \frac{q_{1k}}{\sum_{j=1}^K q_{1j}}
\label{eq: seq HMM pi_k} \\
A_{jk} &=& \frac{\sum_{t=2}^T R^{(t-1,t)}_{jk} }{ \sum_{l=1}^K \sum_{t=2}^T R^{(t-1,t)}_{jl} }
\label{eq: seq HMM A_jk} .
\end{eqnarray}

สำหรับพารามิเตอร์ $\bm{\phi}$ การหาค่าก็สามารถทำได้ในทำนองเดียวกัน
เพียงแต่แบบจำลองมาร์คอฟซ่อนเร้น เปิดกว้างสำหรับการเลือกใช้\textit{ฟังก์ชันการปล่อย} 
%$p(\bm{x}_t|\bm{z}_t, \bm{\phi})$ 
$p(\bm{x}_t|\bm{\phi}_k)$
ได้หลายแบบ.

หากเลือก\textit{ฟังก์ชันการปล่อยเกาส์เซียน} นั่นคือ
\index{thai}{แบบจำลองมาร์คอฟซ่อนเร้น!ฟังก์ชันการปล่อย!เกาส์เซียน}
\index{english}{HMM!emission!gaussian variables}
%$p(\bm{x}_t|z_{tk} = 1, \bm{\phi})$
$p(\bm{x}_t|\bm{\phi}_k)$
$\equiv \mathcal{N}(\bm{x}_t|\bm{\mu}_k, \bm{\Sigma}_k)$.
เมื่อทำการหาค่าตัวทำมากที่สุด ผลลัพธ์จะได้เป็น
\begin{eqnarray}
\bm{\mu}_k 
&=& \frac{\sum_{t=1}^T q_{tk} \cdot \bm{x}_t }{ \sum_{t=1}^T q_{tk} }
\label{eq: HMM M step Gaussian mu} \\
\bm{\Sigma}_k 
&=& \frac{\sum_{t=1}^T q_{tk} \cdot (\bm{x}_t - \bm{\mu}_k) \cdot (\bm{x}_t - \bm{\mu}_k)^T }{ \sum_{t=1}^T q_{tk} }
\label{eq: HMM M step Gaussian sigma} .
\end{eqnarray}

หากเลือก\textit{ฟังก์ชันการปล่อยอเนกนามวิยุต} (discrete multinomial emission function) 
\index{thai}{แบบจำลองมาร์คอฟซ่อนเร้น!ฟังก์ชันการปล่อย!อเนกนามวิยุต}
\index{english}{HMM!emission!discrete multinomial variables}
นั่นคือ การกำหนด
$p(\bm{x}_t|\bm{\phi}_k)$
$\equiv \prod_{d=1}^D \phi_{kd}^{x_{td}}$
เมื่อ 
พารามิเตอร์ $\phi_{kd}$ แทนค่าความน่าจะเป็นที่จะพบตัวแปรที่ถูกสังเกต $\bm{x}_t$ เป็นชนิด $d^{th}$ หากสถานะซ่อนเร้นเป็นชนิด $k^{th}$.
ค่าของตัวแปรที่ถูกสังเกต $\bm{x}_t$ ใช้\textit{รหัสหนึ่งร้อน}
ซึ่งคือ $\bm{x}_t = [x_{t1}, \ldots, x_{tD}]^T$ โดย $D$ คือจำนวนค่าวิยุต ที่ตัวแปรสามารถแทนได้.
ส่วนประกอบ $x_{td} \in \{0,1\}$ และ $\sum_{d=1}^D x_{td} = 1$.
เมื่อทำการหาค่าตัวทำมากที่สุด ผลลัพธ์จะได้เป็น
\begin{eqnarray}
\phi_{kd} 
&=& \frac{\sum_{t=1}^T q_{tk} \cdot x_{td} }{ \sum_{t=1}^T q_{tk} }
\label{eq: HMM M step multinomial phi}.
\end{eqnarray}

ค่าเริ่มต้นของพารามิเตอร์ $\bm{\pi}$ และ $\bm{A}$ อาจกำหนดได้โดยการสุ่ม แต่ต้องควบคุมให้ค่าเป็นไปตามเงื่อนไขของความน่าจะเป็น
นั่นคือ $\pi_k \geq 0$, $\sum_k \pi_k = 1$, $A_{jk} \geq 0$ และ $\sum_k A_{jk} = 1$.
ค่าเริ่มต้นของพารามิเตอร์ของ $\bm{\phi}$ 
%(หรืออาจรวมถึงค่าเริ่มต้นของ $\bm{\pi}$ และ $\bm{A}$ ด้วย) ก็
อาจกำหนดเป็นเสมือนพารามิเตอร์อีกส่วน และใช้กระบวนการเรียนรู้จากข้อมูลเพื่อช่วยกำหนดค่าได้.
%ต่าง ๆ เหล่านี้ได้.
%
%ประมาณคร่าว ๆ จากข้อมูลได้. (ดู \cite{Bishop2006a} เพิ่มเติม)
%เช่น การใช้สมมติฐาน\textit{ไอ.ไอ.ดี.} แล้วทำการหาค่าทำมากที่สุด. 

\textit{ขั้นตอนวิธีอีเอ็ม} มีคุณสมบัติความถูกต้องและคุณสมบัติการลู่เข้าที่ดี (ดู \cite{SpringerUrban2014} เพิ่มเติม).
อย่างไรก็ตาม 
ใน\textit{ขั้นตอนการหาค่าคาดหมาย}
การประมาณค่าของค่าความน่าจะเป็นภายหลัง $\bm{q}_t$ และ $\bm{R}^{(t-1,t)}$ 
แม้อาจสามารถทำได้โดยวิธี\textit{การสลายปัจจัย} เช่น
$\bm{q}_t$ 
$= p(\bm{z}_t|\bm{X}, \bm{\theta}_0)$
$= \sum_{ \{\bm{z}_1, \ldots, \bm{z}_{t-1}, \bm{z}_{t+1}, \ldots, \bm{z}_T \} }$ 
$p(\bm{Z}|\bm{X}, \bm{\theta}_0)$
และ
$\bm{R}^{(t-1, t)} = p(\bm{z}_{t-1}, \bm{z}_t|\bm{X}, \bm{\theta}_0)$
$= \sum_{ \{\bm{z}_1, \ldots, \bm{z}_{t-2}, \bm{z}_{t+1}, \ldots, \bm{z}_T \} } p(\bm{Z}|\bm{X}, \bm{\theta}_0)$
โดย $p(\bm{Z}|\bm{X}, \bm{\theta}_0)$ ก็อาจจะหาได้จากกฎของเบส์
$p(\bm{Z}|\bm{X}, \bm{\theta}_0)$ 
$= p(\bm{Z},\bm{X}| \bm{\theta}_0) / \sum_{\bm{Z}} p(\bm{Z},\bm{X}| \bm{\theta}_0)$
แต่วิธีนี้ใช้การคำนวณมหาศาล.

เฉพาะการคำนวณ $\sum_{ \{\bm{z}_1, \ldots, \bm{z}_{t-1}, \bm{z}_{t+1}, \ldots, \bm{z}_T \} } p(\bm{Z}|\bm{X}, \bm{\theta}_0)$ เองอย่างเดียว ก็เท่ากับต้องบวกพจน์ทั้งหมด $(T-1) \cdot K$ พจน์เข้าด้วยกัน และค่าของแต่ละพจน์ ก็ต้องผ่านการคำนวณต่าง ๆ ดังอภิปราย.
%อาจจะได้จากการคำนวณตามกฎของเบส์ ที่
%%ซึ่งคือการคำนวณสมการ~\ref{eq: seq HMM 1 sequence joint prob}.
ดังนั้น เมื่อต้องนำมาใช้กับ\textit{ขั้นตอนวิธีอีเอ็ม} ซึ่งต้องคำนวณค่า\textit{ความน่าจะเป็นภายหลัง}ใหม่ทุก ๆ สมัยฝึก
การประมาณค่า $\bm{q}_t$ และ $\bm{R}^{(t-1,t)}$  ด้วยวิธีนี้
จึงไม่เหมาะที่จะนำมาใช้ได้ในทางปฏิบัติ.

ปัญหาการคำนวณค่า\textit{ความน่าจะเป็นภายหลัง}อย่างมีประสิทธิภาพ
ถูกบรรเทาด้วย\textit{ขั้นตอนวิธีไปข้างหน้ากับถอยกลับ} ที่จะอภิปรายต่อไปในหัวข้อ~\ref{sec: seq HMM forward-backward}.

\subsection{ขั้นตอนวิธีไปข้างหน้ากับถอยกลับ}
\label{sec: seq HMM forward-backward}

\textbf{ขั้นตอนวิธีไปข้างหน้ากับถอยกลับ} (forward-backward algorithm)
\index{thai}{ขั้นตอนวิธีไปข้างหน้ากับถอยกลับ}
\index{thai}{แบบจำลองมาร์คอฟซ่อนเร้น!ขั้นตอนวิธีไปข้างหน้ากับถอยกลับ}
\index{english}{HMM!forward-backward algorithm}
\index{english}{forward-backward algorithm}
เป็นขั้นตอนวิธี ที่ใช้คำนวณค่าของ\textit{ความน่าจะเป็นภายหลัง}ที่ใช้ใน\textit{วิธีอีเอ็ม} ได้อย่างมีประสิทธิภาพ.
จริง ๆ แล้ว \textit{ขั้นตอนวิธีไปข้างหน้ากับถอยกลับ} มีการศึกษาอย่างกว้าง และวิธีดำเนินการก็มีอยู่หลายแบบ
หัวข้อนี้จะอภิปรายแบบหนึ่งที่มีการใช้อย่างกว้างขวาง\cite{Bishop2006a} เรียกว่า \textbf{ขั้นตอนวิธีแอลฟา-บีตา} (alpha-beta algorithm).
\index{thai}{ขั้นตอนวิธีแอลฟา-บีตา}
\index{english}{alpha-beta algorithm}
\index{thai}{แบบจำลองมาร์คอฟซ่อนเร้น!ขั้นตอนวิธีไปข้างหน้ากับถอยกลับ!ขั้นตอนวิธีแอลฟา-บีตา}
\index{english}{HMM!forward-backward algorithm!alpha-beta algorithm}
เนื่องจาก หัวข้อนี้พิจารณาค่าพารามิเตอร์ $\bm{\theta}_0$ เป็นเสมือนค่าคงที่
ดังนั้นเงื่อนไข $\bm{\theta}_0$ จะถูกละไว้ในฐานที่เข้าใจ เพื่อความกระชับ. 

%ตามแนวทางการอธิบายของบิชอบ\cite{Bishop2006a} 
%(ซึ่งดำเนินตาม \cite{Jordan2007} อีกที)
ด้วยเงื่อนไขของแบบจำลองมาร์คอฟซ่อนเร้น 
ระบบจะมีคุณสมบัติดังนี้
%
\begin{eqnarray}
p(\bm{X}|\bm{z}_t)
&=& p(\bm{x}_1, \ldots, \bm{x}_t|\bm{z}_t) \cdot p(\bm{x}_{t+1}, \ldots, \bm{x}_T|\bm{z}_t)
\label{eq: alpha-beta prelude property 1} \\
p(\bm{x}_1, \ldots, \bm{x}_{t-1}|\bm{x}_t, \bm{z}_t)
&=& p(\bm{x}_1, \ldots, \bm{x}_{t-1}|\bm{z}_t)
\label{eq: alpha-beta prelude property 2} \\
p(\bm{x}_1, \ldots, \bm{x}_{t-1}|\bm{z}_{t-1}, \bm{z}_t)
&=& p(\bm{x}_1, \ldots, \bm{x}_{t-1}|\bm{z}_{t-1})
\label{eq: alpha-beta prelude property 3} \\
p(\bm{x}_{t+1}, \ldots, \bm{x}_T|\bm{z}_t, \bm{z}_{t+1})
&=& p(\bm{x}_{t+1}, \ldots, \bm{x}_T|\bm{z}_{t+1})
\label{eq: alpha-beta prelude property 4} \\
p(\bm{x}_{t+2}, \ldots, \bm{x}_T|\bm{x}_{t+1}, \bm{z}_{t+1})
&=& p(\bm{x}_{t+2}, \ldots, \bm{x}_T|\bm{z}_{t+1})
\label{eq: alpha-beta prelude property 5} \\
p(\bm{X}|\bm{z}_{t-1}, \bm{z}_{t})
&=& p(\bm{x}_{1}, \ldots, \bm{x}_{t-1}|\bm{z}_{t-1})
\cdot p(\bm{x}_t|\bm{z}_t) \cdot p(\bm{x}_{t+1}, \ldots, \bm{x}_{T}|\bm{z}_{t})
\nonumber \\
\label{eq: alpha-beta prelude property 6} \\
p(\bm{x}_{T+1}|\bm{X}, \bm{z}_{T+1})
&=& p(\bm{x}_{T+1}|\bm{z}_{T+1})
\label{eq: alpha-beta prelude property 7} \\
p(\bm{z}_{T+1}|\bm{X}, \bm{z}_{T+1})
&=& p(\bm{z}_{T+1}|\bm{z}_{T+1})
\label{eq: alpha-beta prelude property 8} 
%
\end{eqnarray}
เมื่อ $\bm{X} = \{ \bm{x}_1, \ldots, \bm{x}_T \}$.

พิจารณา 
\begin{eqnarray}
\bm{q}_t &=& p(\bm{z}_t|\bm{X}) = \frac{p(\bm{X}|\bm{z}_t) \cdot p(\bm{z}_t)}{p(\bm{X})}
\label{eq: alpha-beta q}.
\end{eqnarray}

ด้วยสมการ~\ref{eq: alpha-beta prelude property 1} และ\textit{กฎผลคูณ}
เราจะได้
\begin{eqnarray}
\bm{q}_t 
&=& \frac{p(\bm{x}_1, \ldots, \bm{x}_t,\bm{z}_t) \cdot p(\bm{x}_{t+1}, \ldots, \bm{x}_T|\bm{z}_t)}{p(\bm{X})}
= \frac{\alpha(\bm{z}_t) \cdot \beta(\bm{z}_t) }{p(\bm{X})}
\label{eq: alpha-beta q alpha beta}
\end{eqnarray}
โดยนิยาม
\begin{eqnarray}
\alpha(\bm{z}_t)
& \equiv & p(\bm{x}_1, \ldots, \bm{x}_t, \bm{z}_t)
\label{eq: alpha-beta alpha} \\
\beta(\bm{z}_t)
& \equiv & p(\bm{x}_{t+1}, \ldots, \bm{x}_T| \bm{z}_t)
\label{eq: alpha-beta beta}.
\end{eqnarray}

ค่า $\alpha(\bm{z}_t) \in \mathbb{R}^K$
แทนค่าความน่าจะเป็นร่วม
ระหว่างข้อมูลชุดลำดับที่สังเกตจนถึงเวลา $t$
กับสถานะซ่อนเร้นของเวลา $t$.
ค่า $\beta(\bm{z}_t) \in \mathbb{R}^K$
แทนค่าความน่าจะเป็นแบบมีเงื่อนไขของข้อมูลชุดลำดับที่สังเกตตั้งแต่เวลา $t$ ไปจนจบ เมื่อมีสถานะซ่อนเร้นที่เวลา $t$ เป็นเงื่อนไข.
เพื่อความสะดวก กำหนดให้ $\alpha(z_{tk})
\equiv p(\bm{x}_1, \ldots, \bm{x}_t, z_{tk}=1)$
และ
$\beta(\bm{z}_t)
 \equiv p(\bm{x}_{t+1}, \ldots, \bm{x}_T| z_{tk}=1)$
โดย $\bm{z}_t$ แสดงด้วยรหัสหนึ่งร้อน.

ในทำนองเดียวกัน
\begin{eqnarray}
\bm{R}^{(t-1, t)}
&=&
p(\bm{z}_{t-1}, \bm{z}_t | \bm{X})
= \frac{p(\bm{X}|\bm{z}_{t-1}, \bm{z}_t) \cdot p(\bm{z}_{t-1}, \bm{z}_t)}{p(\bm{X})}
\nonumber \\
&=&
\frac{
p(\bm{x}_1, \ldots,\bm{x}_{t-1}|\bm{z}_{t-1})
\cdot p(\bm{x}_t|\bm{z}_t) \cdot
p(\bm{x}_{t+1}, \ldots, \bm{x}_T|\bm{z}_t)
\cdot p(\bm{z}_t| \bm{z}_{t-1}) 
\cdot p(\bm{z}_{t-1})
}{p(\bm{X})}
\nonumber \\
&=&
\frac{
	\alpha(\bm{z}_{t-1})
	\cdot p(\bm{x}_t|\bm{z}_t) \cdot
	\beta(\bm{z}_t)
	\cdot p(\bm{z}_t| \bm{z}_{t-1}) 
}{p(\bm{X})}
\label{eq: alpha-beta R alpha beta}.
\end{eqnarray}

แนวคิดของ\textit{ขั้นตอนวิธีไปข้างหน้ากับถอยกลับ}
คือ จัดรูปการคำนวณ $\alpha(\bm{z}_t)$ และ $\beta(\bm{z}_t)$
ให้อยู่ในรูปที่สามารถคำนวณได้อย่างมีประสิทธิภาพ โดยอาศัย\textit{ความสัมพันธ์แบบเรียกซ้ำ} (recursive relation).
การคำนวณค่า $\alpha(\bm{z}_t)$ สามารถจัดรูปใหม่ได้ดังนี้
\begin{eqnarray}
\alpha(\bm{z}_t)
&=&
p(\bm{x}_1, \ldots, \bm{x}_t, \bm{z}_t)
\nonumber \\
&=&
p(\bm{x}_1, \ldots, \bm{x}_t| \bm{z}_t) \cdot p(\bm{z}_t)
\nonumber \\
&=&
p(\bm{x}_t|\bm{z}_t) \cdot p(\bm{x}_1, \ldots, \bm{x}_{t-1}| \bm{z}_t) \cdot p(\bm{z}_t)
\nonumber \\
&=&
p(\bm{x}_t|\bm{z}_t) \cdot p(\bm{x}_1, \ldots, \bm{x}_{t-1}, \bm{z}_t)
\nonumber \\
&=&
p(\bm{x}_t|\bm{z}_t) \cdot \sum_{\bm{z}_{t-1}} p(\bm{x}_1, \ldots, \bm{x}_{t-1}, \bm{z}_{t-1}, \bm{z}_t)
\nonumber \\
&=&
p(\bm{x}_t|\bm{z}_t) \cdot \sum_{\bm{z}_{t-1}} p(\bm{x}_1, \ldots, \bm{x}_{t-1}, \bm{z}_t| \bm{z}_{t-1}) \cdot p(\bm{z}_{t-1})
\nonumber \\
&=&
p(\bm{x}_t|\bm{z}_t) \cdot \sum_{\bm{z}_{t-1}} p(\bm{x}_1, \ldots, \bm{x}_{t-1}| \bm{z}_{t-1}) 
\cdot p(\bm{z}_t|\bm{z}_{t-1}) \cdot p(\bm{z}_{t-1})
\nonumber \\
&=&
p(\bm{x}_t|\bm{z}_t) \cdot \sum_{\bm{z}_{t-1}} p(\bm{x}_1, \ldots, \bm{x}_{t-1}, \bm{z}_{t-1}) 
\cdot p(\bm{z}_t|\bm{z}_{t-1}) 
\nonumber \\
&=&
p(\bm{x}_t|\bm{z}_t) \cdot \sum_{\bm{z}_{t-1}} \alpha(\bm{z}_{t-1}) 
\cdot p(\bm{z}_t|\bm{z}_{t-1})
\label{eq: HMM alpha-beta alpha}
\end{eqnarray}
สำหรับ $t = 2, \ldots, T$.
\begin{eqnarray}
\alpha(\bm{z}_1)
&=& p(\bm{x}_1, \bm{z}_1)
= p(\bm{z}_1) \cdot p(\bm{x}_1|\bm{z}_1) = \prod_{k=1}^K \left( \pi_k \cdot p(\bm{x}_1|\bm{\phi}_k) \right)^{z_{1k}}
\label{eq: HMM alpha-beta alpha t1}.
\end{eqnarray}
นั่นคือ $\alpha( z_{1k} ) = \pi_k \cdot p(\bm{x}_1|\bm{\phi}_k)$.

การคำนวณเริ่มจากลำดับเวลาแรก แล้วค่อย ๆ คำนวณขยับไปทีละลำดับ.
การคำนวณสมการ~\ref{eq: HMM alpha-beta alpha}
ทำการบวก $K$ พจน์ สำหรับแต่ละสถานะซ่อนเร้น ซึ่งสถานะซ่อนเร้นมีจำนวนทั้งหมด $K$ สถานะ.
ดังนั้นที่แต่ละลำดับเวลา การคำนวณจะขยายเป็น $K^2$ (นั่นคือ $O(K^2)$)
และการคำนวณจะเป็น $O(T K^2)$ สำหรับทั้งชุดลำดับ.

ในทำนองเดียวกัน
ค่า
$\beta(\bm{z}_t)$
สามารถจัดรูปการคำนวณใหม่ได้ดังนี้
\begin{eqnarray}
\beta(\bm{z}_t)
&=& p(\bm{x}_{t+1}, \ldots, \bm{x}_T|\bm{z}_t)
\nonumber \\
&=& \sum_{\bm{z}_{t+1}} p(\bm{x}_{t+1}, \ldots, \bm{x}_T, \bm{z}_{t+1}|\bm{z}_t)
\nonumber \\
&=& \sum_{\bm{z}_{t+1}} p(\bm{x}_{t+1}, \ldots, \bm{x}_T|\bm{z}_{t+1},\bm{z}_t)) 
\cdot p(\bm{z}_{t+1}|\bm{z}_t)
\nonumber \\
&=& \sum_{\bm{z}_{t+1}} p(\bm{x}_{t+1}, \ldots, \bm{x}_T|\bm{z}_{t+1})) 
\cdot p(\bm{z}_{t+1}|\bm{z}_t)
\nonumber \\
&=& \sum_{\bm{z}_{t+1}} p(\bm{x}_{t+2}, \ldots, \bm{x}_T|\bm{z}_{t+1}))
\cdot p(\bm{x}_{t+1}|\bm{z}_{t+1}) 
\cdot p(\bm{z}_{t+1}|\bm{z}_t)
\nonumber \\
&=& \sum_{\bm{z}_{t+1}} \beta(\bm{z}_{t+1})
\cdot p(\bm{x}_{t+1}|\bm{z}_{t+1}) 
\cdot p(\bm{z}_{t+1}|\bm{z}_t)
\label{eq: HMM alpha-beta beta}
\end{eqnarray}
สำหรับ $t = 1, \ldots, T-1$.
สำหรับ ลำดับเวลาท้ายสุด 
เพื่อประเมินค่า $\beta(\bm{z}_T)$ พิจารณาสมการ~\ref{eq: alpha-beta q} และ~\ref{eq: alpha-beta q alpha beta} 
เมื่อ $t = T$.
นั่นคือ
\begin{eqnarray}
p(\bm{z}_T|\bm{X})
&=&
\frac{p(\bm{x}_1, \ldots, \bm{x}_T,\bm{z}_T) \cdot \beta(\bm{z}_T) }{p(\bm{X})} 
= \frac{p(\bm{X}, \bm{z}_T)}{p(\bm{X})} \cdot \beta(\bm{z}_T) 
\end{eqnarray}
และจาก\textit{กฎผลคูณ} ซึ่ง ณ ที่นี้ คือ
$\frac{p(\bm{X}, \bm{z}_T)}{p(\bm{X})} = p(\bm{z}_T|\bm{X})$
ดังนั้น ค่าของ $\beta(\bm{z}_T)$ ต้องเท่ากับหนึ่ง
สำหรับทุก ๆ สถานะของ $\bm{z}_T$.
นั่นคือ
$\beta(z_{Tk}) = 1$ สำหรับ $k = 1, \ldots, K$.
(หมายเหตุ นิยาม $\beta(\bm{z}_t) \equiv p(\bm{x}_{t+1}, \ldots, \bm{x}_T| \bm{z}_t)$
	ในนิพจน์~\ref{eq: alpha-beta beta} ไม่ได้ครอบคลุมลำดับ $t = T$.)

ตรงกันข้ามกับการคำนวณ $\alpha(\bm{z}_t)$ ที่เริ่มจากลำดับเวลาแรก แล้วขยับลำดับไปข้างหน้า
การคำนวณ $\beta(\bm{z}_t)$ เริ่มจากลำดับเวลาท้ายสุด แล้วขยับย้อนถอยหลังมาเรื่อย ๆ.
หลังจากได้ค่าของ $\alpha(\bm{z}_t)$ และ $\beta(\bm{z}_t)$ สำหรับ $t = 1, \ldots, T$
แล้วอาจประเมินค่า\textit{ความน่าจะเป็นภายหลัง}ด้วยสมการ~\ref{eq: alpha-beta q alpha beta} และ~\ref{eq: alpha-beta R alpha beta}
ใน\textit{ขั้นตอนการหาค่าคาดหมาย}
ซึ่งต้องการค่า $p(\bm{X})$ ประกอบ
หรือ อาจนำค่า $\alpha(\bm{z}_t)$ และ $\beta(\bm{z}_t)$ ที่ได้
ไปใช้ใน\textit{ขั้นตอนการหาค่าตัวทำมากที่สุด}โดยตรงเลยก็ได้
เนื่องจากการคำนวณใน\textit{ขั้นตอนการหาค่าตัวทำมากที่สุด}นั้น
ค่าของ $p(\bm{X})$ จะหักล้างกันเอง ตัวอย่างเช่น สมการ~\ref{eq: seq HMM pi_k} ซึ่งคือ
\begin{eqnarray}
\pi_k &=& \frac{q_{1k}}{\sum_{j=1}^K q_{1j}}
= \frac{\alpha(z_{1k}) \cdot \beta(z_{1k})}{\sum_{j=1}^K \alpha(z_{1j}) \cdot \beta(z_{1j})}
\label{eq: seq HMM pi_k alpha beta} .
%\\
%A_{jk} &=& \frac{\sum_{t=2}^T R^{(t-1,t)}_{jk} }{ \sum_{l=1}^K \sum_{t=2}^T R^{(t-1,t)}_{jl} }
%\label{eq: seq HMM A_jk alpha beta} .
\end{eqnarray}

อย่างไรก็ตาม 
หากต้องการประเมินค่าของ $p(\bm{X})$ ก็สามารถทำได้อย่างสะดวก.
พิจารณาสมการ~\ref{eq: alpha-beta q} และสมการ~\ref{eq: alpha-beta q alpha beta} จะเห็นว่า
\begin{eqnarray}
p(\bm{z}_t|\bm{X})
&=& \frac{\alpha(\bm{z}_t) \cdot \beta(\bm{z}_t)}{p(\bm{X})}
\nonumber \\
p(\bm{z}_t, \bm{X})
&=& \alpha(\bm{z}_t) \cdot \beta(\bm{z}_t)
\nonumber
\end{eqnarray}
ดังนั้น
\begin{eqnarray}
p(\bm{X}) = \sum_{\bm{z}_t} p(\bm{z}_t, \bm{X})
= \sum_{\bm{z}_t} \alpha(\bm{z}_t) \cdot \beta(\bm{z}_t)
\label{eq: alpha beta p(X) any t}
\end{eqnarray}
ซึ่งหมายถึง เราสามารถเลือกดัชนีลำดับ $t$ ใดก็ได้ ที่จะใช้ประเมินค่า $p(\bm{X})$.
ค่าดัชนีลำดับที่สะดวกในกรณีนี้ คือ $t = T$ ซึ่งจะได้
\begin{eqnarray}
p(\bm{X})
&=& \sum_{\bm{z}_T} \alpha(\bm{z}_T)
\label{eq: alpha beta p(X)}
\end{eqnarray}
เพราะว่า $\beta(\bm{z}_{tk}) = 1$ สำหรับทุก ๆ ค่าของ $k$.

สังเกตว่า
ค่า $p(\bm{X})$ อาจหาได้โดย\textit{การสลายปัจจัย} 
$p(\bm{X}) = \sum_{\bm{Z}} p(\bm{Z}, \bm{X})$
แต่การทำเช่นนั้นเท่ากับการบวกของ $K^T$ พจน์ ซึ่งแต่ละพจน์ต้องประเมินค่า $p(\bm{Z}, \bm{X})$
เปรียบเทียบกับสมการ~\ref{eq: alpha beta p(X)} ซึงเท่ากับการบวกของ $K$ พจน์เท่านั้น.
การจัดรูปการคำนวณในสมการ~\ref{eq: alpha beta p(X)} จึงเปลี่ยนการคำนวณที่ปริมาณเป็นสัดส่วนเติบโตแบบชี้กำลัง
มาเป็นสัดส่วนแบบเชิงเส้น ลดการคำนวณลงได้มหาศาล โดยเฉพาะกับชุดลำดับข้อมูลยาว ๆ.

\paragraph{การอนุมานข้อมูลด้วยแบบจำลองมาร์คอฟซ่อนเร้น.}
แบบจำลองมาร์คอฟซ่อนเร้น สามารถนำประยุกต์ใช้ได้กว้างขวางในการอนุมานต่าง ๆ.
ตัวอย่างหนึ่งที่สำคัญ คือ กรณีการอนุมานจุดข้อมูลต่อไปในชุดลำดับ เช่น ในกรณีการทำนายทางการเงิน (ภาพบนสุด รูป~\ref{fig: seq sequential pattern recognition tasks} ที่อินพุตเป็นชุดลำดับของราคาปิดต่อวัน จากหลาย ๆ วันที่ผ่านมา และเอาต์พุตคือค่าทำนายราคาปิดของวันปัจจุบัน).
นั่นคือ ด้วยข้อมูลชุดลำดับที่ถูกสังเกตมา $\bm{X} = \{\bm{x}_1, \ldots, \bm{x}_T \}$
เราต้องการทำนายจุดข้อมูล $\bm{x}_{T+1}$.
ด้วยเงื่อนไขมาร์คอฟและทฤษฎีของเบส์
การอนุมานอาจทำผ่านค่าความน่าจะเป็น
ซึ่งวิเคราะห์ได้ดังนี้
\begin{eqnarray}
p(\bm{x}_{T+1}|\bm{X}) 
&=& \sum_{\bm{z}_{T+1}} p(\bm{x}_{T+1}, \bm{z}_{T+1}|\bm{X})
\nonumber \\
&=& \sum_{\bm{z}_{T+1}} p(\bm{x}_{T+1}|\bm{z}_{T+1}) \cdot p(\bm{z}_{T+1}|\bm{X})
\nonumber \\
&=& \sum_{\bm{z}_{T+1}} 
\left\{
p(\bm{x}_{T+1}|\bm{z}_{T+1}) \cdot \sum_{\bm{z}_T} p(\bm{z}_T, \bm{z}_{T+1}|\bm{X})
\right\}
\nonumber \\
&=& \sum_{\bm{z}_{T+1}} 
\left\{
p(\bm{x}_{T+1}|\bm{z}_{T+1}) 
\cdot \sum_{\bm{z}_T} p(\bm{z}_{T+1}|\bm{z}_T) \cdot p(\bm{z}_T|\bm{X})
\right\}
\nonumber \\
&=& \sum_{\bm{z}_{T+1}} 
\left\{
p(\bm{x}_{T+1}|\bm{z}_{T+1}) 
\cdot \sum_{\bm{z}_T} p(\bm{z}_{T+1}|\bm{z}_T) \cdot 
\frac{p(\bm{z}_T,\bm{X})}{p(\bm{X})}
\right\}
\nonumber \\
&=& 
\frac{1}{p(\bm{X})}
\sum_{\bm{z}_{T+1}} 
\left\{
p(\bm{x}_{T+1}|\bm{z}_{T+1}) 
\cdot \sum_{\bm{z}_T} p(\bm{z}_{T+1}|\bm{z}_T) \cdot 
\alpha(\bm{z}_T)
\right\}
\label{eq: alpha-beta predict next x} .
\end{eqnarray}

สมการ~\ref{eq: alpha-beta predict next x} ประเมินได้
ด้วยการบวก $K^2$ พจน์.
การคำนวณสามารถทำได้อย่างมีประสิทธิภาพเช่นนี้ได้
เพราะการประเมินค่า $p(\bm{z}_t|\bm{X})$ สามารถทำผ่านค่า $\alpha(\bm{z}_t)$ ได้.
%เปรียบเทียบกับการคำนวณโดยตรงผ่านวิธีการสลายปัจจัย

\paragraph{ข้อจำกัดของแบบจำลองมาร์คอฟซ่อนเร้น.}
แบบจำลองมาร์คอฟซ่อนเร้น เป็นแบบจำลองเชิงความน่าจะเป็น
แม้จะมีศักยภาพสูง
แต่ปัจจุบัน
การประยุกต์ใช้กับภาระกิจการรู้จำรูปแบบเชิงลำดับที่ซับซ้อน เช่น การรู้จำเสียงพูด และการประมวลผลภาษาธรรมชาติ
นิยมใช้แนวทางของ\textit{โครงข่ายประสาทเวียนกลับ} (หัวข้อ~\ref{sec: RNN}) มากกว่า
เพราะว่า \textit{โครงข่ายประสาทเวียนกลับ}สามารถทำภาระกิจดังกล่าวได้ดีกว่ามาก.
ปัจจัยที่เป็นสาเหตุของความสามารถที่จำกัดของแบบจำลองมาร์คอฟซ่อนเร้น
อาจได้แก่
จำนวนสถานะซ่อนเร้น ถูกจำกัด 
หรือการที่ต้องกำหนด ระบุจำนวนสถานะอย่างชัดเจนในตัวแบบจำลอง,
%ไม่สามารถใช้ความสัมพันธ์ จากลำดับข้างหลังได้โดยตรง 
%เช่น ``There is'' กับ ``There are'' การเลือก plurality ต้องรู้คำในลำดับข้างหลัง
การเรียนรู้ความสัมพันธ์ระยะยาว ต้องการอาศัยการทำผ่านตัวแปรซ่อนเร้น ซึ่งถูกจำกัดจำนวนสถานะไว้ 
และการใช้รหัสหนึ่งร้อน ยังทำให้ตัวแปรซ่อนเร้นไม่อาจแทนความสัมพันธ์ที่ซับซ้อนอย่างมีประสิทธิภาพได้ คือ ไม่สามารถระบุแยกความสัมพันธ์เป็นองค์ประกอบย่อยได้
และอาจจะรวมถึง
การอาศัยมุมมองเชิงความน่าจะเป็น ซึ่งอยู่บนสมมติฐานของการวิเคราะห์ที่ครอบคลุมทุกกรณี ที่อาจจะส่งผลในทางปฏิบัติ (หากไม่มีกลไกพิเศษ เพื่อแก้ไข ชดเชย หรือบรรเทาการคำนวณที่พัฒนาจากสมมติฐานเช่นนี้%
\footnote{%
งานวิจัย \cite{NakjaiK18, NakjaiEtAl2019a} ได้ชี้ให้เห็นปัญหาของ\textit{สมมติฐานว่าการวิเคราะห์ครอบคลุมทุกกรณี} (assumption of all-inclusiveness) และได้เสนอกลไกบรรเทา สำหรับกรณีโครงข่ายประสาทเทียมจำแนกประเภท.
}%
).

%\section{Glossary}
\section{อภิธานศัพท์}

\begin{description}
	
	\item[ข้อมูลเชิงลำดับ (sequential data):] 
	ข้อมูลประเภทที่จุดข้อมูลมีความสัมพันธ์เชิงลำดับระหว่างกัน
	\index{thai}{ข้อมูลเชิงลำดับ}
	\index{english}{sequential data}
	
	
	\item[แบบจำลองมาร์คอฟ (Markov model):] 
	\index{english}{Markov model}
	\index{thai}{แบบจำลองมาร์คอฟ}	
	แบบจำลองความสัมพันธ์เชิงลำดับของข้อมูล ที่ใช้เงื่อนไข\atom{มาร์คอฟ}
	ซึ่งจำกัด ให้จุดข้อมูลมีความความสัมพันธ์เชิง\textit{ความไม่เป็นอิสระต่อกันแบบมีเงื่อนไข} (conditional dependence) ระหว่างกันได้ เฉพาะกับจุดข้อมูลลำดับที่ผ่านมา ตามจำนวนลำดับที่กำหนด.


	\item[แบบจำลองมาร์คอฟซ่อนเร้น (Hidden Markov model คำย่อ HMM):]
	แบบจำลองสำหรับข้อมูลเชิงลำดับ ที่บรรยายความสัมพันธ์เชิงลำดับของค่าข้อมูล ผ่าน\textit{ตัวแปรซ่อนเร้น}
	และใช้เงื่อนไขมาร์คอฟกับ\textit{ตัวแปรซ่อนเร้น}.
	\index{english}{HMM}
	\index{thai}{แบบจำลองมาร์คอฟซ่อนเร้น}
	
		
	\item[ตัวแปรที่สังเกตได้ (observable variable):]
	ค่าจุดข้อมูล ซึ่งเป็นค่าที่สามารถรู้แน่นอนได้
	\index{thai}{ตัวแปรที่สังเกตได้}
	\index{english}{observable variable}
	
	\item[สถานะซ่อนเร้น (latent state) หรือ ตัวแปรซ่อนเร้น (latent variable):]
\index{english}{latent state}
\index{english}{latent variable}
\index{english}{latent state!HMM}
\index{english}{latent variable!HMM}
ค่าจุดข้อมูลที่สมมติขึ้น หรือเชื่อว่ามีอยู่
อาจจะสามารถรู้ค่าแน่นอนได้ หรืออาจจะไม่สามารถรู้ค่าได้เลย 
และอาจมีนัยความหมายจริงก็ได้ หรืออาจจะไม่ได้มีนัยความหมายที่ชัดเจนก็ได้.

	\item[ค่าความน่าจะเป็นเริ่มต้น (initial probabilities):]
\index{english}{initial probabilities}
\index{english}{initial probabilities!HMM}
\index{thai}{ค่าความน่าจะเป็นเริ่มต้น}
\index{thai}{ค่าความน่าจะเป็นเริ่มต้น!แบบจำลองมาร์คอฟซ่อนเร้น}
ความน่าจะเป็นของสถานะต่าง ๆ ของจุดข้อมูลที่ลำดับแรกสุด

	\item[ความน่าจะเป็นของการเปลี่ยนสถานะ  (transition probabilities):]
\index{english}{transition probabilities}
\index{thai}{ความน่าจะเป็นของการเปลี่ยนสถานะ}
\index{english}{transition probabilities!HMM}
\index{thai}{ความน่าจะเป็นของการเปลี่ยนสถานะ!แบบจำลองมาร์คอฟซ่อนเร้น}
ความน่าจะเป็นของสถานะต่าง ๆ ของจุดข้อมูลที่ลำดับถัดไป เมื่อจุดข้อมูลลำดับปัจจุบันมีสถานะดังระบุ.

	\item[ความน่าจะเป็นของการปล่อย (emission  probabilities):]
\index{thai}{ความน่าจะเป็นของการปล่อย}
\index{english}{emission  probabilities}
\index{thai}{ความน่าจะเป็นของการปล่อย!แบบจำลองมาร์คอฟซ่อนเร้น}
\index{english}{emission  probabilities!HMM}
ความน่าจะเป็นของค่าจุดข้อมูลที่สังเกตได้ เมื่อสถานะซ่อนเร้นมีค่าดังระบุ

	\item[ฟังก์ชันควรจะเป็น  (likelihood function):]
\index{thai}{ฟังก์ชันควรจะเป็น}
\index{english}{likelihood function}
ฟังก์ชันของตัวแปรที่สนใจ ที่คำนวณค่าความน่าจะเป็น ด้วยค่าข้อมูลที่สังเกตได้

	\item[ขั้นตอนวิธีอีเอ็ม (expectation-maximization algorithm คำย่อ EM algorithm):]
ขั้นตอนวิธีทั่ว ๆ ไป สำหรับการหาค่าพารามิเตอร์ ของแบบจำลองเชิงความน่าจะเป็น
โดยอาศัยขั้นตอนการคำนวณค่าคาดหมาย เมื่อกำหนดค่าพารามิเตอร์ที่สนใจเป็นค่าคงที่
สลับกับขั้นตอนการหาค่ามากที่สุด 
ที่ใช้ค่าคาดหมายที่ได้ประเมินค่า\textit{ฟังก์ชันควรจะเป็น} สำหรับการหาค่าพารามิเตอร์ที่ทำให้\textit{ฟังก์ชันควรจะเป็น}มีค่ามากที่สุด.
\index{thai}{ขั้นตอนวิธีอีเอ็ม}
\index{english}{expectation-maximization algorithm}
\index{thai}{ขั้นตอนวิธีอีเอ็ม!แบบจำลองมาร์คอฟซ่อนเร้น}
\index{english}{expectation-maximization algorithm!HMM}

\end{description}


